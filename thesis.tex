\documentclass[msc,deptreport,cs]{infthesis} % Do not change except to add your degree (see above).

\usepackage[usenames,dvipsnames]{xcolor}
%% Imports poached from frankly
%% STILL can't find what makes \figrule work
\usepackage{natbib}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{thmtools,thm-restate}
\usepackage{comment}
\usepackage{flushend}
\usepackage{listings}
\usepackage{lstlinebgrd}

\usepackage[makeroomr]{cancel}
%% \usepackage{beramono}

%% \lstdefinestyle{mystyle}{
%%     %% backgroundcolor=\color{backcolour},
%%     %% commentstyle=\color{codegreen},
%%     %% keywordstyle=\color{magenta},
%%     %% numberstyle=\tiny\color{codegray},
%%     %% stringstyle=\color{codepurple},
%%     breakatwhitespace=false,
%%     breaklines=true,
%%     captionpos=b,
%%     keepspaces=true,
%%     %% numbers=left,
%%     %% numbersep=5pt,
%%     showspaces=false,
%%     showstringspaces=false,
%%     showtabs=false,
%%     tabsize=2,
%%     %% basicstyle=\small\ttfamily
%%     basicstyle=\ttfamily\footnotesize,
%%     %% breaklines=true
%% }

%% \lstset{style=mystyle}

%% \lstset{escapeinside={<@}{@>}}

\lstset{
  %% basicstyle=\small\ttfamily\bfseries,
  basicstyle=\footnotesize\ttfamily\bfseries,
  %% basicstyle=\footnotesize\ttfamily,
  %% basicstyle=\small\ttfamily,
  breaklines=true,
  % For having lighter-coloured text inside listings
  % https://tex.stackexchange.com/questions/144448/color-a-text-line-in-a-code-lstlisting
  escapeinside={<@}{@>}
}


\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{xspace}
%% \usepackage[pdftex,
%%             pdfauthor={Sam Lindley, Conor McBride, and Craig McLauglin},
%%             pdftitle={Doo bee doo bee doo}]{hyperref}
%\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue}
%% \hypersetup{colorlinks=true,allcolors=black}
\usepackage{url}

% get rid of hypertext link on \citeauthor
\usepackage{etoolbox}

\usepackage{amssymb}

\usepackage{mathtools} % allows flush-left align environments and paired
                       % delimiters.
                       %
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}


%% abstract for inline code
\newcommand{\code}[1]{\lstinline{#1}}
\newcommand{\codem}[1]{\lstinline[mathescape]{#1}}


\newcommand{\highlight}[1]{%
  \colorbox{red!20}{$\displaystyle#1$}}

\newcommand{\texthighlight}[1]{%
  \colorbox{red!20}{#1}}

\newcommand{\highlightout}[1]{%
  \colorbox{black!20}{$\displaystyle#1$}}

\newcommand{\greytext}[1]{\textcolor{black!40}{#1}}

\newcommand\aeff{{\AE}ff\xspace}

\newcommand\figscale{0.85}

\newcommand\nondetfrank{$\mathbb{F}_{\cal{ND}}$}
\newcommand\countingfrank{$\mathbb{F}_{\cal{C}}$}
\newcommand\treefrank{$\mathbb{F}_{\cal{T}}$}

\newcommand\feed{$\mathcal{F}$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\counter}{{\color{blue} \textsf{c}}}
\newcommand{\justc}[1]{{\color{blue} \textsf{count}({#1})}}
\newcommand{\yieldc}{{\color{blue}{\textsf{yield}}}}
\newcommand{\plusc}{{\color{blue} \oplus}}
\newcommand{\threshc}{{\color{blue} \textsf{t}}}
\newcommand{\succc}[1]{\bluetext{#1 \plusc 1}}

\newcommand{\bluetext}[1]{{\color{blue}#1}}

\newcommand\yield{\textsf{yield}\xspace}
\newcommand\Yield{\textsf{Yield}\xspace}
\newcommand\allows{\textsf{allows}\xspace}


\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newcommand{\todo}[1]
           {{\par\noindent\small\color{RoyalPurple}
  \framebox{\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
    {\textbf{TODO:} #1}}}}

\newcommand{\interrupt}[1]{!(#1)}

\newcommand{\fighead}{\textbf}

\newcommand{\lameff}{$\lambda_{\text{eff}}$\xspace}
\newcommand{\lameffrow}{$\lambda_{\text{eff}}^\rho$\xspace}
\newcommand{\feff}{$F_\textrm{eff}$\xspace}
\newcommand{\impeff}{Implicit \lameff}
\newcommand\Frank{\emph{Frank}\xspace}

\newcommand\Cse{\textbf{Case}}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\many}{\overline}
\newcommand{\opt}[1]{#1^?}
\newcommand{\medvert}{\mid}

\newcommand{\sem}[1]{\llbracket{#1}\rrbracket}
\newcommand{\seml}{\left\llbracket}
\newcommand{\semr}{\right\rrbracket}

\newcommand{\mdo}{~\textbf{do}~}
\newcommand{\seq}{~\textbf{;}~}
\newcommand{\assn}[2]{{#1}~\leftarrow~{#2}}
\newcommand{\func}[2]{\text{#1}~{#2}}

\newcommand{\deno}[1]{\sem{#1}\rho}
\newcommand{\denoex}[2]{\sem{#1}#2}
\newcommand{\pc}[1]{\llparenthesis{#1}\rrparenthesis}

\newcommand{\TyVar}{\mathit{Var}}
\newcommand{\dom}{\mathit{dom}}
%\newcommand{\sub}{\subseteq}
\newcommand{\Star}{{\Large$\star$}}

\newcommand{\reducesto}{\longrightarrow}

\newcommand\ba{\begin{array}}
\newcommand\ea{\end{array}}

\newcommand{\bl}{\ba[t]{@{}l@{}}}
\newcommand{\el}{\ea}

\newcommand{\bstack}{\begin{array}[t]{@{}l@{}}}
\newcommand{\estack}{\end{array}}

\newenvironment{equations}{\[\ba{@{}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}
\newenvironment{eqs}{\ba{@{}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{clauses}{\ba{@{}l@{~}c@{~}l@{}}}{\ea}

\newenvironment{syn}{\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{syntax}{\[\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}

\newcommand{\judgeword}[1]{~\mathbf{#1}~}

%\renewcommand{\sig}{\Sigma}
%\renewcommand{\sigs}{\Sigma s}
\newcommand{\sigentails}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\hspace{-0.4ex}\text{-\!-}}\,}

%% \newcommand{\sigmodels}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\!\mathord{=}}\,}
% \newcommand{\sigentails}[1]{\vdash_{#1}}

\newcommand{\val}[3]  {#1 \vdash {#2} : {#3}}

\newcommand{\rt}[1]{\langle{#1}\rangle}   % returner type

\newcommand{\valg}{\val{\Gamma}}

%% \newcommand{\is}[4]  {#1 \sigentails{#2} {#3} \judgeword{is} {#4}}
%% \newcommand{\isgs}{\is{\Gamma}{\sigs}}

%% \newcommand{\cdoes}[4]{#1 \sigentails{#2} {#3} \judgeword{has} {#4}
%% \newcommand{\cdoesgs}{\cdoes{\Gamma}{\sigs}}


%% some options for rendering bidirectional typing judgements

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \in {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \ni {#4}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

\newcommand{\kindcheckbase}[3]{#2 \mathbin{#1} #3} % For well-kindedness of types
\newcommand{\inferbase}[5]{#1; #3 \mathbin{#2} {#4} \Rightarrow {#5}}
\newcommand{\checkbase}[5]{#1; #3 \mathbin{#2} #5 \mathbin{:} #4}
\newcommand{\patbase}[5]{{#1} \vdash {#4} \mathbin{:} {#3} \mathbin{#2} {#5}}
\newcommand{\bindbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \Rightarrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \Leftarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \uparrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \downarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \judgeword{infers} {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \judgeword{checks} {#4}}
%% \newcommand{\patbase}[4]{{#2} \judgeword{matches} {#3} \mathbin{#1} #4}

\newcommand{\makes}[5]{\inferbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\has}[5]{\checkbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\does}[4]{\checkbase{#1}{\vdash}{#2}{#3}{#4}}
\newcommand{\can}[4]{\makes{\kenv}{#1}{#2}{#3}{#4}}

\newcommand{\effs}[2]{{#1} \judgeword{does} {#2}}


% redefinitions for cbv type system
\newcommand{\kindchecks}[2]{\kindcheckbase{\vdash}{#1}{#2}} % Checks that a type is well-kinded
\newcommand{\infers}{\makes}
\newcommand{\checks}{\has}
\newcommand{\checksdef}{\does}
\newcommand{\matchesc}{\matches}
\newcommand{\matchesck}{\matchesc{\kenv}}

\newcommand{\infersk}{\makes{\kenv}}
\newcommand{\checksk}{\has{\kenv}}
\newcommand{\checksdefk}{\does{\kenv}}

\newcommand{\kindchecksk}{\kindchecks{\kenv}} % Checks that a type is well-kinded
\newcommand{\inferskgs}{\makes{\kenv}{\Gamma}{\sigs}}
\newcommand{\checkskgs}{\has{\kenv}{\Gamma}{\sigs}}
\newcommand{\checksdefkg}{\does{\kenv}{\Gamma}}


\newcommand{\adj}{\Delta}
\newcommand{\adapt}{\Theta}
\newcommand{\ext}{\Xi}
\newcommand{\sigs}{\Sigma}
\newcommand{\sig}{I}

\newcommand{\seed}{\sigma}

\newcommand{\effbox}[1]{[#1]}

\newcommand{\key}[1]{\mathbf{#1}} % keyword
\newcommand{\var}{\mathit}        % local variable or meta variable
\newcommand{\defaultvarname}[0]{x}

\newcommand{\op}{\mathsf}  % operator (command or computation)
\newcommand{\con}{\mathsf} % constructor (type or data)
\newcommand{\inter}{\mathsf} % interface
\newcommand{\str}[1]{\textrm{``#1''}} % string literal


\newcommand{\handleSymbol}{\rightarrow}
\newcommand{\handle}[2]{{#1} \handleSymbol {#2}}

\newcommand{\thunk}[1]{\{{#1}\}}

\newcommand{\force}[1]{{#1}!}

\newcommand{\emptylist}{[]}
\newcommand{\cons}{\mathbin{::}}
\newcommand{\concat}{\,\texttt{++}\,} %mathbin{+\!+}}
%\newcommand{\snoc}{\mathbin{:<}}
\newcommand{\snoc}{\ }


\newcommand{\NN}{\mathbb{N}}

\newcommand\slab[1]{(\textrm{#1})}

\newcommand{\ev}{E}
\newcommand{\evd}{\varepsilon}

\newcommand{\effin}[1]{\langle {#1} \rangle}
\newcommand{\effout}[1]{[{#1}]}

\newcommand{\nowt}{\emptyset}
\newcommand{\id}{\iota}
\newcommand{\pid}{\var{s}} % Pattern identity variable

\newcommand{\EC}{\mathcal{E}}
\newcommand{\EF}{\mathcal{F}}
\newcommand{\PC}{\mathcal{P}} % Syntactic phrase class for af operation
\newcommand{\venv}{\theta}

\newcommand{\freeze}{\ceil}

\newcommand{\uc}{\mathord{\downarrow}}
\newcommand{\cu}{\mathord{\uparrow}}

\newcommand{\redto}{\leadsto}
\newcommand{\redtou}{\leadsto_{\mathrm{u}}}
\newcommand{\redtoc}{\leadsto_{\mathrm{c}}}
\newcommand{\stepsto}{\longrightarrow}

\newcommand{\stepstou}{\longrightarrow_{\mathrm{u}}}
\newcommand{\stepstoc}{\longrightarrow_{\mathrm{c}}}

\newcommand{\sigat}{\mathbin{@}}

\newcommand{\meta}{\mathsf}
\newcommand{\level}{\meta{level}}
\newcommand{\af}{\meta{af}}
\newcommand{\handles}{~\meta{handles}~}

\newcommand{\poised}{~\meta{poisedfor}~}
\newcommand{\insts}{\meta{inst}}
\newcommand{\remap}{\meta{remap}}

\newcommand{\sigyields}[1]
           {\mathbin{\text{-\!-\!}[{\text{\scriptsize ${#1}$}}]\,}}

\newcommand{\matches}[5]{\patbase{#1}{\sigyields{#4}}{#2}{#3}{#5}}
\newcommand{\matchesv}[4]{\patbase{#1}{\dashv}{#2}{#3}{#4}}
\newcommand{\matchesvk}{\matchesv{\kenv}}

\newcommand{\bindsv}[4]{\bindbase{\dashv}{#2 \leftarrow #3}{#1}{#4}}
\newcommand{\bindsc}[5]{\bindbase{\sigyields{#4}}{#2 \leftarrow #3}{#1}{#5}}

\newcommand{\letin}[4][\defaultvarname]
           {\key{let}\;{#1}:{#2}={#3}\;\key{in}\;{#4}}
\newcommand{\letxin}[3][\defaultvarname]
           {\key{let}\;{#1}={#2}\;\key{in}\;{#3}}
\newcommand{\letrec}[4][f]{\key{letrec}~\many{{#1}:{#2} = {#3}}~\key{in}~{#4}}
\newcommand{\letrecU}[3][f]{\key{letrec}~\many{{#1} = {#2}}~\key{in}~{#3}}
\newcommand{\Gt}{\theta} % Substitution meta variable
\newcommand{\submap}[2]{{{#1}\vDash{#2}}}
\newcommand{\sub}[4]{#1 \vdash {{#2}:\submap{{#3}}{{#4}}}}
\newcommand{\subk}{\sub{\kenv}}
\newcommand{\subext}[2]{{{#1}{#2}}}
\newcommand{\subst}[3][\defaultvarname]{{#2}[{#3}/{#1}]}

% Frank letrec substitution
\newcommand{\recsub}[5][f]
      {[\many{\cu (\thunk{\many{\many{#2}\mapsto\letrec[{#1}]{#5}{#3}{#4}}}
            : {#5})/{#1}}]}


%%%% START inference rule system for action of adjustment on ability %%%%
\newcommand{\semi}{;}
\newcommand{\kenv}{\Phi}  % kind environment
\newcommand{\kenva}{\Psi} % another kind environment
%% \newcommand{\kenv}{\mathcal{T}} % kind environment
\newcommand{\ienv}{\Omega} % Instance environment
\newcommand{\adjact}[3]{{#1}\vdash{#2}\dashv{#3}}
\newcommand{\adpcom}[5]{{{#1}\vdash{#2}({#3} \to {#4})\dashv{#5}}}
\newcommand{\itrbnd}[5]{{{#1}\vdash{#2}:{#3}\dashv{#4}\semi{#5}}}
% \newcommand{\wf}[2]{{{#1}\vdash{#2}}}
\newcommand{\itrinst}[4]{{{#1}\vdash{#2}:{#3}\dashv{#4}}}

%%% END inference rule system for action of adjustment on ability %%%%%

% Untyped machine letrec substitution
\newcommand{\recsubst}[5]
 {{#1}[\many{(\thunk{\many{\many{#2} \mapsto \letrecU{#3}{#4}}}:{#5})/f}]}

%% Abstract machine commands
% Typing
\newcommand{\HAbs}[2]{{{#1}\to{#2}}}

\newcommand{\fail}{\textbf{fail}}

%% Translation function: Frank Terms to Untyped A-Normal Form
\newcommand{\UANF}[1]{{\llbracket{{#1}}\rrbracket}}

% Terms
\newcommand{\mtrns}[3][]{{#2} & \Rightarrow^{#1} & {#3}} % For array env
\newcommand{\mtrnsR}[3][]{{#2}\Rightarrow^{#1}{#3}}

\newcommand{\confg}[2]{{\langle{{#1}},{{#2}}\rangle}}
\newcommand{\term}[3]
           {{\langle{{#1}},{{#2}}\rangle\downarrow{#3}}}

\newcommand{\admin}[2]{{\langle{{#1}}\mid{{#2}}\rangle}}
\newcommand{\mat}[3]
           {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\rangle}}
\newcommand{\matc}[5]
        {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\mid{{#4}}\mid{{#5}}\rangle}}

\newcommand{\msub}[3][\defaultvarname]{{#2}[{#1}\mapsto{#3}]}

\newcommand{\FHan}[4][\many{\effin{\adj}}]{{({#2}:{#1},{#3}\mid{#4})}}
\newcommand{\FSeq}[2][\defaultvarname]
           {{({#1}.{#2})}}
\newcommand{\SCons}[2]{{{#1}\circ{#2}}}


\newcommand{\HSHan}[5][C]{{{#2}\circ({#3},{#1},{#4}\mid{#5})}}
\newcommand{\HSSeq}[4][\defaultvarname]
           {{#2}\circ({#1}:{#3}.{#4})}
\newcommand{\HSCons}[2]{{{#1}\circ{#2}}}
\newcommand{\NF}[2]{{{#1}~\star~{#2}}}

\newcommand{\evalto}{\Longrightarrow}


\newcommand{\para}[1]{\paragraph{#1.}}

\newcommand{\gor}{\mid}
\newcommand{\pipe}{\texttt{|}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of main text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{preliminary}

\title{Asynchronous Effect Handling}

\author{Leo Poulson}

\abstract{
  Features for asynchronous programming are commonplace in the programming
  languages of today, allowing programmers to issue tasks to run on other
  threads and wait for the results to come back later. These features are often
  built into the language, and are opaque to the user.

  In this thesis we show how a library for asynchronous programming can be very
  easily implemented in a language with existing support for effect handlers. We
  show how, with a small change to the language implementation, truly
  asynchronous programming with pre-emptive concurrency is achieved.

  Our system is expressive enough to define common asynchronous programming
  constructs, such as async-await and futures, within the language itself.
}

\maketitle

\section*{Acknowledgements}
thanks!

\tableofcontents

\end{preliminary}

\chapter{Introduction}

Effects, such as state and nondeterminism, are pervasive when programming; for a
program to do anything beyond compute a pure mathematical function, it must
interact with the outside world, be this to read from a file, make some random
choice, or run concurrently with another program. Algebraic effects and their
handlers (\cite{plotkin2013handling}) are a novel way to encapsulate, reason
about and specify computational effects in programming languages. For instance,
a program that reads from and writes to some local state can utilise the
\textsf{State} effect, which supports two \emph{operations}; \textsf{get} and
\textsf{put}. A handler for the \textsf{State} effect gives a meaning to these
abstract operations. Programming with algebraic effects and handlers is
increasingly popular; they have seen adoption in the form of libraries for
existing languages (\cite{kammar2013handlers, kiselyov2013extensible,
  brady2013programming}) as well as in novel languages designed with effect
handling at their core (\cite{bauer2015programming, leijen2017type, convent2020doo}).

Traditional effect handling is \emph{synchronous}; when an operation is invoked,
the rest of the computation pauses whilst the effect handler performs the
requisite computation and then resumes the original caller.
%
For many effects, this blocking behaviour is not a problem; the handler usually
returns quickly, and the user notices no delay. However, not every possible
computational effect behaves like this. Consider an effect involving a query to
a remote database. We might not want to block the rest of the computation whilst
we perform this, as the query might take a long time; this case is even stronger
if we do not immediately want the data. To support this kind of behaviour, we
need to be able to invoke and handle effects in an asynchronous, non-blocking
manner.

In this project we investigate the implementation and applications of
asynchronous effect handling. Our lens for this is the language
Frank~(\cite{convent2020doo}), a functional programming designed with effect
handlers at its core. We follow the design
of~\aeff~(\cite{ahman2020asynchronous}), a small programming language designed
around asynchronous effects but supporting little else.
%
% We show how, with a small change to the semantics of Frank, we can recreate the
% asynchronous effect handling behaviour of~\aeff~whilst enjoying the benefits of
% traditional effect handlers.
We show how by making a simple change to the semantics of Frank, in order to
yield pre-emptible threads, we can recreate the asynchronous effect handling
behaviour of \aeff~whilst still enjoying the benefits of traditional effect
handlers.

\todo{Last paragraph could be fixed}

Frank is well-suited to implement an asynchronous effects library. The fine-grained control over suspended computations makes it easy to treat code as data, and
\todo{Something else after the end}
% Frank is a well-suited language for an asynchronous effects library, especially
% because of the fine-grained control over suspended computations, making it very
% easy to treat code as data.
%
Despite this, our approach does not use any specific
Frank features; furthermore, the changes made to the semantics of Frank are
easily recreateable. It is our hope that these methods could be recreated in
another language equipped with first-class effect handlers.


\todo{Rewrite. Want to say that the change to the semantics is simple enough and
  the implementation simple enough that there should be no problems recreating
  our work in another language.}

Effect handlers have
already proven to make complicated control flow easy to implement
(\textbf{refs}), and our work further cements this viewpoint.

Our contributions are as follows;

\begin{itemize}
  %% \subparagraph*{Asynchronous Effects Library}
\item We present a library for programming with asynchronous effects, built in
  Frank. We show how a complex system can be expressed concisely and elegantly
  when programming in a language with effect handlers.
%% \todo{Rewrite the end of this; slightly
  %% messy}.

%% \subparagraph*{Pre-emptive Concurrency}
\item We show how, by making a small change to the operational semantics of
  Frank, we achieve \emph{pre-emptive concurrency}; that is, the suspension of
  running threads \emph{without} co-operation. It is our hope that this change
  is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples}
\item We also deliver a set of examples of the uses of asynchronous effects, and
  show how they have benefits to other models.
\end{itemize}

\section{Related Work}

Asynchronous programming with effect handlers is a fairly nascent field.
%
Koka (\cite{leijen2014koka}) is a programming language with built-in effect
handlers and a Javascript backend. \citeauthor{leijen2017structured} later shows
us how Koka can naturally support asynchronous programming
(\cite{leijen2017structured}). The asynchronous behaviour relies on offloading
asynchronous tasks with a \textsf{setTimeout} function supplied by the NodeJS
backend.

Multicore OCaml (\cite{dolan2014multicore}) also supports asynchronous
programming through effect handling (\cite{dolan2017concurrent}). They handle
effects and signals, which can be received asynchronously, and show how to
efficiently and safely write concurrenct systems programs. However, in a similar
way to Koka, the asynchrony relies on the operating system supplying operations,
such as \textsf{setSignal} and \textsf{timer} signals.

A problem shared by both Koka and Multicore OCaml is they have no support for
\emph{user-defined} asychronous effects; the asynchronous signals that can be
received are predefined. This problem is solved by
\aeff~(\cite{ahman2020asynchronous}), a small language built around asynchronous
effect handling. \citeauthor{ahman2020asynchronous} approach the problem of
asynchrony from a different perspective, by decoupling the invocation of an
effect from its handling and resumption with the handled value. When an effect
is invoked the rest of the computation is not blocked whilst the handler is
performed. Programs then install interrupt handlers that dictate how to act on
receipt of a particular interrupt. To recover synchronous behaviour, these
interrupt handlers can be \textsf{await}ed; this will block the rest of the code
until the interrupt is received.

\citeauthor{ahman2020asynchronous} then show how the simple building blocks of
interrupt handlers can be used to build common constructs for asynchronous
programming, such as cancellable remote function calls and a pre-emptive
scheduler.

\todo{Section on the expressivity?}

% We design our system based on \aeff, embedding its behaviour into Frank. We show
% that we can easily recover the behaviour of \aeff~when equipped with effect
% handlers, and show that asynchronous effects can still be used in conjunction
% with traditional, synchronous effects.

%
%The most prominent work is \aeff~(\cite{ahman2020asynchronous}),

%% \paragraph*{Contributions}

%% \subparagraph*{Asynchronous Effects Library} We present a library for programming
%% with asynchronous effects in the style of \aeff, built in Frank. We show how a
%% complex system can be expressed concisely and elegantly when programming in a
%% language with effect handlers, further cementing the case for effects as a
%% foundation for concurrent programming. \todo{Rewrite the end of this; slightly
%%   messy}.

%% \subparagraph*{Pre-emptive Concurrency} We show how, by making a small change to
%% the operational semantics of Frank, we achieve pre-emptive concurrency; that is,
%% the suspension of running threads \emph{without} co-operation. It is our hope
%% that this change is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples} We also deliver a set of examples of the uses of
%% asynchronous effects, and show how they have benefits to other models.

\section{Structure}

In Chapter~\ref{chap:programming-in-frank} we give an introduction to
programming with effects in Frank. We skip over some unneeded (and previously
well-covered) parts of the language, such as adaptors, in the interests of time.

In Chapter~\ref{chap:formalisation} we give the formalisation of Frank. Again,
we skip over extraneous details which can be seen in past work
(\cite{convent2020doo}), opting to only describe the parts needed to understand
the changes to the semantics for the following chapter.

In Chapter~\ref{chap:preemptive-concurrency} we show how by making a small
change to the semantics of Frank we yield pre-emptible threads; that is, we can
interrupt a function in the same co-operative style but without co-operation.

In Chapter~\ref{chap:implementation} we describe the implementation of our
asynchronous effect handling library in Frank. In Chapter~\ref{chap:examples} we
give examples of the new programs that become easily expressible when combined
with the changes made in Chapter~\ref{chap:preemptive-concurrency}.

In Chapter~\ref{chap:conclusion} we conclude.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Programming in Frank}
\label{chap:programming-in-frank}

Frank is a typed functional programming language, designed around the
definition, control and handling of algebraic effects. As such, Frank has an
effect type system used to track which effects a computation may use.

\todo{Extend this a bit - talk about ambient ability, computation vs. value, etc}

% Frank offers very fine-grained control over computations. It clearly
% distinguishes between computation and value, and offers \emph{multihandlers} to
% carefully control when computations are evaluated. This combined with effect
% handling provides a very rich foundation for expressing complex control
% structures.

In this chapter we introduce Frank, and show why it is so well-suited to our
task. We assume some familiarity with typed functional programming, and skip
over some common features of Frank --- algebraic data types, pattern matching,
etc. --- so we can spend more time with the novel, interesting parts. We also
skip some novel features of Frank, such as
adaptors~(\cite{convent2017enhancing}), as they are not essential for
understanding the work of this project.

% \section{Types, Values and Operators}
\paragraph*{Types, Values and Operators}

Frank types are distinguished between \emph{effect types} and \emph{value
  types}. Value types are the standard notion of type; effect types are
used to describe where certain effects can be performed and handled. Value types are further divided into traditional data types, such a \code{Bool},
\code{List X}, and \emph{computation types}.

A computation type
%
\lstinline[mathescape]!{X$_1$ -> $\ldots$ -> X$_m$ -> [I$_1$, $\ldots$, I$_n$] Y}!
%
%% This type expresses that the operator can handle some effect in the first
%% argument and then performs some other effects as a result, returning a value of
%% type \code{Y}.
describes an operator that takes $m$ arguments and returns a value of type
\code{Y}. The return type also expresses the \emph{ability} the computation
needs access to, being a list of $n$ \emph{interface} instances. An interface is
a collection of \emph{commands} which are offered to the computation.

\todo{Go more into depth about 'abilities'?}

%% Frank then specialises effect handling to traditional function application; a
%% function is the special case of an operator that handles no arguments. We see
%% that a function type \code{\{X -> Y -> Z\}} is just a special case of the
%% general operator type where no effects are handled or performed. Throughout this
%% thesis, we call

\paragraph*{Thunks}

\emph{Thunks} are the special case of an $n$-ary function that takes 0
arguments. We can evaluate them --- performing the suspended computation ---
with the 0-ary sequence of arguments, denoted \code{!}.
%
% Computations are suspended by wrapping them in braces.
The opposite action --- suspending a computation --- is done by surrounding the computation in braces, such that for a suspended computation \code{comp}, \code{\{comp!\}} is the identity.
%
This gives us fine-grained control over when we want to evaluate computations.


% For instance, we might want the sequential composition operator \code{snd} (also
% commonly known as the semicolon operator);

% \begin{lstlisting}
%   snd : {X -> Y -> Y}
%   snd x y = y
% \end{lstlisting}

% Frank is a left-to-right call-by-value language; arguments to functions are
% evaluated from left-to-right, until they become a value. In the case of
% \code{snd}, \code{x} is first evaluated, then \code{y}, which is finally
% returned. Compare this to \code{if};

% \begin{lstlisting}
% if : {Bool -> {X} -> {X} -> X}
% if true  yes no = yes!
% if false yes no = no!
% \end{lstlisting}

% \noindent The branches are given as thunks, where a single thunk is evaluated
% depending on the condition. If we did not take this approach both cases would be
% evaluated, which is clearly not the intended semantics of \code{if}. Frank's
% distinction between computation and value make controlling evaluation simple and
% pleasing.

Consider the operator \code{badIf} below;

\begin{lstlisting}
badIf : {Bool -> X -> X -> X}
badIf true  yes no = yes
badIf false yes no = no
\end{lstlisting}

\noindent Frank is a \emph{left-to-right}, \emph{call-by-value} language; all
arguments to operators are evaluated from left-to-right until they become a
value. As such, in the case of \code{badIf}, both of the branches will be
evaluated before the result of one of them is returned. We can recover the
correct semantics for \code{if} by giving the branches as thunks;

\begin{lstlisting}
if : {Bool -> {X} -> {X} -> X}
if true  yes no = yes!
if false yes no = no!
\end{lstlisting}

\noindent Here a single thunk is evaluated depending on the value of the
condition. Frank's distinction between computation and value make controlling
evaluation simple and pleasing.

%% \todo{Example --- maybe fire missiles one?}

% \section{Effects and Effect Handling}
% \label{sec:effects}

\paragraph*{Interfaces and Operations}

Frank encapsulates effects through \emph{interfaces}, which offer
\emph{commands}. For instance, the \code{State} effect (interface) offers two
operations (commands), \code{get} and \code{put}. In Frank, this translates to

\begin{lstlisting}
  interface State X = get : X
                    | put : X -> Unit

  interface RandInt = random : Int
\end{lstlisting}

The interface declaration for \code{State X} expresses that \code{get} is a
0-ary operation which is \emph{resumed} with a value of type \code{X}, and
\code{put} takes a value of type \code{X} and is resumed with \code{unit}.
Computations get access to an interface's commands by including them in the
\emph{ability} of the program. Commands are invoked just as normal functions;

\begin{lstlisting}
  xplusplus : {[State Int] Unit}
  xplusplus! = put (get! + 1)
\end{lstlisting}

\noindent This familiar program increments the integer in the state by 1.

\paragraph*{Handling Operations}

%% Traditional functions in Frank are a specialisation of Frank's handlers; that is
%% to say, functions are handlers that handle no effects. A handler for an
%% interface pattern matches \emph{on the operations} that are invoked, as well as
%% on the \emph{values} that the computation can return. Furthermore, the handler
%% gets access to the \emph{continuation} of the calling function as a first-class
%% value. Consider the handler for \code{State};

A handler for a specific interface can also pattern match on the
\code{operations} that are performed, and not just the values that can be
returned. As an example, consider the canonical handler for the \code{State S}
interface.

\begin{lstlisting}
  runState : {<State S> X -> S -> X}
  runState <get -> k>   s = runState (k s) s
  runState <put s -> k> _ = runState (k unit) s
  runState x            _ = x
\end{lstlisting}

%% \noindent The type of \code{runState} expresses that the first argument is a
%% computation that can perform \code{State S} effects and will eventually return a
%% value of type \code{X}, whilst the second argument is a value of type \code{S}.

\noindent Observe that the type of \code{runState} contains \code{<State S>},
called an \emph{adjustment}. This expresses that the first argument can perform
commands in the \code{State S} interface, and that \code{runState} must handle
these commands if they occur.

\subparagraph*{Computation Patterns} The second and third lines specify how we
handle \code{get} and \code{put} commands. Observe that we use a new type of
pattern, called a \emph{computation pattern}; these are made up of a command and
some arguments (which are also values), plus the continuation of the calling
code. The types of arguments and the continuation are determined by the
interface declaration and the type of the handler; for instance, in \code{<get
  -> k>} the type of \code{k} is \code{\{S -> [State S] X\}}. The continuation
can then perform more \code{State S} effects. This differs to some other
implementations of effect handling languages (\cite{kammar2013handlers}) where
the handlers can be \emph{deep}, meaning the continuation has been re-handled by
the same handler automatically. Frank's \emph{shallow} handlers mean we have to
explicitly re-handle the continuation, but have the benefit of giving more
control over how we would like to do so.

%% What happens when we run \code{runState xplusplus! 0}? When a computation is
%% invoked, it is performed until it results in either a \emph{value} or a
%% \emph{command}. Thus, \code{runState} will be paused until \code{xplusplus!}
%% reduces; \code{runState} is resumed when \code{xplusplus} is in one of these two
%% forms.

%% \code{xplusplus} instantly invokes \code{get!}. At this point, control is given
%% to the handler \code{runState}; both in the sense that \code{runState} is now
%% being executed by the interpreter, and that \code{runState} has control over the
%% \emph{continuation} of \code{xplusplus}, which is a function of type \code{Int
%%   -> [State Int] Unit}. We see that \code{runState} chooses to resume this
%% continuation with the value of the state at that time.

\paragraph*{Effect Forwarding}

Effects that are not handled by a particular handler are left to be forwarded up
to the next one. For instance, we might want to write a random number to the
state;

\begin{lstlisting}
  xplusrand : {[State Int, RandomInt] Unit}
  xplusrand! = put (get! + random!)
\end{lstlisting}

\noindent We then have to handle both the \code{State Int} and \code{Random}
effect in this computation. Of course, we could just define one handler for both
effects; however in the interests of \emph{modularity} we want to define two
different handlers for each effect and \emph{compose} them. We can reuse the
same \code{runState} handler from before, and define a new handler for
\code{RandomInt} to generate pseudorandom numbers;

\begin{lstlisting}
  runRand : {Int -> <RandomInt> X -> X}
  runRand seed <random -> k> = runRand (mod (seed + 7) 10) (k seed)
  runRand _ x = x
\end{lstlisting}

\noindent And compose them in the comfortable manner, by writing \code{runRand
  (runState xplusrand!)}.

% Observe that the interaction between \code{xplusrand} and the handlers becomes
% like a conversation; the caller asks the handler for a result and waits,
% blocking, until the handler responds. We can characterise this as
% \emph{synchronous} effect handling. But what if we want to make a request for
% information --- such as the pseudorandom number --- and do something else, then
% pick it up later? We cannot just invoke \code{random} as this would block whilst
% the number is generated, which could possibly take a long time. This
% \emph{asynchronous} behaviour is exactly what we look for in this project.

% \todo{Maybe show example of how the order of composition can change the ending
%   semantics --- a la state + aborting}

\paragraph*{Top-Level Effects}
Some effects need to be handled outside of pure Frank, as Frank is not
expressive or capable enough on its own. Examples are console I/O, web requests,
and ML-style state cells. These effects will pass through the whole stack of
handlers up to the top-level, at which point they are handled by the
interpreter.



\paragraph*{Implicit Effect Polymorphism}

Consider the type of the well-known function \code{map} in Frank;

\begin{lstlisting}
  map : {{X -> Y} -> List X -> List Y}
  map f [] = []
  map f (x :: xs) = (f x) :: (map f xs)
\end{lstlisting}

\noindent One might expect that the program \code{map \{_ -> random!\} [1, 2, 3]}
would give a type error; we are mapping a function of type \code{\{Int ->
  [RandomInt] Int\}}, which does not match the argument type \code{\{X -> Y\}}.
However, Frank uses a shorthand for \emph{implicit effect variables}. The
desugared type of \code{map} is actually

\begin{lstlisting}[mathescape]
  map : {{X -> [$\epsilon$|] Y} -> List X -> [$\epsilon$|] List Y}
\end{lstlisting}

\noindent This type expresses that whatever the ability is of \code{map f xs} will be
offered to the element-wise operator \code{f}. As such, the following
typechecks;

\begin{lstlisting}
  writeRand : {List Int -> [RandomInt] List Int}
  writeRand xs = map {_ -> random!} xs
\end{lstlisting}

%% \todo{Talk about deliberately stopping this}

%% \todo{Talk about what the bar means. }

A similar thing happens in interface declarations. We might define the
\code{Choose} effect, which non-deterministically asks for one of two
computations to be picked for it to continue with;

\begin{lstlisting}
  interface Choose X =
      choose : {[Choose X] X} -> {[Choose X] X} -> X
\end{lstlisting}

\noindent This definition desugars to

\begin{lstlisting}[mathescape]
  interface Choose X [$\epsilon$] =
      choose : {[$\epsilon$| Choose X] X} -> {[$\epsilon$| Choose X] X} -> X
\end{lstlisting}

\noindent Once again, an implicit effect variable is inserted in every ability
available.

%% \paragraph*{Synchronicity and Conversations}
%% Observe how the interaction between the effect invoking function and the handler
%% of this effect becomes like a conversation; the caller asks the handler for a
%% response to an operation, and the caller will then wait, blocking, for a
%% response. We characterise this as \emph{synchronous} effect handling; the
%% operation caller and the handler synchronise to communicate.

%% But what if we want to make a request for information, then do something else,
%% then pick up the result later when we need it? This is the canonical example of
%% asynchronous programming. It is not as simple as just invoking our e.g.
%% \code{getRequest} effect; computation would block once this is invoked, meaning
%% we are stuck waiting for the request to return. This sort of behaviour is
%% exactly what we want to explore in this project.

%% \todo{Move this elsewhere}

%% \paragraph*{Multihandlers}

%% Recall that in Frank pure functions are just the special case of handlers that
%% handle no effects. Naturally, this notion extends to the $n$-ary case; we can
%% handle multiple effects from different sources are once. Handlers which handle
%% multiple effects simultaneously are unsurprisingly called \emph{multihandlers}.
%% This lets us write functions such as \code{pipe} (example due to~\cite{convent2020doo});

%% \begin{lstlisting}[numbers=left]
%% interface Send X = send : X -> Unit
%% interface Receive X = receive : X
 
%% pipe : {<Send X>Unit -> <Receive X>Y -> [Abort]Y}
%% pipe <send x -> s> <receive -> r> = pipe (s unit) (r x)
%% pipe <_> y = y
%% pipe unit <_> = abort!
%% \end{lstlisting}

%% Line 5 states that \code{pipe} will handle all instances of the \code{Send}
%% effect in the first argument, all instances of the \code{Receive} effect in the
%% second, and might perform \code{Abort} commands along the way. The matching
%% clauses are also new to the reader; line 6 implements the communication between
%% the two functions. We reinvoke \code{pipe}, passing the payload \code{x} of
%% \code{send} to the continuation of \code{r}. Lines 7 and 8 make use of the
%% \emph{catch-all} pattern, \code{<m>}. This will match the invocation of any
%% effect that is handled by that argument, or a value, binding this to \code{m}.
%% In line 7, the catchall pattern matches either a \code{send} command or a value;
%% in this case, the receiver has produced a value, so we can return that. In line
%% 8 \code{<_>} matches either a value or a \code{receive}; but it must be a
%% \code{receive} command, as the value case would have been caught above. The
%% \code{abort} command is then invoked, as this is erroneous. A recovery strategy
%% can be implemented by a handler for \code{Abort}.

\paragraph*{Polymorphic Commands}

As well as having polymorphic interfaces, such as \code{State X}, parametrised
by e|.g.~the data stored in the state, Frank supports polymorphic
\emph{commands}. These are commands which can be instantiated for any type. An
example is ML-style references, realised through the \code{RefState} interface;

\begin{lstlisting}
interface RefState = new X   : X -> Ref X
                   | read X  : Ref X -> X
                   | write X : Ref X -> X -> Unit
\end{lstlisting}

\noindent For instance, \code{new X} can be instantiated by supplying a value as
an argument. A \code{Ref X} cell is then returned as answer.

\section{Case Study: Cooperative Concurrency}
\label{sec:concurrency}

%% Frank is a single-threaded language. It is fortunate, then, that effect handlers
%% give us a malleable way to run multiple program-threads ``simultaneously'' \todo
%% {This is poorly written --- fix}.

Effect handlers have proved to be useful abstractions for concurrent programming
(\cite{dolan2015effective, dolan2017concurrent, hillerstrom2016compilation}).
This is partly because the invocation of an operation not only offers up the
operation's payload, but also the \emph{continuation} of the calling
computation. In Frank, these continuations are first-class. The handler for this
operation is then free to do what it pleases with the continuation. For many
effects, such as \code{getState}, nothing interesting happens to the
continuation and it is just resumed immediately. But these continuations are
first-class; they can resumed, but also stored elsewhere or even thrown away.

We illustrate this with some examples of concurrency in this section.

%
%As such, by handling
%% \code{Yield} operations, we easily pause and switch between several threads.

\subsection{Simple Scheduling}
\label{subsec:simple-scheduling}

We introduce some simple programs and some scheduling multihandlers, to
demonstrate how subtly different handlers generate different scheduling
strategies.

\begin{lstlisting}
interface Yield = yield : Unit

words : {[Console, Yield] Unit}
words! = print "one "; yield!; print "two "; yield!; print "three "; yield!

numbers : {[Console, Yield] Unit}
numbers! = print "1 "; yield!; print "2 "; yield!; print "3 "; yield!
\end{lstlisting}

First note the simplicity of the \code{Yield} interface; we have one operation
supported, which looks very boring; the operation \code{yield!} will just return
unit. It is the way we \emph{handle} yield that is more interesting. These two
programs will print some information out and yield inbetween each print
operation.

We can write a \emph{multihandler} to schedule these two programs. A
multihandler is simply an operator that handles multiple effects from different
sources simultaneously.

\begin{lstlisting}[numbers=left]
schedule : {<Yield> Unit -> <Yield> Unit -> Unit}
schedule <yield -> m> <yield -> n> = schedule (m unit) (n unit)
schedule <yield -> m> <n> = schedule (m unit) n!
schedule <m> <yield -> n> = schedule m! (n unit)
schedule _ _ = unit
\end{lstlisting}

When we run \code{schedule words! numbers!} we read \code{one 1 two 2 three 3
  unit} from the console. What happened? First \code{words} is evaluated until
it results in a \code{yield} command. Recall that Frank is a left-to-right
call-by-value language; at this point, we start evaluating the second argument,
\code{numbers}. This again runs until a \code{yield} is performed, where we give
control again to the scheduler. Now that both arguments are commands or values
we can proceed with pattern matching; the first case matches and we resume both
threads, handling again. This process repeats until both threads evaluate to
\code{unit}. In this way, we can imagine multihandler arguments as running in
parallel and then \emph{synchronising} when pattern matching is performed.

If we omit line 2 we get quite a different result; the console output would be
\code{one 1 two three 2 3}. This is because both threads are first evaluated
until they are either a command or a value; this prints out \code{one 1}. Here
we see the first use of the catch-all pattern \code{<n>}, which matches either a
command or a value. At this point we resume the first thread, but the second
thread remains blocked as the \code{yield} invocation has not been handled. We
evaluate the first thread until it is \code{unit}, at which point we do the same
to the second thread.

%% If we omit the first line of pattern matching (line 2) we get quite a different
%% result; the console output would be \code{one 1 two three 2 3}. This is because
%% both threads are evaluated until they are \code{yield} invocations, printing out
%% \code{one 1}; but then only the first thread is resumed. We then evaluate
%% \code{words} until it becomes a \code{unit} value. At this point the patterns on
%% line 4 match, as the catchall pattern \code{<m>} will match commands or values.
%% We then evaluate \code{numbers} until this is also \code{unit}.

%% \begin{lstlisting}
%% -- Runs all of the LHS first, then the RHS.
%% scheduleA : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleA <yield -> m> <n> = scheduleA (m unit) n!
%% scheduleA <m> <yield -> n> = scheduleA m! (n unit)
%% scheduleA _ _ = unit

%% -- Lets two yields synchronise, then handles both
%% scheduleB : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleB <yield -> m> <yield -> n> = scheduleB (m unit) (n unit)
%% scheduleB <yield -> m> <n> = scheduleB (m unit) n!
%% scheduleB <m> <yield -> n> = scheduleB m! (n unit)
%% scheduleB _ _ = unit
%% \end{lstlisting}

%% \todo{Can maybe delete the 2nd and 3rd matches of scheduleB to make the point
%%   more clear?}

%% We see two multihandlers above. Each take two \code{yield}ing threads and
%% schedule them, letting one run at a time. \code{scheduleA} runs the first thread
%% to completion, and only then runs the second one; the first time that the second
%% thread \code{yield}s it is \emph{blocked}, and can no longer execute. As such,
%% the output of \code{scheduleA words! numbers!} is \code{one 1 two three 2 3
%%   unit}.

%% \code{scheduleB} is fairer and more profound. We run \code{scheduleB words!
%%   number!} and receive \code{one 1 two 2 three 3 unit}; \code{scheduleB} is fair
%% and will ``match'' the yields together. We step through slowly. First
%% \code{words!} will print \code{one}, then it will \code{yield}. At this point
%% --- recalling that multihandlers pattern match left-to-right --- the second
%% thread, \code{numbers!}, is allowed to execute. In the meantime, \code{words!}
%% is stuck as \code{<yield -> m>}; it cannot evaluate any further, it is
%% \emph{blocked}. Whilst \code{words} is blocked \code{numbers!} prints \code{1}
%% and then \code{yield}s. Great; now the first case matches. Both threads are
%% resumed and the process repeats itself.

%% \todo{ The second paragraph here is a more compelling explanation; maybe we can
%%   just get rid of all of the scheduleA business and /just/ have the scheduleB
%%   stuff? scheduleA is quite obvious i think whilst B is more subtle and compelling. }

%% \todo{ It's not true that it matches L-R as much as runs all computations L - R
%%   until they are all a command / value - fix this }

\subsection{Forking New Processes}
\label{subsec:forking-new-processes}

We can make use of Frank's higher-order effects to dynamically create new
threads at runtime. We strengthen the \code{Yield} interface by adding a new
operation \code{fork};

\begin{lstlisting}
  interface Co = fork : {[Co] Unit} -> Unit
               | yield : Unit
\end{lstlisting}

The type of \code{fork} expresses that \code{fork} takes a suspended computation
that can perform further \code{Co} effects, and returns unit when handled. We
can now run programs that allocate new threads at runtime, such as the below

\begin{lstlisting}
forker : {[Console, Co [Console]] Unit}
forker! = print "Starting! ";
          fork {print "one "; yield!; print "two "};
          fork {print "1 "; yield!; print "2 "};
          exit!
\end{lstlisting}

We can now choose a strategy for handling \code{fork} operations; we can either
lazily run them, by continuing our current thread and then running them, or
eagerly run them, suspending the currently executing thread and running the
forked process straight away. The handler for the former, breadth-first style of
scheduling, is;

\begin{lstlisting}
scheduleBF : {<Co> Unit -> [Queue Proc] Unit}
scheduleBF <fork p -> k> = enqueue {scheduleBF (<Queue> p!)};
                           scheduleBF (k unit)
scheduleBF <yield -> k>  = enqueue {scheduleBF (k unit)};
                           runNext!
scheduleBF unit          = runNext!
\end{lstlisting}

\noindent where the operations \code{enqueue} and \code{runNext} are offered by
the \code{Queue} effect. We have to handle the computation \code{scheduleBF
  forker!} with a handler for \code{Queue} effects afterwards. We can abstract
over different queue handlers for even more possible program combinations.
Moreover, notice how concisely we can express the scheduler; this is due to the
handler having access to te continuation of the caller, and treating it as a
first-class object that can be stored elsewhere.

% We can see a diagram of how
% \code{scheduleBF} treats continuations in Figure~\ref{fig:scheduleBF}, and a
% similar diagram of how the depth-first handling differs in
% Figure~\ref{fig:scheduleDF}.

%% \begin{figure}
%%   \centering
%%   \begin{subfigure}
%%     \includegraphics[width=0.8\textwidth]{imgs/scheduleBF.png}
%%     \caption{Breadth-First scheduling}\label{fig:scheduleBF}
%%   \end{subfigure}
%%   \begin{subfigure}
%%     \includegraphics[width=0.8\textwidth]{imgs/scheduleDF.png}
%%     \caption{Depth-First scheduling}\label{fig:scheduleDF}
%%   \end{subfigure}
%% \end{figure}

\chapter{Formalisation of Frank}
\label{chap:formalisation}

The formalisation of the Frank language has been discussed at length in previous
work~(\cite{convent2020doo}). However, in order to illustrate changes made to
the language in this work, we explain some of the relevant parts of the
language.

\begin{figure}[h]  %\figrule
\scalebox{\figscale}{%
\[
\ba{@{}c@{}}
\ba{@{}c@{\quad\quad}c@{}}
\begin{syn}
  \slab{data types}            & D \\
  \slab{value type variables}  & X \\
  \slab{effect type variables} & E \\
  \slab{value types}           & A, B   &::= & D~\overline{R} \\
                               &        &\gor& \thunk{C} \gor X \\
  \slab{computation types}     & C      &::= & \many{T \to}~G \\
  \slab{argument types}        & T      &::= & \effin{\adj}A \\
  \slab{return types}          & G      &::= & \effout{\sigs}A \\

  \slab{type binders}          & Z      &::= & X \gor [E]\\
  \slab{type arguments}        & R      &::= & A \gor [\Sigma]\\
  \slab{polytypes}             & P      &::= & \forall \overline{Z}.A \\
\end{syn}
&
\begin{syn}
  \slab{interfaces}           & I \\
  \slab{term variables}       & x, y, z, f \\
  \slab{instance variables}   & \pid, a, b, c \\
  \slab{seeds}                & \seed  &::= & \nowt \gor \ev \\
  \slab{abilities}            & \sigs  &::= & \seed\pipe\ext \\
  \slab{extensions}           & \ext   &::= & \id \gor \ext, \sig~\many{R} \\
  \slab{adaptors}             & \adapt &::= & \id \gor \adapt, \sig(S \to S') \\
  \slab{adjustments}          & \adj   &::= & \adapt\pipe\ext \\
  \slab{instance patterns}    & S      &::= & \pid \gor S \snoc a \\
  \slab{kind environments}    & \kenv,
                                \kenva &::= & \cdot \gor \kenv, Z \\
  \slab{type environments}    & \Gamma &::= & \cdot \gor \Gamma, x:A %\\
%                              &        &    & \hphantom{\cdot}
                                              \gor \Gamma, f:P\\
 \slab{instance environments} & \ienv  &::= & \pid:\sigs \gor \ienv, a:\sig~\many{R}\\
\end{syn} \\
\ea \\
\ea
\]}
%% \\[0.25cm]

\caption{Types}
\label{fig:types}
%\figrule
\end{figure}

\paragraph*{Types}
Value types are either datatypes instantiated with type arguments
$D~\overline{R}$, thunked computations $\thunk{C}$, or value type variables $X$.
%
Computation types are of the form

\[
  C = \effin{\adapt_1\pipe\ext_1}A_1 \to \dots \to \effout{\sigs} B
\]

\noindent where a computation of type $C$ handles effects in $\ext_i$ or pattern
matches in $A_i$ on the $i$-th argument and returns a value of type $B$. $C$ may
perform effects in ability $\sigs$ along the way.
%
The $i$-th argument to $C$ can perform effects in $\sigs$ adapted by adaptor
$\adapt_i$ and augmented by extension $\ext_i$.

An ability $\sigs$ is an extension $\ext$ plus a seed, which can be closed
($\nowt$) or open $\ev$. This lets us explicitly choose whether a function can
be effect polymorphic, as discussed earlier. An extension $\ext$ is a finite
list of interfaces.

%% We deliberately leave out details on adaptors for the sake of brevity. We also
%% skip over the typing rules, as they are standard. These can be seen in the
%% appendix.

We omit details on adaptors as they are present in previous work
(\cite{convent2020doo}). The same goes for the typing rules, which we do not
change.

\begin{figure} %\figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
  %% \slab{monomorphic term variables} & x, y, z \\
  %% \slab{polymorphic term variables} & f \\
  \slab{constructors}               & k \\
  \slab{commands}                   & c \\
  \slab{uses}                 & m      &::= &
     x \gor f~\many{R} \gor m~\many{n} \gor \cu(n:A) \\
  \slab{constructions}        & n      &::= &
    \uc m \gor k~\many{n} \gor c~\many{R}~\many{n} \gor \thunk{e} \\
                              &        &\gor& \key{let}~f : P = n~\key{in}~n'
                                   \gor
                                   \key{letrec}~\many{f : P = e}~\key{in}~n \\
                              &        &\gor&  \effin{\adapt}~n \\
  \slab{computations}         & e      &::=& \many{\many{r} \mapsto n}
  \\
  \slab{computation patterns} & r      &::=& p
                                        \gor \effin{\handle{c~\many{p}\,}{z}}
                                        \gor \effin{x} \\
  \slab{value patterns}       & p      &::=& k~\many{p} \gor x        \\
\end{syntax}
}
%% \\[0.25cm]
%\textit{with} term variables $x$, $y$, $z$, polymorphic term variables $f$, constructors $k$, commands $c$\\[0.25cm]
\caption{Terms}
\label{fig:terms}
% \figrule
\end{figure}

\paragraph*{Terms} Frank uses bidirectional typing (\cite{pierce2000local}); as such, terms are
split into \emph{uses} whose types are inferred, and \emph{constructions}, which
are checked against a type. Uses are monomorphic variables $x$, polymorphic
variable instantiations $f~\many{R}$, applications $m~\many{n}$ and type
ascriptions $\cu(n:A)$. Constructions are made up of uses $\uc m$, data
constructor instances $k~\many{n}$, suspended computations $\thunk{e}$, let
bindings $\key{let}~f : P = n~\key{in}~n'$, recursive let $\key{letrec}~\many{f
  : P = e}~\key{in}~n$ and adaptors $\effin{\adapt}~n$. We can inject a use into
a construction and vice versa ($\uc$, $\cu$); in real Frank code these are not
present.

Computations are produced by a sequence of pattern matching clauses. Each
pattern matching clause takes a sequence $\many{r}$ of computation patterns.
These can either be a request pattern $\effin{\handle{c~\many{p}\,}{z}}$, a
catch-all pattern $\effin{x}$, or a standard value pattern $p$. Value patterns
are made up of data constructor patterns $k~\many{p}$ or variable patterns $x$.

\paragraph*{Runtime Syntax}

The operational semantics uses the runtime syntax of
Figure~\ref{fig:runtime-syntax}.
%
Uses and constructions are further divided into those which are values. Values
are either variable or datatype instantiations, or suspended computations.
%
We also declare a new class of \emph{normal forms}, to be used in pattern
binding. These are either construction values or \emph{frozen commands},
$\freeze{\EC[c~\many{R}~\many{w}]}$.
%
%% with a special term $\freeze{\EC[c~\many{R}~\many{w}]}$, of \emph{frozen
%%   commands}. We discuss these further later.
Frozen commands are used to capture a continuation's \emph{delimited
  continuation}. As soon as a command is invoked it becomes frozen. The entire
rest of the computation around the frozen command then also freezes (in the same
way that water behaves around ice), until we reach a handler for the frozen
command.

Finally we have evaluation contexts, which are sequences of evaluation frames.
The interesting case is $u~(\many{t}, [~],\many{n})$; it is this that gives us
left-to-right call-by-value evaluation of multihandler arguments.

\begin{figure}[t]
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{constructions}           & n   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}
\caption{Runtime Syntax}
\label{fig:runtime-syntax}
%% \figrule
\end{figure}

\paragraph*{Operational Semantics} Finally, the operational semantics are given
in Figure~\ref{fig:operational-semantics}.

The essential rule here is \textsc{R-Handle}. This relies on a new relations
regarding \emph{pattern binding} (Figure~\ref{fig:pattern-binding}).
$\bindsc{r}{T}{t}{\sigs}{\venv}$ states that the computation pattern $r$ of type
$T$ at ability $\sigs$ matches the normal form $t$ yielding substitution
$\venv$. The index $k$ is then the index of the earliest line of pattern matches
that all match. The conclusion of the rule states that we then perform the
substitutions $\many{\venv}$ that we get on the return value $n_k$ to get our
result. This is given type $B$.

\textsc{R-Ascribe-Use} and \textsc{R-Ascribe-Cons} remove unneeded conversions
from use to construction. \textsc{R-Let} and \textsc{R-LetRec} are standard.
\textsc{R-Adapt} shows that an adaptor applied to a value is the identity.

We have several rules regarding the freezing of commands. When handling a
command, we need to capture its delimited continuation; that is, the largest
enclosing evaluation context that does \emph{not} handle it.
\textsc{R-Freeze-Comm} expresses that invoked commands instantly become frozen;
\textsc{R-Freeze-Frame-Use} and \textsc{R-Freeze-Frame-Cons} show how the rest
of the context becomes frozen. These two rules rely on the predicate $\EC~
\textsf{handles}~c$. This is true if the context does indeed handle the
command $c$; i.e.\ it is a context of the form $u~(\many{t}, [~], \many{u'})$
where $u$ is a handler that handles $c$ at the index corresponding to the hole.
Thus, the whole term is frozen up to the first handler, at which point is it
handled with \textsc{R-Handle}.

The $\textsc{R-Lift}$ rules then express that we can perform any of these
reductions in any evaluation context.

\begin{figure}
%% \figrule
\flushleft
\scalebox{\figscale}{%
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
    \stepstou m'} \quad \boxed{n \stepstoc n'}$}

\centering
\scalebox{\figscale}{%
\\
\begin{mathpar}
\inferrule[R-Handle]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A \to}~\effout{\sigs}B})~\many{t} \redtou \cu ((\many{\venv}(n_k) : B)}

\inferrule[R-Ascribe-Use]
  { }
  {\cu(\uc u:A) \redtou u}

\inferrule[R-Ascribe-Cons]
  { }
  {\uc \cu (w : A) \redtoc w}

\inferrule[R-Let]
  { }
  {\key{let}~f:P = w~\key{in}~n \redtoc n[\cu (w : P)/f]}

\inferrule[R-LetRec]
  {\many{e = \many{\many{r} \to n}}}
  {%\vphantom{\many{\many{\many{\many{f}}}}}
   \key{letrec}~\many{f:P = e}~\key{in}~n' \redtoc
    n'[\many{\cu (\thunk{\many{\many{r} \to \key{letrec}~\many{f:P = e}~\key{in}~n}}: P)/f}]}

\inferrule[R-Adapt]
  { }
  {\effin{\adapt}~w \redtoc w}

\inferrule[R-Freeze-Comm]
  { }
  {c~\many{R}~\many{w} \redtoc \freeze{c~\many{R}~\many{w}}}\\

\inferrule[R-Freeze-Frame-Use]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtou \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\inferrule[R-Freeze-Frame-Cons]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtoc \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\\
\inferrule[R-Lift-UU]
  {m \redtou m'}
  {\EC[m] \stepstou \EC[m']}

\inferrule[R-Lift-UC]
  {m \redtou m'}
  {\EC[m] \stepstoc \EC[m']}

\inferrule[R-Lift-CU]
  {n \redtoc n'}
  {\EC[n] \stepstou \EC[n']}

\inferrule[R-Lift-CC]
  {n \redtoc n'}
  {\EC[n] \stepstoc \EC[n']}
\end{mathpar}
}

\caption{Operational Semantics}
\label{fig:operational-semantics}
%% \figrule
\end{figure}

\paragraph*{Pattern Binding}

We now discuss the pattern binding rules of Figure~\ref{fig:pattern-binding}.
The relation $\bindsv{p}{A}{w}{\venv}$ states that a value pattern $p$ of type $A$ matches normal form $w$ yielding substitution $\venv$. \textsc{B-Var} states that any pattern $w$ matches a value $x$, whilst \textsc{B-Data} states that a constructor pattern $k \many{w}$ matches a construction term $k \many{p}$ if each subpattern $p_{i}$ matches an argument to the construction $w_{i}$.


The rules regarding $\bindsc{r}{T}{t}{\sigs}{\venv}$ are more interesting. \textsc{B-Value} defers computation pattern matching onto value pattern matching. \textsc{B-Request} expresses that a computation pattern $\effin{c~\many{p} \to z}$ matches a frozen computation $\freeze{\EC[c~\many{R}~\many{w}]}$ if command $c$ is handled by the evaluation context $\EC$, and if the arguments to the command each match a subpattern in the computation pattern.

The catchall pattern \code{<x>} matches any value and any command that is handled by the current evaluation context; \textsc{B-CatchAll-Value} and \textsc{B-CatchAll-Request} express this. Observe that \textsc{B-CatchAll-Request} has the same constraints as \textsc{B-Request}; the computation pattern only matches a command if it could otherwise be handled.

\begin{figure}
%% \figrule
\flushleft
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
$\boxed{\bindsc{r}{T}{t}{\sigs}{\venv}}$
}


\centering
\scalebox{\figscale}{%
\begin{mathpar}
\inferrule[B-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\\\ \bindsv{p}{A}{w}{\venv}}
  {\bindsc{p}{\effin{\adj}A}{w}{\sigs}{\venv}}

  \inferrule[B-Request]
    {%I~\many{R} \in \ext \\ %\capturesI{\Delta}{I}{\iota}\\
    \adjact{\sigs}{\adj}{\sigs'} \\
    \EC \poised c \\\\
    \adj = \adapt\pipe\ext \\
    c : \forall \many{Z}. \many{B \to}~B' \in \ext \\
    (\bindsv{p_i}{B_i}{w_i}{\venv_i})_i}
    {\bindsc{\effin{c~\many{p} \to z}}{\effin{\adj}A}
    {\freeze{\EC[c~\many{R}~\many{w}]}}{\sigs}{\many{\venv}[\cu (\thunk{x \mapsto \EC[x]} : \thunk{B' \to \effout{\sigs'}A})/z]}}
\\
\inferrule[B-CatchAll-Value]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{w}{\sigs}{[\cu (\thunk{w}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\\
\inferrule[B-CatchAll-Request]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  \EC \poised c \\\\
  \adj = \adapt\pipe\ext \\
  c : \forall \many{Z}. \many{B \to}~B' \in \ext
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}

\end{mathpar}

}

\flushleft
%~~ \textit{Value pattern $p$ for type $A$ matches $w$ and binds $\venv$.}
%
\scalebox{\figscale}{%
  $\boxed{\bindsv{p}{A}{w}{\venv}}$
  }

\centering
\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[B-Var]
  { }
  {\bindsv{x}{A}{w}{[\cu (w : A)/x]}}

\inferrule[B-Data]
  {k~\many{A} \in D~\many{R} \\
   (\bindsv{p_i}{A_i}{w_i}{\venv_i})_i}
  {\bindsv{k~\many{p}}{D~\many{R}}{k~\many{w}}{\many{\venv}}}
\end{mathpar}
  }

\caption{Pattern Binding}
\label{fig:pattern-binding}
%% \figrule
\end{figure}



\chapter{Pre-emptive Concurrency}
\label{chap:preemptive-concurrency}

\section{Motivation}
\label{sec:interrupt-motivation}

Our scheduler in Section~\ref{sec:concurrency} relies on threads manually
\yield{}ing. This is fine for simple examples, but when working with more
complex programs this is inconvenient; the programmer must insert \yield{}s with
a consistent frequency, so as to avoid process starvation. Furthermore, if we
use external or library functions these will not hold yields, so will be
uninterruptible. It would be simpler and fairer to just use some automatic way of
\yield{}ing.

\todo{Redo above}

%% One important part of our asynchronous effect handling system is the ability to
%% interrupt arbitrary computations. If two threads are running concurrently and
%% are communicating with one another, we have to stop running one to let messages
%% come in from the other. This is achievable with explicitly yielding, as in
%% Section~\ref{sec:concurrency}, however we would prefer for this behaviour to be
%% done automatically.

Consider the two programs below;

\begin{lstlisting}
interface Stop = stop : Unit
interface Go = go : Unit

controller : {[Stop, Go, Console] Unit}
controller! =
    stop!; print "stop!" ; sleep 200000; go!; controller!

runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)
\end{lstlisting}

%% \noindent We ideally want a multihandler that can run these two programs in
%% parallel, such that the console output will be \code{1 stop 2 stop 3 stop}; that
%% is to say, the \code{stop} and \code{go} operations from \code{controller} can
%% control the execution of \code{runner}.

\noindent We want a multihandler that uses the \code{stop} and \code{go}
commands from \code{controller} to control the execution of \code{runner}. The desired console output is \code{1 2 3 ... (n-1) n stop! (n + 1) ...}, running infinitely.
% desired console output is some sequence of numbers with \code{stop} printed out
% in the middle every once in the

The problem as it stands is that there is no way for \code{runner} to be
suspended whilst it is running; it will just infinitely run, never giving
control to the handler or to \code{controller}.

% There
% are several possible interleavings of

% The console output
% of this multihandler should be then \code{1 stop 2 stop 3 stop}.
%
%We need
%% pre-emptive interruptions for this, as otherwise there would be no way for the
%% \code{stop} and \code{go} messages to be registered.

%% \section{Interruption with Yields}
%% \label{sec:yield-interruption}

%% One way we can get this behaviour is using the \code{Yield} interface. This
%% offers a single operation, \code{yield : Unit}. With this, we can write a
%% multihandler \code{suspend};

% We can simulate this behaviour by using the familiar \code{Yield} interface from
% Section~\ref{subsec:simple-scheduling}.

As an example, we show how we can approximate the desired behaviour using the familiar \code{Yield} interface from Section~\ref{subsec:simple-scheduling}.

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; yield!: runner (x + 1)

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

% \noindent Running \code{suspend runner! controller! nothing} then prints out
% \code{1 stop 2 stop 3} as desired.
\noindent Running \code{suspend (runner 0) controller! nothing} then prints out
\code{1 stop 2 stop 3 stop ...}.
%
This is due to the same synchronisation behaviour that we saw in
Section~\ref{subsec:simple-scheduling}; \code{runner} is evaluated until it
becomes a command or a value, and then \code{controller} is given the same
treatment. Once both are a command or a value, pattern matching is done.

In this way we use \yield~commands to split up our computations and let
processing time be given to other computations. The closest handler for
\yield~operations then gets access to the continuation of \code{runner} and can
choose how to handle it.

We are, however, still operating co-operatively; the programmer has to manually
insert \yield~commands. Furthermore, in this case we \yield~far too often; it would be more efficient to have a consistent, yet longer, period in between each \yield~command.
%
As such, we continue searching for a better solution.

\section{Relaxing Catches}
\label{sec:relaxing-catches}

One approach is to relax the rules for pattern matching with the catchall
pattern $\effin{x}$. This would let us match generic commands that may not be
handled by the current handler. The key to implementing this lies in the pattern
binding rules of Figure~\ref{fig:pattern-binding}; specifically
\textsc{B-CatchAll-Request}.

%% The key to this lies in the catchall pattern, $\effin{x}$, and the pattern
%% binding rules of Figure~\ref{fig:pattern-binding}; specifically
%% \textsc{B-CatchAll-Request}. %We quickly go into detail on this rule now.
%
%% $\effin{x} : {\effin{\adj}A}$ states that $\effin{x}$ is a term with value type
%% $A$ and \emph{adjustment} $\adj = \adapt\pipe\ext$, made up of an adaptor
%% $\adapt$ and an extension $\ext$. This extension is made up of a list of
%% interface instantiations $\sig~\many{R}$.

The crux is that the command $c$ that is invoked in the frozen term
$\freeze{\EC[c~\many{R}~\many{w}]}$ must be a command offered by the extension
$\ext$; that is, it must be handled by the current use of \textsc{R-Handle}.
Refer back to the example of Section~\ref{sec:interruption-motivation}. This
rule means that the catch-all pattern \code{<_>} in the final pattern matching
case of \code{suspend} can match against \code{stop} or \code{go}, as they are
present in the extension of the second argument, but not \code{print} commands;
although the \code{Console} interface is present in the ability of
\code{controller}, it is not in the extension in \code{suspend}.



\begin{figure}[h]
%% \figrule
%% \flushleft
%% \centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
\begin{mathpar}
%% \\

\inferrule[B-CatchAll-Request-Loose]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  \xcancel{\EC \poised c} \\
  \xcancel{\adj = \adapt\pipe\ext} \\
  \xcancel{c : \forall \many{Z}. \many{B \to}~B' \in \ext}
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}
\caption{Updated \textsc{B-CatchAll-Request}}
\label{fig:loose-catchall-request}
%% \figrule
\end{figure}

In the interests of pre-emption, we propose to remove this constraint from
\textsc{B-CatchAll-Request}, replacing the rule with
\textsc{B-CatchAll-Request-Loose} as seen in
Figure~\ref{fig:loose-catchall-request}. The key constraint that has been
removed is $c : \forall \many{Z}. \many{B \to}~B' \in \ext$, which requires that
the frozen command must be present in the argument extension $\ext$. The
constraint $\EC \poised c$ just states that the evaluation context containing
the frozen command will handle $c$; we do away with this, as we do not
necessarily want to handle the command here.

% This lets us update the previous
% \code{suspend} code to the following, which yields the same results as last
% time;

This lets us change \code{runner} back to its original form, and update \code{suspend} like so;

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)

suspend : {Unit -> <Stop, Go> Unit
    -> Maybe {[Console] Unit} -> [Console] Unit}
suspend <r> <stop -> c> _ =
    suspend unit (c unit) (just r)
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

\noindent Now when we run \code{suspend (runner 0) controller! nothing}, the
\code{suspend} handler can match the catchall pattern \code{<r>} against the
\code{print} commands in \code{runner}. This prints out \code{1 stop! 2 stop! 3
  stop! ...} as before.

The no-snooping policy with respect to effect handlers (\cite{convent2020doo})
states that a handler should not be able to intercept effects that it does not
handle. This change breaks this policy, as we can now tell when an command is
used. Whilst we can not handle it as per usual, we get the option to throw away
the continuation. A system that does not allow for snooping is much preferred.

\todo{Either flesh this out or remove it}

\section{Freezing Arbitrary Terms}
\label{sec:freezing-terms}

The approach of Section~\ref{sec:relaxing-catches} can only interrupt command
invocations. If \code{runner} were instead a sequence of pure computations ---
such as \code{1 + 1; 1 + 1; 1 + 1} --- we would be unable to interrupt it.

As such, we make a more significant change to the semantics of Frank. We adapt
the syntax so that \emph{any} term may become frozen, and not just commands;
this is reflected in Figure~\ref{fig:runtime-syntax-freeze}. In
Figure~\ref{fig:freezing} we see additional rules for freezing arbitrary
\emph{uses} and the surrounding computations. We can freeze arbitrary
\emph{constructions} in an identical fashion, substituting $m$ for $n$. These
rules rely on an extra predicate $\EF \textsf{ not handler }$, which is true
unless $\EF$ is of the form $u~(\many{t}, [~], \many{n})$. Frozen terms behave
very much like frozen commands, freezing the entire computation up to the
nearest handler. Finally, we supplement the pattern binding rules with the rule
in Figure~\ref{fig:catchall-freeze}, which shows how a computation becomes
unfrozen. A frozen computation $\freeze{m}$ can match against the catchall
pattern $\effin{x}$; the suspended, thawed computation $\thunk{m}$ is then bound
to $x$ in the continuation.


\begin{figure}
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & {\dots} \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{constructions}           & n   &::= & \dots \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}}\\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}

\caption{Runtime Syntax, Updated with Freezing of Uses}
\label{fig:runtime-syntax-freeze}
%% \figrule
\end{figure}


\begin{figure}
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'}$
}

\scalebox{\figscale}{%
\centering
\begin{mathpar}

\inferrule[R-Freeze-Use]
  {  }
  { m \redtou \freeze{m} }

\inferrule[R-Freeze-Frame-Use]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtou \freeze{\EF[\EC[m]]} }

\inferrule[R-Freeze-Frame-Cons]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtoc \freeze{\EF[\EC[m]]} }

\end{mathpar}
}

\caption{Freezing Uses}
\label{fig:freezing}
%% \figrule
\end{figure}

\begin{figure}
%% \figrule
\flushleft

\scalebox{\figscale}{%
\centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\begin{mathpar}

\inferrule[B-CatchAll-Freeze-Use]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{\freeze{m}}{\sigs}{[\cu (\thunk{m}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}

\caption{Thawing Computations.}
\label{fig:catchall-freeze}
%% \figrule
\end{figure}

% Note that frozen terms here behave in a similar way to frozen commands, by
% freezing the rest of the term around it as well. This continues up until a
% handler is reached, at which point the term is unfrozen and resumed. This
% process of freezing up to a handler is enforced by the predicate $\EF \textsf{
%   not handler }$, which is true only when $\EF$ is of the form $u~(\many{t},
% [~], \many{n})$.

% With this in mind, we now give the updated rule for the catchall pattern
% matching on frozen terms. This can be seen in Figure \ref{fig:catchall-freeze}.
% It expresses that an arbitrary frozen term can be matched against the
% computation pattern $\effin{x}$. The suspended, unfrozen computation $\thunk{m}$
% is then bound to $x$, in a similar way to other \textsc{B-CatchAll} rules.
% Observe that this maintains no-snooping; we don't know that the frozen
% computation performed an effect.



%% \begin{lstlisting}
%% suspend : {Unit -> <Stop, Go> Unit -> Maybe {[Console] Unit} -> [Console] Unit}
%% suspend <r> <stop -> c> _ =
%%     suspend unit (c unit) (just r)
%% suspend <_>          <go -> c>   (just res) =
%%     suspend res! (c unit) nothing
%% suspend unit         <_>         _ = unit
%% \end{lstlisting}

We can simply reuse the \code{suspend} handler from
Section~\ref{sec:relaxing-catches}. Everything works largely the same; we run
the leftmost argument until it freezes, invokes a command or is a value, at
which point we start evaluating the next argument. The frozen term can then be
bound to the catch-all pattern, if this is the pattern that matches.

However, observe that the frozen term is automatically rehandled at the closest
handler. This is problematic; if we had a handler for another effect, such as
\code{state}, before the \code{suspend} handler. In this case, the handler below
would automatically resume \code{runner} when it freezes; we would still have
the same problem, as control would never rise to \code{suspend}. This problem
would be solved if we had finer-grained control over when to resume a frozen
computation.

\todo{Rewrite above paragraph}

\section{Yielding}
\label{sec:inserting-yields}

Observe that the freezing approach of Section~\ref{sec:freezing-terms} ends up
reimplementing a lot of the behaviour of the freezing of ordinary commands,
without adding much new behaviour. Furthermore, the term gets automatically
unfrozen at the closest handler, severely limiting control over computations. It
turns out that we can get the exact same behaviour by just inserting a command
invocation into the term instead, and handling this as normal.
%

Once again, the simple $\Yield = \yield : \textsf{Unit}$ interface from
Section~\ref{sec:concurrency} can be used here. Whilst the interface itself
sounds very boring, its use here comes from the fact it freezes the rest of the
computation around it up until the next \Yield~handler.
% Recall the simple \Yield~effect from Section~\ref{sec:concurrency}; it
% supports one operation, $\yield : \textsf{Unit}$.
% %
% Whilst it sounds boring from the type, remember that the invocation of an effect
% offers up the continuation of the program as a first-class value, so that they
% might concurrently run the function with other functions or control execution by
% some other means.

% Our solution is simple; whenever we are in an evaluation context where the
% ability contains the \Yield effect, we insert an invocation of \yield before the
% term in question. This is expressed formally in Figure~\ref{fig:insert-yield}.
% We refer to this system as \nondetfrank.

Our new system is simple; whenever a term reduces underneath a handler for
\Yield effects, we insert an invocation of the \yield command before the reduct.
This is expressed formally in Figure~\ref{fig:insert-yield}. We refer to
'normal' Frank, as described in Chapter~\ref{chap:formalisation}, supplemented
with this rule as \nondetfrank.

% \todo{Add rules for eval ctxs converting use to const, use to use, etc}

\begin{figure}[h]
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{n \redtou n'} $
}

\scalebox{\figscale}{%
\begin{mathpar}
%

\inferrule[R-Yield]
{ n \redtoc n' \\
  \EF~\textsf{allows}~\yield }
          { \EF[n] \redtou \EF[\textsf{yield}!; n] }
\end{mathpar}
}
%
%
\caption{Inserting Yields}
\label{fig:insert-yield}
%% \figrule
\end{figure}

Note that \textsc{R-Yield-EF} relies on the predicate $\EF~\allows~c$. For any
frame apart from argument frames (i.e. $u (\many{t}, [~], \many{n})$),
$\EF~\allows~c = \textsf{false}$. In this case, it is defined as follows;

\begin{align*}
  \cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},[~],\many{n})~\allows~c =
  &~\ext_{|\many{t}|}~\allows~c ~ \\
  & \text{where}~\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|} \\
  \_\_\_~(\many{t}, [~], \many{n}) \allows c =& \textsf{false}
  %\adjact{\sigs}{\adj_{|\many{t}|}}{\sigs'}
\end{align*}

\todo{Fix long underscore}

%% \noindent For an ability $\sigs = \seed\pipe\ext$, the predicate $\sigs~ \allows~c$ is true if
%% $c \in I$ for some $I \in \ext$.

\noindent For an extension $\ext$, the predicate $\ext~\allows~c$ is true if $c
\in I$ for some $I \in \ext$.

Informally, $\EF~\allows~c$ is true when $\EF$ is a handler, and the extension at
the hole contains an interface which offers \yield~as a command. For instance,
if a handler had type \code{\{<Yield>X -> Y -> [Yield]X\}}, the first argument
would be allowed to yield but the second would not.

We also make use of an auxiliary combinator $\_ ; \_$. This is the traditional
sequential composition operator $\textsf{snd}~x~y~\mapsto~y$, where both
arguments are evaluated and the result of the second one is returned. We see
that it would be a type error if we were to insert a \code{yield} command in a
context where \yield~was not a part of the ability. In the context of
\textsc{R-Yield-EF} this means we will perform the \yield~operation and then the
use $m$, but discard the result from \yield.

Observe that this gives us fine-grained control over which parts of our program
are pre-emptible.
% One might want a short-running function to not be pre-emptible
% and just run without pause; conversely, one might want a long-running function
% to be interruptible.
The programmer can easily toggle this by labelling the pre-emptible threads with
\yield in the ability. This is one improvement over the system of
Section~\ref{sec:freezing-terms}; previously every thread was interruptible.
Another benefit is that we define fewer new rules and constructs. We also
benefit from the choice of when to resume a computation; in the previous system
computations were automatically unfrozen at the nearest handler, but this
problem is fixed in \nondetfrank. Finally, we can write custom handlers for
\yield~commands, whilst the unfreezing rules in Figure~\ref{fig:catchall-freeze}
was fixed at just restarting the continuation.

%% \todo{Talk about how this differs to the Freezing system}.

\paragraph*{Nondeterminism}

This system, and the system from Section~\ref{sec:freezing-terms}, are both
nondeterministic. This is because at any point we have the opportunity to either
invoke yield (respectively freeze the term), or continue as before.

Consider running \code{hdl (print "A") (print "B")}, for some binary
multihandler \code{hdl}. We could evaluate
\code{print "A"} first and then \code{print "B"}, or freeze \code{print "A"} and
evaluate \code{print "B"} first. Both of these would obviously result in
different things being printed to the console.

\section{Counting}
\label{sec:counting}


%% The semantics given by Section~\ref{sec:inserting-yields} is fine, but is
%% non-deterministic; at any point, we can choose to either insert a \yield
%% invocation or carry on as normal. Furthermore, we do not particularly need to
%% yield very frequently; we might rather yield every 1000 reduction steps or so.

The system described in Section~\ref{sec:inserting-yields} is slightly
problematic; we can insert a \yield whenever we want. If we spend too much time
inserting and handling \yield commands little other computation will be done.
Furthermore, it is non-deterministic; we often have the choice of either
\yield{}ing or reducing as normal. We need a way to decide whether or not to
\yield.

% \todo{It's not problematic; it's just not practical}

To combat this we supplement the operational semantics with a counter
$\counter$. This counter has two states; it could either be counting up, which
is the form $\justc{n}$ for some $n$, or it is a signal to yield as soon as
possible, which is the form $\yieldc$. To increment this counter, we use a
slightly modified version of addition, denoted $\plusc$. This is simply defined
as

\begin{equations}
  x \plusc y =
          \left\{ \ba{@{}l@{\quad}l@{}}
              \justc{x + y} & \text{if } x + y \leq \threshc \\
              \yieldc & \text{otherwise}
          \right.
\end{equations}

\noindent where $\threshc$ is the threshold at which we force a yield.

The transitions in our operational semantics now are of the form
$m; \counter \redtou m'; \counter \bluetext{'}$. In Figure~\ref{fig:counting-rules} we give
an updated rule for \textsc{R-Handle} --- overwriting the previous rule --- and
two new rules for inserting yields. We refer to this system as \countingfrank.

\begin{figure}
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
    \stepstou m'} \quad \boxed{n \stepstoc n'}$
}

\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[R-Handle-Count]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~\many{t}; \justc{n}~
    \redtou~
    \cu ((\many{\venv}(n_k) : B)); \bluetext{n \plusc 1}}

\\
\inferrule[R-Yield-Can]
          { \EC~\textsf{allows}~\yield }
          { \EC[m]; \yieldc~\redtou~\EC[\textsf{yield!}; m]; \justc{0} }
\\
\inferrule[R-Yield-Can't]
          { \neg (\EC~\textsf{allows}~\yield) \\
            m; \justc{n} \redtou m'; \bluetext{c'} }
          { \EC[m]; \yieldc~\redtou~\EC[m']; \yieldc }
\\

\end{mathpar}
}

\caption{Yielding with Counting}
\label{fig:counting-rules}
%% \figrule
\end{figure}

\textsc{R-Handle-Count} replaces the previous rule \textsc{R-Handle}. If the
counter is in the state $\justc{n}$, we perform the handling as usual,
incrementing the counter by 1. Here we use $\plusc$, which will set the counter
to be $\yieldc$ if increasing the counter brings it over the threshold value.

\textsc{R-Yield-Can} and \textsc{R-Yield-Can't} dictate what to do if the
counter is in the \yieldc~state. If the evaluation context allows \yield~
commands to be inserted we do so and reset the counter. If not, but the term
could otherwise reduce if the counter were of the form \justc{k}, then we make
that transition, still maintaining the $\yieldc$ signal.

All of the other rules from Figure~\ref{fig:operational-semantics} are then
implicitly converted to $m; \count{k} \redtou m'; \count{k}$; that is to say
they may only reduce when the counter is \emph{not} in the yielding form, and
reducing does not increase the counter.

\citeauthor{dolan2017concurrent} take a similar approach to this when
investigating asynchrony in Multicore OCaml (\cite{dolan2017concurrent}). They
rely on the operating system to provide a timer interrupt, which is handled as a
first-class effect. Our system is more self-contained; the timing is implemented
within the language itself and doesn't rely on the operating system providing
interrupts. Furthermore, we get fine-grained control over when the timer can
fire, as we can choose to put \yield~in the ability of interruptible
terms.

\paragraph*{Determinism}
Observe that the semantics of Frank equipped with the rules in
Figure~\ref{fig:counting-rules} are now deterministic; for any term and counter
pair, there is only one possible reduction we can make. This is helpful for the
sake of implementation; it is always clear which reduction to make at any point.

We can characterise this by saying that \countingfrank~\emph{implements}~
\nondetfrank; that is to say the counting system gives a deterministic way to
perform the nondeterministic system.

\begin{theorem}[Counting Implements Nondeterminism] ~
%% \begin{restatable}[Counting Implements Nondeterminsim]{theorem}{countimplynondet}\label{thm:count-impl-nondet}
\begin{itemize}
\item For any use $m$ and counter $\counter$, if $m, \counter~\redtou~
  m',\counter'$ in \countingfrank~ then $m~\redtou~m'$ in \nondetfrank.
\item For any construction $n$ and counter $\counter$, if $n, \counter~\redtou~
  n',\counter'$ in \countingfrank~ then $n~\redtou~n'$ in \nondetfrank.
\end{itemize}
%% \end{restatable}
\end{theorem}

% One might consider a different approach, rather than a global counter, which
% would also implement the nondeterministic semantics.

In Section~\ref{sec:starvation} we see a different approach, rather than a
global counter, which also implements the nondeterministic semantics.

\section{Handling}
\label{sec:handling}

Observe that we can now use the same \code{suspend} handler from
Section~\ref{sec:interrupt-motivation}, without having to manually insert
\yield~commands in \code{runner}. The following code will then give the desired
output, of a series of numbers printing interspersed evenly with \code{stop!};

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend <yield -> r> <c>           = suspend (r unit) c!
suspend unit         <_>         _ = unit
\end{lstlisting}

The first argument is evaluated until the counter is greater than the threshold,
at which point a yield command is performed; the rest of the computation is then
frozen and the second argument is evaluated. Observe that the \Yield~interface
is not present in the adjustment of the second argument, so it is left to run
as normal.

We might also want to make the controller --- being the second argument ---
preemptible; it might do some other computation in between performing
\code{stop} and \code{go} operations. We have to add \Yield to the adjustment at
the second argument, but also more pattern matching cases.

\begin{lstlisting}[]
suspend : {<Yield> Unit -> <Stop, Go, <@\texthighlight{Yield}@>> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
<@\texthighlight{
suspend <yield -> r> <yield -> c> p = suspend (r unit) (c unit) p
}@>
<@\texthighlight{
suspend <yield -> r> <c>          p = suspend (r unit) c! p
}@>
<@\texthighlight{
suspend <r>          <yield -> c> p = suspend r! (c unit) p
}@>
\end{lstlisting}

These let \yield~commands synchronise with each other, achieving fair
scheduling, as discussed in Section~\ref{sec:concurrency}. It is annoying to
write these by hand, as they take up a lot of space and are orthogonal to the
rest of the logic of the handler. It is fortunate that this process of resuming
as many yields as possible can be automated completely. Given a multihandler
with $m$ arguments, $n$ of which have \Yield~in their adjustment, we first try
to resume all $n$ \yield~commands. After this we try to resume all of the
different permutations of $n-1$ \yield~commands, and so on until we are trying
to resume 0 \yield~commands.
%
%The resuming clauses for the 3-ary case can be seen below.

%% \begin{lstlisting}
%% sch3 : {<Yield> Unit -> <Yield> Unit -> <Yield> Unit -> Unit}
%% sch3 <yield -> h> <yield -> j> <yield -> k> =
%%     sch3 (h unit) (j unit) (k unit)

%% sch3 <yield -> h> <yield -> j> <k> = sch3 (h unit) (j unit) k!
%% sch3 <yield -> h> <j> <yield -> k> = sch3 (h unit) j! (k unit)
%% sch3 <h> <yield -> j> <yield -> k> = sch3 h! (j unit) (k unit)

%% sch3 <yield -> h> <j> <k> = sch3 (h unit) j! k!
%% sch3 <h> <yield -> j> <k> = sch3 h! (j unit) k!
%% sch3 <h> <j> <yield -> k> = sch3 h! j! (k unit)
%% \end{lstlisting}

These commands can be inserted generically at runtime. If no other hand-written
patterns match, we insert these patterns and try all of them. It is important to
insert the automatically resuming patterns \emph{after} the rest of the
patterns, as the multihandler may want to handle \yield~commands some other way;
we do not want to interfere with this. This means we can program in a simpler,
direct manner, easily toggling which arguments should be interruptible by adding
\Yield~to the corresponding interface. Automatically inserting \yield-handling
clauses when combined with automatically \emph{inserting} \yield~commands then
gives us pre-emptive concurrency at no overhead to the programmer.

\section{Starvation}
\label{sec:starvation}

Consider the following program;

\begin{lstlisting}
  echo : {String -> [Console, Yield] Unit}
  echo st = print st; echo st

  sched : {<Yield> Unit -> <Yield> Unit -> Unit}
  sched unit unit = unit

  tree : {[Console] Unit}
  tree! = sched (echo "A ")
                (sched (echo "B ") (echo "C "))
\end{lstlisting}

We would like \code{tree!} to print out \code{"A B C A B C A B C ..."}. However, when
using \countingfrank~with automatic insertion of \yield~commands, the result is
\code{"A B C B C B C ..."}. The \code{echo "A "} thread is \emph{starved} of
processor time. This happens because when \code{echo "B "} yields the command
is immediately handled by the lower \code{sched} handler and \code{echo "C "}
is ran (and vice versa).

What we need is for each multihandler to have its own counter, which is
incremented every time an argument to the multihandler reduces. When an argument
reduces when the counter is over the threshold, we insert a \yield command in
front of the reduct.

With respect to \code{tree}, in this system \code{echo "A "} will reduce,
increasing the counter at the upper \code{sched}uler until the counter passes
over the threshold, at which point a \yield is inserted in front of \code{echo
  "A "}. We now switch to the other branch, \code{sched (echo "B ") (echo "C
  ")}. When \code{echo "B "} reduces, we increment a counter at both
\code{sched} handlers. Both counters then pass \threshc~at the same time, at
which point we insert a \yield~in front of \code{echo "B "} to be handled by the
lower scheduler. A similar thing happens to \code{echo "C "}.

\todo{Finish this!}

\begin{figure}
\scalebox{\figscale}{%

\begin{mathpar}

\inferrule[R-Handle]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} \bluetext{@ c} : \thunk{\many{\effin{\adj} A \to}~\effout{\sigs}B})~\many{t} \redtou \cu ((\many{\venv}(n_k) : B)}
 
\\

\inferrule[Arg-Increment]
  { %k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
    %(\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j} \\
    % \exists i. \adj_i = \adapt_i\pipe\ext_i \
    %\highlight{\exists i. \Yield \in \ext_i \text{ for } \adj_i = \adapt_i\pipe\ext_i  }
    % \forall~j\leq~n~.~\bluetext{c_j} \not = \yieldc
    n \redtoc n'
  } { \cu (\thunk{((r_{i,j})_j \to n_i)_i}  {\bluetext{@ c}} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~(\many{t}, n, \many{n})
    \redtou \\
     \cu (\thunk{((r_{i,j})_j \to n_i)_i } {\bluetext{@} (\textsf{incOrReset}(\bluetext{c}, \adj_{|\many{t}|}))} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~(\many{t}, {\textsf{maybeYield}(n', \bluetext{c}, \adj_{|\many{t}|})}, \many{n})
       }
\end{mathpar}
}
\caption{Updated Counting Rules}
\label{fig:tree-counting}
\end{figure}

This system is expressed formally in Figure~\ref{fig:tree-counting}. Every
handler --- just being a collection of pattern matching rules
$\thunk{((r_{i,j})_j \to n_i)_i}$ --- is implicitly given a counter \counter~
initialised at $\justc{0}$. The first rule, \textsc{R-Handle}, expresses that
counters are removed when a handler is evaluated on fully-evaluated arguments.
The second rule, \textsc{Arg-Increment}, expresses that when an argument to a
multihandler evaluates, we increment the counter; if the counter is above the
yielding threshold we insert a yield command before the argument and reset the
counter. \textsc{Arg-Increment} relies on two auxilary functions, defined as;

\begin{equations}
  \textsf{incOrReset} (\counter, \adj = \adapt\pipe\ext) =
          \left\{ \ba{@{}l@{\quad}l@{}}
               \counter & \text{if } \Yield \not \in \ext \\
               \succc{\counter} & \text{if } \Yield \in \ext \text{ and } \counter \not = \yieldc \\
               \justc{0} & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc
              % \justc{x + y} & \text{if } x + y \leq \threshc \\
              % \yieldc & \text{otherwise}
          \right.
\end{equations}

\begin{equations}
  \textsf{maybeYield} (n, \counter, \adj = \adapt\pipe\ext) =
          \left\{ \ba{@{}l@{\quad}l@{}}
            \yield!; n & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc \\
            n & \text{otherwise}

               % \counter & \text{if } \Yield \not \in \ext \\
               % \succc{\counter} & \text{if } \Yield \in \ext \text{ and } \counter \not = \yieldc \\
               % \justc{0} & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc
          \right.
\end{equations}

We denote this system, being the basic system described in
Chapter~\ref{chap:formalisation} equipped with the rules in
Figure~\ref{fig:tree-counting}, as \treefrank.

\begin{theorem}[\treefrank~Implements Nondeterminism]~
\begin{itemize}
\item For any use $m$ if $m~\redtou~m'$ in \treefrank~then $m~\redtou~m'$ in
  \nondetfrank.
\item For any construction $n$, if $n~\redtou~n'$ in \treefrank~then
  $n~\redtou~n'$ in \nondetfrank.
\end{itemize}
\end{theorem}
\begin{proof}
  We can see that this holds by just erasing the counters from the
  multihandlers.
\end{proof}

\todo{Finish off this section; talk about starvation, etc}

\section{Soundness}

% We now state the soundness property for our extended system, as well as the
% subject reduction theorem needed for this proof. Our system is nothing more than
% the system of~\citeauthor{convent2020doo} with extra rules; as such we omit most of
% the details.

We now state the soundness properties for our systems, as well as the subject
reduction theorem needed for each soundness proof.


\begin{theorem}[Subject Reduction]~
  \label{thm:sub-red}
\begin{itemize}
\item If $\inferskgs{m}{A}$ and $m; \counter \redtou m'; \counter'$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n; \counter \redtoc n'; \counter'$ then $\checkskgs{A}{n'}$.
\end{itemize}
  \end{theorem}

\begin{proof}
The proof follows by induction on the transitions $\redtou, \redtoc$. We first
consider the two possible states for $\counter$. If it is in the form
$\justc{n}$, then the reduction rules are simply the same as
in~\cite{convent2020doo}, as we do not change the counter. The only exception to
this is the updated \textsc{R-Handle} rule, which is the same as before except
for modifications to the counter; regardless of the counter, the resulting term
$m'$ still remains the same type.

Thus the only new cases are \textsc{R-Yield-Can} and \textsc{R-Yield-Can't}.

\begin{itemize}
\item[\Cse] \textsc{R-Yield-Can}
  By the assumption we have that $\EC~\allows~\yield$. This only holds
  if the context is of the form
  \[\EC[~] = \cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},[~],\many{n'})\]

  Assume that
  \[\inferskgs{\cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},\EC'[n],\many{n'})}{B}\]

  From $\EC~\allows~\yield$ we know that $\yield \in \ext_{|\many{t}|}$ where
  $\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|}$.
  %
  Then by inversion on \textsc{T-App} we have
  $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{\EC'[n]}$ and
  $\adjact{\sigs}{\adj_{|\many{t}|}}{\sigs_{|\many{t}|}}$.
  %
  It follows than that
  $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{\EC'[\yield; n]}$, as
  we know that \yield~commands are permitted under ability $\sigs'_{|\many{t}|}$.
  %

  %% This follows from the assumption $\EC~\allows~\yield$, which
  %% entails that $\yield~\in~\sigs'_{|\many{t}|}$. Thus
  %% $\inferskgs{\EC[\yield; n]}{B}$.

\item[\Cse] \textsc{R-Yield-Can't}
  This case is more straightforward. By the assumption we have that the
  evaluation frame $\EF$ does not permit yielding, but the term inside the frame
  could otherwise reduce.

  Assume $\checkskgs{A}{\EF[n]}$, and therefore $\checkskgs{A'}{n}$. By the
  assumption and subject reduction, $\checkskgs{A'}{n'}$. Then clearly
  $\checkskgs{A}{\EF[n']}$.

\end{itemize}
\end{proof}




\begin{theorem}[Type Soundness]\label{thm:soundness}
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a unique
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a unique
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
%% In particular, if $\sigs = \nowt$ then either the term is a value $w$ or the
%% term can reduce by one step.
\end{theorem}

\begin{proof}
The proof proceeds by simultaneous induction on
$\infers{\cdot}{\cdot}{\sigs}{m}{A}$ and $\checks{\cdot}{\cdot}{\sigs}{A}{n}$.
\end{proof}

\todo{Talk about Soundness for \nondetfrank~as well as \countingfrank.}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{chap:implementation}

%% We now introduce the Frank library for programming with asynchronous effects.
%% %
%% Our design closely follows \aeff~(\cite{ahman2020asynchronous}), a language
%% designed around writing multithreaded programs using asycnhronous effects.

In this section we give a brief introduction to programming with asynchronous
effects, and introduce the Frank library for doing so.
%
Our design closely follows \aeff~(\cite{ahman2020asynchronous}).

One can consider the traditional treatment of shallow effect handling as having
three stages. First an operation \textsf{op} is invoked, with arguments $V$ and
continuation $\lambda x . M$. Then the handler for \textsf{op} --- being the
\emph{implementation} of \textsf{op} --- is evaluated until it returns some
value $V$. Finally, the continuation of the caller is resumed by binding $V$ to
$x$ in $M$.

% \todo{Check the maths here}

What makes effect handling \emph{synchronous} is that the operation call
\textsf{op} \emph{blocks} until the continuation $M$ is resumed. This means that
for \emph{every} algebraic effect, the rest of the computation has to wait for
the handler to be performed, even when the results are not immediately needed.
% What makes effect handling \emph{synchronous} is that the three stages above
% happen in order and straight away. As soon as \textsf{op} is invoked, the
% handler is evaluated with the arguments to \textsf{op}. As soon as the handler
% has reduced to a value, the continuation is resumed. \todo{Rewrite this bit.}

The \emph{asynchronous} treatment of effect handling decouples these three
stages; each of invoking an effect, evaluation of the handler, and resumption of
the caller are separate.
%
% This permits the non-blocking invocation of effects; we invoke an operation and
% can continue the rest of the computation before the operation has been handled.
This permits the non-blocking invocation of effects; we can invoke an operation,
continue with other work, then when (or even if) we need the result of the
operation we can choose to block.
%
% The decoupling of operation invocation from handling has other benefits that we
% discuss later in this section.

\todo{I'm not convinced by the use of ``the rest of the computation''}

Consider effect handling as a simple two threaded application; one thread is the
caller, which invokes some operation \textsf{op}, and the other is the handler
for \textsf{op}. In the synchronous treatment, once the caller invokes \code{op}
the rest of the caller is blocked until the handler has finished handling
\code{op}, at which point the caller restarts. In the asynchronous treatment,
the caller can continue executing; once it needs the result of the operation it
can then choose to block.

Asynchronous effects are used for writing multithreaded programs. A single
thread might handle some operations and also perform other ones, which
themselves are handled by other threads. In the rest of this section we explain
this behaviour by example, and introduce our library for programming with
asynchronous effects in Frank.

%
%% A secondary benefit of decoupling the components of effect handling is that
%% operations can be invoked

% \todo{Talk about how these are all decoupled}

\section{Communication}

Consider a program \feed which lets the user scroll through an seemingly
infinite feed of information (example due to
\citeauthor{ahman2020asynchronous}). The program displays each item in the cache
of data as the user scrolls; the program simulates being infinite by making a
request for another cache of data whenever the user is nearly at the end of the
current cache. In this way, the user never notices the feed pausing to download
more data. This program could be run in parallel with a user interface
controller and a server, among others.

The client thread \feed~would then interact with these other threads by sending
\emph{signals} and receiving \emph{interrupts}. One can imagine these as a
further division of operation calls; a signal is the sender requesting an
operation be performed, and an interrupt is the corresponding incoming request
that the other threads receive. For instance, \feed~would send a \code{request}
signal to ask the server to send a new cache of data; \feed~owuld then receive a
\code{response x} interrupt, where \code{x} is the new data from the server.

Despite this example, we remark that signals do not require a corresponding
interrupt as response and vice versa.
%
For instance, \feed~would perform \code{display d} signals, as requests to the
UI controller to display data \code{d}; the client then doesn't need a response
from the UI controller. Similarly, \feed~receives \code{nextItem} interrupts
whenever the user requests to see a new item.


% This program has to interact with the outside world,

% We can implement this using asynchronous effects and several smaller program
% threads. We might have a user interface thread which deals with input and
% output, a client which  a server which

% Asynchronous effects are particularly useful for writing \emph{multithreaded}
% programs. We may have several other threads in addition to \feed, such as a
% server and a user interface controller.

% Using asynchronous effects, threads communicate with one another using
% \emph{signals}, which are analogous to effect invocations. For instance, \feed
% would use a \code{request} signal to ask for more data from the server. Signals
% sent from other threads become \emph{interrupts} from the receiver's point of
% view; for instance, \feed~would receive \code{response} interrupts from the
% server, containing the new cache of data.

% \todo{Maybe say ``operation calls are further split into signals & interrupts?''}


% For instance, in
% Section~\ref{sec:pre-emptive-scheduling} we implement a pre-emptive scheduler,
% which sends \code{stop} and \code{go} signals without expecting an interrupt as
% a response. Indeed,

\todo{Say something about ``dynamic behaviour'' or whatever}

\todo{Talk about potentially having the system intercept signals?}

% \todo{Write with a view to saying that this behaves asychronously; remember that
%   the user wants to imagine it's asynchronous and that the implementation is
%   just a kind of specialisation of this}

% How is this implemented with asynchronous effects? We have a number of operations
% here: \code{request} for when \feed~needs more information, \code{display d} to
% display data \code{d}, and then the \code{next} operation that \feed~responds
% to. Observe that from the point of view of \feed, \code{request} and
% \code{display} differ to \code{next}; the latter two are operations that
% \feed~performs, whilst \code{next} is an operation \feed~\emph{responds} to. We
% call the latter (outgoing) operations \emph{signals} and the former (incoming)
% opreations \emph{interrupts}.

We define \emph{interrupt handlers} to dictate how to act when an interrupt is
received. An interrupt handler is a function of type \code{S -> Maybe \{R\}},
where \code{S} is a sum type made up of the possible interrupts that can be
received; an example is the \code{Feed} type defined below.
%
% \todo{Fix the way we talk about S.}
%
The return type of the handler is \code{Maybe \{R\}} as we can choose \emph{not}
to handle the interrupt by returning \code{nothing}; this could be because it is
the wrong type of signal, or if some other condition regarding the interrupt is
not fulfilled\footnote{An interrupt handler which inspects the body of the
  interrupt before executing is called a \emph{guarded} interrupt handler. We
  see an example of guarded interrupt handling in
  Section~\ref{sec:pre-emptive-scheduling}.}.
%
An example of an interrupt handler is \code{boringFeed};

\begin{lstlisting}
data Feed = nextItem | request Int
          | response (List Int) | display Int

boringFeed : {Feed -> Maybe {[Console] Unit}}
boringFeed nextItem = just {print "10"}
boringFeed _ = nothing
\end{lstlisting}

\noindent The interrupt handler \code{boringFeed} prints out \code{10} on
receipt of a \code{nextItem} interrupt; if it receives any other interrupt it
does nothing.

A thread will then \emph{install} an interrupt handler to use it. Once
installed, an interrupt handler is then informed of every interrupt that the
installing thread receives. We formalise what exactly happens in the next section.

\todo{Fix this?}

% \noindent When a thread installs the interrupt handler \code{boringFeed}, it
% prints out \code{10} the first time it receives a \code{nextItem} interrupt.

% From henceforth we also refer to interrupt handlers
% as \emph{promises}; an interrupt handler for \textsf{op} once installed is a
% \emph{promise} to perform the given action once an \textsf{op} interrupt is
% received.

% \todo{Maybe get rid of this part.}


\section{An Interface for Asynchronous Effects}

To make our ideas more concrete, we introduce the Frank interface used for
programming with asynchronous effects. First of all we introduce the datatype
used to track the state of an installed promise, \code{Prom}.

\begin{lstlisting}
data Prom X = prom (Ref (PStatus X))
data PStatus X = waiting | done X | resume {X -> Unit}
\end{lstlisting}

A value of type \code{Prom X} is a reference to a value of type \code{PStatus
  X}. It is stored as a reference as we have to write to this cell from two
locations; the interrupt handler itself updates the cell when it has been
fulfilled, and the handler for \code{await} commands also has to access the cell
when the promise is awaited.
%
A promise has three possible states, each a different constructor for
\code{PStatus}. The first, \code{waiting}, expresses that the promise has not
yet been fulfilled. The second, \code{done x}, expresses that the promise has
completed and resulted in a value, \code{x}. The third option, \code{resume
  cont}, is used when a promise is awaited but has not yet completed; in this
case, the handler for \code{await} writes the continuation of the caller to
\code{resume}. The interrupt handler then automatically resumes this once it is
fulfilled.

% The
% continuation \code{cont} is the continuation offered by the calling code when
% the \code{await} effect is performed. We see how this is handled later in this
% section. \todo{Maybe go over this?}

\todo{Talk about caller not getting access to the Pid cell}

\begin{lstlisting}
interface Promise S =
    promise R : {S -> Maybe {<@\greytext{[Promise S, RefState, Yield]}@> R}}
             -> Prom R <@\greytext{[Promise S, RefState, Yield]}@>
  | signal : S -> Unit
  | await R : Prom R <@\greytext{[Promise S, RefState, Yield]}@> -> R
\end{lstlisting}

The entire \code{Promise} interface is polymorphic in the type of \emph{signals}
that threads can perform. This will be a datatype such as \code{Feed}, as
discussed earlier. The commands themselves are polymorphic in the
result types.

The \code{promise} command is used to install an interrupt handler; it takes an
interrupt handler and returns a \code{Prom R} value. The interrupt handler can
perform further \code{Promise S} effects, and must also have access to the
\code{RefState} interface; we show why later. The \code{Yield} interface is also
present so that interrupt handlers are themselves pre-emptible when executed. We
can also parametrise the \code{Promise} interface by effects that the interrupt
handlers can perform. For instance, if using the \code{Promise S [Console]}
interface interrupt handlers also perfom \code{Console} effects and further
\code{Promise S [Console]} effects. This is due to implicit effect polymorphism
as discussed in Chapter~\ref{chap:programming-in-frank}. A stack of installed
interrupt handlers is kept for each thread.

\todo{Talk about why it needs ref}

The \code{signal} command takes a value of the \code{S} type and returns
\code{unit}. When handling \code{signal sig}, all other threads are interrupted;
they stop whatever they were doing, and all installed interrupt handlers now
have to handle this signal. We go through each interrupt handler \code{ih} in
the stack. Recall that an interrupt handler is just a function of type \code{S
  -> Maybe \{R\}}. Thus we simply apply \code{ih} to the interrupt \code{sig}.
If $\code{(ih sig)} \redto \code{nothing}$ we leave \code{ih} on the stack and
look at the next interrupt handler. If
$\code{(ih sig)} \redto \code{(just thk)}$, the interrupted thread immediately
performs the thunk \code{thk} before continuing with the interrupted
computation. In this case, \code{ih} is removed from the stack. We say that a
promise which reduces to a \code{(just thk)} is \emph{fulfilled}.

\todo{talk about how AEff non-confluent, etc}

Finally, the \code{await} command takes a \code{Prom R} value and returns a
value of type \code{R}. At this point, we inspect the promise state as stored in
reference. If the promise is still \code{waiting}, we take the continuation
\code{cont} offered up by \code{await} and store it in the cell as \code{resume
  cont}. If the promise is \code{done} we immediately resume the continuation
with the stored value. At this point the cell should not have a continuation in
it, as it's not possible for multiple threads to await a single promise. As
such, we just safely exit.

When a promise is fulfilled, it looks inside its associated \code{Prom} cell. If
the status is just \code{waiting}, the promise just writes the returned value to
the cell as \code{done x}. If there is a resumption in the cell, the promise
immediately resumes it. There should not already be a \code{done x} value in the
cell, as only the given promise and the handler for the promise interface should
have access to it.

\todo{Better thing for what we do if there's a continuation in there.}

\section{In Action}

Let's revisit the infinitely scrolling feed example from earlier, and consider
the client thread, \feed. The bulk of the client is an interrupt handler for
\code{nextItem} messages. The body of this handler will display the next datum
and reinstall the interrupt handler, as well as perform any requests for extra data. The type signature of the body of our handler will be

\begin{lstlisting}
onNext : {List Int -> Maybe (Prom (List Int) <@\greytext{[InThread]}@>)
          -> <@\greytext{[InThread]}@> Unit}
\end{lstlisting}

\noindent where \code{[InThread]} is an \emph{interface alias} for
\code{[Promise Feed [Console], Console, RefState, Yield]}. The first argument to
\code{onNext} is the currently stored cache of data. The second argument is a
\code{Prom} cell which may not be present; this stores the promise that waits
for a response from the server when a request for extra data is made.

We use a helper function, \code{displayRestart}, to do some tasks that happen
every time \code{onNext} is executed;

\begin{lstlisting}
displayRestart : {List Int -> Maybe (Prom (List Int) <@\greytext{[InThread]}@>)
              -> <@\greytext{[InThread]}@> Unit}
displayRestart cache p =
    signal (display (head cache));
    let cache = pop cache in
    promise { nextItem -> just { onNext cache p } | _ -> nothing };
    unit
\end{lstlisting}

\noindent We simply \code{display} the first element of the cache, and then
install an interrupt handler for \code{nextItem} interrupts that reinstalls
\code{onNext}, with the top item removed from the cache.

For the sake of simplicity we assume that the cache size is fixed to 10 items.
Then whenever we have 3 or less items in the cache, and another request is not
already in progress, we want to issue a new request for data.

\begin{lstlisting}
onNext xs nothing = if (len xs == 3)
    { let resp = promise {(response x) -> just {x} | _ -> nothing} in
      signal (newData (last xs));
      displayRestart xs (just resp) }
    { displayRestart xs nothing }
\end{lstlisting}

\noindent Observe that if the length of the cache is 3 we first install an
interrupt handler for \code{response} interrupts, and then issue a
\code{newData} signal; we know that the server will respond to the
\code{newData} interrupt it receives with a \code{response} message. As
mentioned before, not every signal sent has a corresponding interrupt that will
later be received; for instance, the \code{display} signal is sent without
requiring an interrupt to respond, and the \code{nextItem} interrupt is received
without the client sending a signal to cause it to come in.

Once the request for new data has been issued, we reinvoke \code{onNext} (via
\code{displayRestart}), but this time carrying the promise. This leads us to the
other branch of \code{onNext};

\begin{lstlisting}
onNextList cache (just p) =
    if (len cache == 0)
         { let newCache = await p in
           displayRestart newCache nothing }
         { displayRestart cache (just p) }
\end{lstlisting}

\noindent Here we check if we are at the end of the current cache. If we are, we
await the promise, binding \code{newCache} to the result. Once the promise
\code{p} is fulfilled we proceed as normal with the cache returned from the
\code{resp} promise.

The client can then use this promise by installing it in the same way as in
\code{displayRestart}; they may want to install another interrupt handler, to
listen for other messages from the user interface.

\section{Modelling Asynchrony}

Whilst it is convenient to describe our implementation as truly asynchronous, it
is not in practice.

We use the system as described in Chapter~\ref{chap:preemptive-concurrency} to
automatically force threads to \yield~after a certain amount of time passes. To
handle these \yield~commands, we use a scheduler similar to as described in
Section~\ref{subsec:forking-new-processes}; rather than a multihandler, which
has a fixed number of threads to be handled, we use the \code{Threads} datatype
as discussed earlier to store our threads in. When one yields, we take the next
one and start executing that.

Earlier we mentioned that when a thread sends a signal, all other threads
immediately perform the body of any fulfilled promises. This is not true in
practise; all other threads are notified that they should perform the bodies of
the fulfilled promises, but they only do so when the performing thread gets
processor time.
%
This is a stricter approach than that taken by \aeff, where an interrupted
computation may still reduce before the interrupt handlers process the
interrupt. However, this is a testament to the true asynchronous behaviour of
\aeff; this is only approximated in Frank. It remains as future work to mimic
the full asynchronous behaviour of \aeff.

%% \chapter{Implementation (Old)}

%% We now introduce the Frank library used for asynchronous effects.
%% %
%% Our design closely follows the design of \aeff~(\cite{ahman2020asynchronous}), a
%% language designed around writing multithreaded programs that communicate by
%% sending \emph{interrupts}. A thread dictates how it will respond to an interrupt
%% by installing an \emph{interrupt handler}, also known as a \emph{promise}.
%% %
%% %% These are analogous to traditional effects and handlers; an interrupt when
%% %% invoked is like the invocation of a command, and an interrupt handler is like an
%% %% effect handler.
%% Interrupts and interrupt handlers can be seen as a less expressive version of
%% effects and effect handlers; an interrupt handler describes how to behave on
%% receipt of an interrupt, but it does not get access to the continuation of the
%% caller.

%% Interrupts and interrupt handlers have one particularly compelling feature; when
%% we invoke an interrupt (in the case of synchronous effects, this is just
%% invoking a command), we can carry on computing the rest of the code whilst we
%% wait for a response. This is a stark difference to normal effects, where the
%% rest of the computation is blocked whilst we wait for an answer. The programmer
%% can then subsequently choose to await the response from interrupt, which blocks
%% computation until the interrupt handler has been fulfilled.

%% Unlike \aeff, our system does not track the use of asychronous effects in the
%% type system. It does, however, track the traditional effects that are permitted
%% in promises.


%% \paragraph*{}

%% \aeff's interrupt handlers are manifested in Frank through the \code{Promise}
%% interface. All of the keywords used in \aeff~are just operations of the
%% \code{Promise} interface, with the \code{promise} operation being a \emph{scoped}
%% operation (\cite{pirog2018syntax}).

%% %% \begin{lstlisting}
%% %% interface Promise <@\greytext{[E]}@> =
%% %%       promise R : Prom R <@\greytext{[E | Promise[E|], RefState, Yield]}@>
%% %%                -> Pid R  <@\greytext{[E | Promise[E|], RefState, Yield]}@>
%% %%     | signal : Sig -> Unit
%% %%     | await R : Pid R <@\greytext{[E | Promise[E|], RefState, Yield]}@> -> R

%% %% data Prom R <@\greytext{[E]}@> = prom {Sig -> Maybe {<@\greytext{[E|]}@>R}}

%% %% data Pid X = pid (Ref (PromiseStatus X))

%% %% data PromiseStatus X = empty | done X | resume {X -> Unit}
%% %% \end{lstlisting}

%% \begin{lstlisting}
%% interface Promise =
%%       promise R : Prom R <@\greytext{[Promise, RefState, Yield]}@>
%%                -> Pid R  <@\greytext{[Promise, RefState, Yield]}@>
%%     | signal : Sig -> Unit
%%     | await R : Pid R <@\greytext{[Promise, RefState, Yield]}@> -> R

%% data Prom R <@\greytext{[E]}@> = prom {Sig -> Maybe {<@\greytext{[E|]}@>R}}

%% data Pid X = pid (Ref (PromiseStatus X))

%% data PromiseStatus X = waiting | done X | resume {X -> Unit}
%% \end{lstlisting}

%% \noindent The \code{promise R} command is a polymorphic command which takes a
%% function of type \code{Sig -> Maybe \{[E|] R\}}. This function is an interrupt
%% handler; it dictates what to do on receipt of an interrupt, which is a thing of
%% type \code{Sig}. The return type of the interrupt handler is \code{Maybe \{[E|]
%%   R\}}; this is because the programmer has the chance to return \code{nothing},
%% which will mean the promise goes unfulfilled and waits for another message. The
%% programmer would want to do this on receipt of other types of message, or if a
%% certain condition regarding the interrupt is not fulfilled\footnote{Interrupt
%%   handlers which put conditions on the incoming interrupts are called
%%   \emph{guarded} interrupt handlers.}. An
%% interrupt handler corresponding to an asynchronous division could be;

%% \begin{lstlisting}
%%   div : {Sig -> Maybe {[Promise] Unit}}
%%   div (ask n d) = if (n > 0)
%%                      {just {signal (response (n / d))}}
%%                      {nohing}
%%   div _ = nothing
%% \end{lstlisting}

%% \noindent where we don't want to fire if the denominator is 0. We call the thunk
%% \code{signal (response (n / d))} the \emph{body} of the interrupt handler. We
%% say that an interrupt handler \emph{fires} if an interrupt is received that
%% results in a non-\code{nothing} value. Observe that whilst we can perform some
%% computation when deciding whether or not to fire based on an interrupt, the type
%% of \code{Prom R} restricts us so that we cannot perform any effects whilst
%% deciding; we may only perform effects in the body of the promise.

%% Once handled, \code{promise R} operation returns a \code{Pid R}. This contains
%% information about the status of the promise; it is either empty, to signify the
%% promise is unfulfilled, or it holds the result of the promise, or it holds a
%% resumption that is automatically invoked when the promise is finished.
%% Importantly, the caller should not look inside the \code{Pid} cell and inspect
%% the value; the caller should only be able to \code{await} it and no more.
%% Ideally \code{Pid} should be an abstract type.

%% \code{signal} is a more simple operation. The \code{Sig} data type is the type
%% of signals that the thread can invoke. These can hold extra data, also called a
%% \emph{payload}. For instance, if we had a program running remote function calls,
%% we might have \code{Sig = call ArgsType | result ResultType}; the payloads are
%% respectively of types \code{ArgsType} and \code{ResultType}. The handler for
%% \code{Promise} will then send the signals to each other thread, possibly
%% executing the interrupt handler if needs be.

%% \code{await} takes a \code{Pid R} and returns a value of type \code{R}. This
%% \code{R} is the returned value of the promise. \code{await} will block until the
%% promise it awaits has been fulfilled; we come on to how it does so later.

%% \paragraph*{Effect Typing}

%% %% We can track and control the effects that promises can perform using Frank's
%% %% effect type system.

%% %% For instance, a Frank program of type \code{[Promise
%% %%     [Console]] X} can install promises that print to the console, a program of
%% %% type \code{[Promise[Console, Web]] X} can install promises that perform web
%% %% requests and print to the console, etc.

%% %% Note however that the effect typing is slightly complicated in the definition of the
%% %% interface; a type of \code{Promise [Console]} means that the installed promise
%% %% can really perform the effects \code{[Promise[Console], Console, RefState,
%% %%     Yield]}. This is expressed by the \code{[E | Promise[E|], RefState, Yield]}
%% %% part of the \code{promise R} definition. A recursive type is needed as the
%% %% promises can themselves invoke other promises.

%% %% \todo{Flesh this out, rewrite it}

%% We can track and control the effects that promises can perform using Frank's
%% effect type system. Recall that Frank effect types implicitly add effect type
%% variables to effect type declarations (as discussed in
%% Section~\ref{sec:effects}); thus the type \code{[Promise, RefState, Yield]}
%% desugars to \code{[E | Promise [E|], RefState, Yield]}. Thus a Frank function
%% with ability \code{[Promise [Console]]} can install promises that use the
%% effects in the interface \code{[Promise [Console], Console, RefState, Yield]}.
%% We use a recursive type so that promises can themselves install other promises.
%% \code{RefState} and \code{Yield} are explicitly added to the ability as a
%% convenience, as every promise requires it in their ability for reasons that
%% become clear later.

%% \paragraph*{Threads}

%% %% To run several threads in parallel, we need to maintain a collection of thread
%% %% states. When we stop executing a thread we suspend it, storing the continuation,
%% %% and start executing a new one, in the same style as Section
%% %% \ref{sec:concurrency}. We also need to store the promises that each thread has
%% %% installed. These are stored as a stack to maintain the order of installation.
%% %% Installing a promise is as straightforward as pushing it onto the corresponding
%% %% thread's promise stack.

%% We maintain a collection of thread states, being the computation thus far and
%% the promises that each thread has installed.
%% %
%% This collection is realised in Frank as the \code{Threads} datatype. It is
%% essentially just a list of three-tuples\footnote{If Frank had support for type
%%   aliases, this is exactly what it would be.}, storing the integer ID, suspended
%% computation, and promise stack of each thread.

%% \begin{lstlisting}
%% data Threads =
%%       tentry Int <@\greytext{-- thread ID}@>
%%              {<@\greytext{[RefState, Yield]}@> Unit}
%%              (TStack {Sig -> {<@\greytext{[RefState, Yield]}@> Unit}
%%                           -> Maybe {<@\greytext{[RefState, Yield]}@> Unit}})
%%              Threads
%%     | tnil
%% \end{lstlisting}

%% When a thread \yield{}s, we take the continuation and store it in
%% \code{Threads}; we then take the next one (according to whatever our scheduling
%% strategy is) and resume the thunk.

%% Observe that installed promises take two arguments. The second
%% argument is the suspended computation thus far. This is because when handling
%% signals we take the promise's body, compose it with the suspended computation
%% and then rehandle it with the \code{Promise} handler. Again, promises can return
%% \code{nothing}; in this case the promise remains on the stack.

%% %% This is because we often have to
%% %% take the body of the promises, compose it with the rest of the interrupted
%% %% computation and then rehandle it with the \code{Promise} handler. If the promise
%% %% results in \code{Nothing}, we don't remove it from the stack and it remains
%% %% installed; recall that returning \code{Nothing} signifies the promise not
%% %% firing. If it returns \code{Just th}, we replace the currently stored suspended
%% %% computation with \code{th}. We go into further detail about this later.


%% \section{Handling Promises}
%% \label{sec:handling-promises}

%% We now introduce the handler for \code{Promise} effects.

%% \begin{lstlisting}
%% hdl : {Int -> Ref Threads
%%     -> <Promise> Unit
%%     -> <@\greytext{[RefState, Yield]}@> Unit}
%% \end{lstlisting}

%% The first argument is the id of the thread being handled. The second one is a
%% reference to the threads structure. These are parametrised by the effects
%% performed in the promises, just like the \code{Promise} interface. The third
%% argument is the thread itself, which performs \code{Promise} operations.
%% %
%% Finally, the ability expresses that this function can perform \code{RefState}
%% effects; the \code{Yield} interface states that \code{hdl} can be interrupted.
%% %% Finally, the return type expresses that this code can perform any of the effects
%% %% that the promises perform, plus \code{RefState} effects; the \code{Yield}
%% %% encodes that this can be interrupted (as in Chapter~\ref{chap:preemptive-concurrency}).

%% \paragraph*{Promises}~
%% \begin{lstlisting}[numbers=left]
%% hdl thId thrs <promise (prom cb) -> k> =
%%     let cell = pid (new waiting) in
%%     let cbMod = (toWrite cell cb) in
%%     let cbMaybe = {sig rest -> case (cbMod sig)
%%           { nothing -> nothing
%%           | (just susp) ->
%%                 just { hdl thId thrs (susp!; <@\greytext{<Promise>}@> rest!)} }} in
%%     let queued = (addCb thId cbMaybe (read thrs)) in
%%     write thrs queued;
%%     hdl thId thrs (k cell)
%% \end{lstlisting}

%% Above we see the handler for \code{promise}. Line 2 creates a new reference cell
%% for the promise id; this is initialised to \code{waiting}, as nothing has been
%% performed yet. Line 3 calls the utility function \code{toWrite}, shown below.

%% %% This takes a
%% %% promise of type \code{Sig -> \{R\}} and converts it to type \code{S ->
%% %%   \{[RefState]Unit\}}; it modifies it to write its value to the corresponding
%% %% \code{Pid} cell once finished.

%% \begin{lstlisting}
%% toWrite : Pid R <@\greytext{[RefState]}@>
%%           -> {S -> (Maybe {<@\greytext{[RefState]}@> R})}
%%           -> {S -> (Maybe {<@\greytext{[RefState]}@> Unit})}
%% toWrite (pid cell) cb =
%%     {x -> case (cb x)
%%          { nothing -> nothing
%%          | (just susp) ->
%%              just {case (read cell)
%%                       { empty -> write cell (done susp!)
%%                       | (resume resumption) -> resumption susp!}} }}
%% \end{lstlisting}

%% This takes a promise of type \code{Sig -> Maybe \{R\}} and converts it to type
%% \code{Sig -> Maybe \{Unit\}}. \code{toWrite} modifies the given callback so
%% once it has been executed it looks inside the given \code{Pid} cell. If the cell
%% is \code{empty}, we just write the return value of the promise body in
%% the cell. If there is a resumption, we resume it with the value of the promise
%% body.

%% %
%% %Having all promises as the same type makes storing them in
%% %% one data structure possible.
%% %
%% %% In lines 4-7 we convert our promise to one that
%% %% takes into account the computation after we've run the promise as well. This is
%% %% essential to get blocking via \code{await} to work properly when running a
%% %% promise, which is important for pre-emptive concurrency and other applications.
%% %% \todo{Go into more depth about this}.

%% In lines 4-7 we convert the promise to also take the computation it interrupts
%% as an argument. The body of the promise is composed with the interrupted
%% computation and the whole thing is rehandled by the promise handler. This is
%% essential to get blocking when installed from a promise working. For instance,
%% we might have a program like \code{thr};

%% \begin{lstlisting}
%% thr : {[Promise] Unit}
%% thr! = promise (prom {stop -> await (promise (prom {go -> unit}))});
%%        otherComputation!
%% \end{lstlisting}

%% The desired behaviour is to start blocking when a \code{stop} message comes in,
%% and then start running again once a \code{go} message is received. If we were
%% just to handle rehandle the promise body separate from the interrupted
%% computation, \code{otherComputation} would not get blocked.

%% Finally in lines 8-10 we add the new promise to the stack of promises installed
%% for this thread and resume the computation with the cell we created earlier.

%% \paragraph*{Signals} ~

%% \begin{lstlisting}
%% hdl thId thrs <signal sig -> thr> =
%%     let newThrs = runThreads sig (read thrs) in
%%     write thrs newThrs;
%%     hdl thId thrs (thr unit)
%% \end{lstlisting}

%% When a thread we're running invokes a signal, we inform the other threads of
%% this using \code{runThreads}. This function then calls the \code{runThread}
%% function on every thread;

%% %% When a signal comes in, we need to try and execute \emph{all} of the installed
%% %% promises, for every thread. To do this we use the \code{runThreads} function,
%% %% which calls the below function for all threads;

%% \begin{lstlisting}
%% runThread sig (trio susp cbs skipped) =
%%   case (dequeue cbs)
%%     { nothing -> trio susp cbs skipped
%%     | (just (pair cb cbs)) ->
%%       case (cb sig susp)
%%         { nothing -> runThread sig (trio susp cbs (enqueue cb skipped))
%%         | (just res) -> runThread sig (trio res cbs skipped)}}
%% \end{lstlisting}

%% \noindent We first check to see if there are any installed promises remaining.
%% If there is, we run the promise with the signal supplied. We supply the callback
%% with the incoming signal and the thunked computation thus far. If the callback
%% returns \code{nothing} we reinstall it. If the callback gives us an updated
%% thunk, we continue to run the rest of the promises, with this thunk the new
%% computation to be extended.

%% At no point in this process are these thunks ever actually invoked; we are
%% simply mutating suspended computations. When a signal triggers a promise, the
%% body of the promise does not get performed until the thread is run by the
%% scheduler. In \aeff, when a signal is received by an interrupt handler there is
%% some nondeterminism present; we can either trigger the interrupt handler or
%% continue computing underneath the handler. In our system this choice is not
%% available; the interrupt handler is always triggered first, and we process the
%% body of it immediately.


%% %% Recall that the type of the callbacks is \code{Sig -> \{Unit\} -> \{R\}}; we
%% %% have to also supply the callbacks with the thunked computation so far. Again,
%% %% this is important to correctly implement blocking. If the callback returns
%% %% \code{nothing} we do not evaluate it and we reinstall it afterwards, by putting
%% %% it onto the ``skipped'' stack.

%% Once promise execution is finished we update the state of \code{thrs} and resume
%% handling, restarting the continuation with \code{unit} immediately.
%% This is unlike traditional effect invocations, where we would block until a
%% result is produced.


%% \paragraph*{Await}~
%% \begin{lstlisting}
%% hdl thId thrs <await cell -> thr> =
%%     case (readPid cell)
%%         { (done x) ->
%%             hdl thId thrs (thr x)
%%         | waiting ->
%%             writePid cell (resume thr);
%%             hdl thId thrs unit }
%% \end{lstlisting}

%% Handling \code{await} is surprisingly the simplest of the lot. Recall that
%% \code{await} takes a promise id cell \code{Pid R} and returns a value of type
%% \code{R}. The handler looks inside this cell; if there is a finished value there
%% already (\code{done x}) it resumes the continuation with this value straight
%% away. If the promise has not yet completed, we then write the resumption (which
%% is of type \code{\{R -> Unit\}}) to the cell. The function \code{toWrite} used
%% when installing promises changes the original promise to resume the continuation
%% stored in \code{Pid}, if there is one present.

%% \section{Multithreading}

%% %% We now show how we can easily introduce multithreading to our system. Observe
%% %% that we are yet to have a handler for any \code{yield} commands. We can handle
%% %% them, yielding co-operative concurrency in the same style as
%% %% Section~\ref{sec:concurrency}, like so;

%% Multithreading then fits into our system in a natural way, via the
%% \code{schedule} handler.

%% \begin{lstlisting}[numbers=left]
%% schedule : {<Yield> Unit -> Int -> Ref Threads -> <@\greytext{[RefState]}@>Unit}
%% schedule <yield -> k> cur thrs =
%%     let next = nextId cur (keys (read thrs)) in
%%     let newThk = lookupThk next (read thrs) in
%%     let newThrs = writeThk cur {k unit} (read thrs) in
%%     write thrs newThrs;
%%     schedule newThk! next thrs

%% schedule unit cur thrs = scheduleT yield! cur thrs
%% \end{lstlisting}

%% \noindent Recall that the threads are stored with a thread id, an integer. We
%% use these in our simple scheduling strategy, where we just cycle through all ids
%% in ascending order. Line 3 finds the id of the next thread as per this strategy,
%% and line 4 looks up the thunk from \code{Threads}. Line 5 then writes the
%% current thread's thunk to \code{Threads}. Line 6 writes the updated version of
%% \code{Threads} and line 7 starts executing the next continuation. Line 9 states
%% that if a thread's value is unit we just force a yield. This is useful if a
%% thread is blocked as we will instantly stop processing it and start the next
%% one.

%% %% One disadvantage of our approach is that we are still tied into using
%% %% \code{Threads}, even though multithreading seems to be orthogonal to handling
%% %% promises; it would be nicer to use a generic queue data structure, or even just
%% %% a multihandler like in Section~\ref{sec:concurrency}. The problem
%% %% is that the stored thunks get modified whilst other threads work, so we need to
%% %% keep an up-to-date version of the latest ones.

%% %% \section{Running Processes}

\chapter{Examples}
\label{chap:examples}

%% The combination of our \code{Promise} interface with the pre-emptive concurrency
%% of Section~\ref{chap:preemptive-concurrency} lets us express complex concurrent
%% programs in a simple, direct manner. In this section we show some examples of
%% these.

%% The developed library gives us an expressive, malleable way to implement common
%% asynchronous programming features within our language.

Many languages which support async-await --- such as C# and Javascript --- have
the behaviour built-in. First the compiler is changed to add new syntax, then
the compiler is changed to add new type-checking, then we have to implement the
semantics; even worse, we have to do this when we want another asynchronous
primitive, such as futures (asynchronous post-processing of results).

We show that with our promise library we can implement all of these common
asynchronous primitives within the language itself.

\section{Pre-emptive Scheduling}
\label{sec:pre-emptive-scheduling}

%% An essential feature of our asynchronous effects system is that it supports
%% pre-emptive concurrency; that is, the suspension and resumption of threads
%% non-cooperatively. Naturally, this relies on the insertion of yields as
%% discussed in Chapter~\ref{chap:preemption}.

%% We supplement the signals supported in our program with two more;

Whilst we have already shown how to pre-emptively schedule several threads in
Section~\ref{sec:handling}, we might want to have a more robust way of doing
this; the multihandler strategy is fixed in a left-to-right evaluation order. In
this method, we can just have a single source sending out \code{stop} and
\code{go} messages, implementing a potentially more sophisticated scheduling
strategy than mere round-robin.

\begin{lstlisting}
data Schedule = stop | go

goPromise : {Sig -> Maybe {<@\greytext{[Promise Schedule]}@> Unit}}
goPromise go = just {unit}
goPromise _ = nothing

stopPromise : {Sig -> Maybe {<@\greytext{[Promise Schedule]}@> Unit}}
stopPromise stop = just {await (promise goPromise);
                         promise stopPromise; unit}
stopPromise _ = nothing

preempt : {{X} -> <@\greytext{[Promise Schedule]}@> X}
preempt comp = promise stopPromise; comp!
\end{lstlisting}

\noindent We can easily make a computation pre-emptible by just installing
\code{stopPromise} before the main body, as in \code{preempt}.

Once a preemptible computation receives a \code{stop} interrupt, it installs
\code{goPromise} and immediately awaits it. This blocks the rest of the
computation from executing until a \code{go} interrupt is received. When such a
signal does come in, \code{goPromise} is fulfilled; the body of the interrupt
handler does nothing, but it unblocks the rest of the thread's computation. At
this point, the rest of the body of \code{stopPromise} is also unblocked, so
another \code{stopPromise} is installed.

For simplicity's sake, we just display a version with only one thread, however this approach can easily be generalised to pre-empt multiple threads by adding ID fields to the \code{stop} and \code{go} signals and using guarded interrupt handlers for \code{goPromise} and \code{stopPromise}.

% \noindent For simplicity's sake we just display a version with only one thread, however this approach can easily be generalised to multiple threads by adding ID fields to the signals in \code{schedule} and using guarded interrupt handlers.

% % \code{stopPromise} is another guarded interrupt handler; it will only fire its
% body if the payload to \code{stop} is the thread's ID. The body then installs a
% promise waiting for \code{go} and immediately awaits it, starting to block. The
% rest of the computation can not proceed until the corresponding go message is
% received. Once the correct go promise is received the promise is fulfilled adn
% the rest of the computation can start again, and the \code{stop} interrupt
% handler is reinstalled. \code{goPromise} is simple in comparison; if it receives
% the correct \code{go} signal it just returns \code{unit}.

%% We can then make a function  by just installing a stop-waiting promise
%% in front of the function code;

%% We can then install the stop interrupt handler before a computation to make it
%% schedulable. The computation being scheduled is then unaware it is being
%% scheduled, as desired.

Now all that remains is to have a source of \code{stop} and \code{go} signals.
This could just be a standard round-robin scheduler or some more sophisticated
strategy. One disadvantage to our approach is that an adversarial thread could
just send \code{stop} and \code{go} signals of its own, overriding the
scheduler. Using session types (\cite{honda1998language}) to restrict
inter-thread communication would be able to solve this problem.

\section{Futures}
\label{sec:futures}

Our asynchronous effects system is expressive enough to implement the
asychronous post-processing of results, or \emph{futures}. Previously these have
had to be implemented as a separate language feature
(\cite{schwinghammer2002concurrent}).

Futures are useful if we want to asynchronously perform some action once another
promise has been completed. In the context of a web application, this might be
updating the application's display once some remote call for data has finished.
Observe that this differs from just awaiting the remote call and then updating
once we have this; we do not want to block everything else from running, rather
perform this action asynchronously, when the promise is complete.

\begin{lstlisting}
futureList : {Pid R <@\greytext{[Promise]}@> -> {R -> <@\greytext{[Promise]}@> Z} -> Sig
    -> Maybe {<@\greytext{[Promise]}@> Z}}
futureList p comp (listSig _) = just { let res = await p in comp res}
futureList _ _ _ = nothing
\end{lstlisting}

\noindent When calling \code{futureList} we supply a promise of result type
\code{R} and a computation of type \code{R -> Z}. We then await the promise, and
once we have a value (of type \code{R}) run the computation with this. An
example computation using this system is;

\begin{lstlisting}
let recv = promise { (listSig xs) -> just {xs} | _ -> nothing} in
let prod = promise {s -> futureList filt product s} in
promise {s -> futureList prod {x -> signal (resultSig x)} s}
\end{lstlisting}

\noindent Where we, upon receipt of a list signal, take the product of the list
element-wise and send another signal with this result. All three of these
promises are triggered by the same signal; \code{recv} is executed first, which
then executes \code{prod}, which then lets the final one run. This behaviour
depends on signals being able to execute many promises at once (that is,
behaving like \emph{deep} rather than shallow handlers).

\section{Async-Await with Workers}
\label{sec:async-await}

Our asynchronous effects system can express the familiar async-await
abstraction. This had previously been implemented in Frank by forking new
threads, then to be handled by a co-operative scheduler like in
Section~\ref{sec:concurrency}. We realise it by using a controller thread, which
will send tasks to one of a set of $n$ worker threads. When these worker threads
are not working, they are instantly skipped; hence there is not much
inefficiency associated with having extra idle workers.

We use three types of signal here. The calling thread sends \code{call}
messages, where the arguments are the computation to run and the call ID. The
controller handles \code{call} interrupts and sends \code{work} interrupts; the
arguments to this signal are the computation again, the call ID and the ID of
the worker who is designated to run this task. Finally, the worker sends
\code{result} signals when it has finished computing; arguments to this are the
result and the call ID.

% We first show how the caller communicates with the controller.

% \todo{Introduce what all of the signals are ????}

% \todo{Parametrise Async by the return type?}

\begin{lstlisting}
data Async R = result R Int | call {R} Int
             | work {R} Int Int

async : {[{String} -> Ref Int
    -> <@\greytext{[Promise (Async String)]}@> Pid String <@\greytext{[Promise (Async String)]}@>
async proc callCounter =
    let callNo = read callCounter in
    let waiter = {s -> resultWaiter callNo s} in
    signal (call proc callNo);
    write callCounter (callNo + 1);
    waiter
\end{lstlisting}

We use this function to issue a new asynchronous task. We keep a global counter
to give each call a unique identifier. We then install a promise
\code{resultWaiter} that waits for a result and simply returns it, if the call
numbers match. Finally we send a \code{call} signal with the process and return
the result interrupt handler. Observe that \code{async} just returns the
\code{result} promise; as such, the \code{await} operation is just the built-in
\code{await} operation.

The controller installs an interrupt handler to react to \code{call} interrupts.
The thread tracks which threads have a task running; if there is a free worker
it then sends a \code{work} signal, containing the computation and the ID of the
worker who should perform it. The controller then installs a promise to update
the active status of the corresponding worker once a \code{result} interrupt is
received from the worker.

% \code{call} signals are handled by the controller thread. This thread keeps
% track of which of the workers do not currently have a task running, and
% also installs a promise to set its state to idle once the corresponding
% \code{result} message is received.


% \begin{lstlisting}
% onResult : {Ref (List (Maybe Int)) -> Int -> Sig
%     -> Maybe {<@\greytext{[Promise]}@> Unit}}
% onResult active wid (result res cid) =
%     just { write active (putIn nothing wid (read active)) }
% onResult _ _ _ = nothing
% \end{lstlisting}

% onAsyncBody : {Ref (List (Maybe Int)) -> {String} -> Int
%     -> <@\greytext{[Promise]}@> Unit}
% onAsyncBody active p callId =
%     case (nextFree (read active))
%         { nothing -> print "All workers are busy."
%         | (just wid) ->
%             write active (putIn (just callId) wid (read active));
%             promise (prom {s -> onResult active wid s});
%             signal (workIn p wid callId)};
%     promise (prom {s -> onAsync active s}); unit
% \end{lstlisting}

Workers listen for a \code{work} interrupt; when one comes in with their ID in
the payload, they simply perform the computation and send a \code{result} signal
with the result. This \code{result} signal triggers the interrupt handler
installed by the \code{async} caller, but also triggers the promise installed by
the controller, to inform it that the worker is now idle. This ability to
trigger multiple promises with one message is a subtle but useful feature of the
asynchronous effects system.

\section{Cancelling Tasks}

Because we are working in a language equipped with effect handlers, we can
easily write a handler for the \textsf{Cancel} effect, which just gets rid of
the continuation and replaces it with some default value (e.g. \code{unit}).

\begin{lstlisting}
  interface Cancel = cancel : Unit
 
  hdlCancel : {<Cancel> Unit -> Unit}
  hdlCancel <cancel -> _> = unit
  hdlCancel unit          = unit
\end{lstlisting}

% \noindent We can use this to cancel a task issued with \code{async}. Recall that
% tasks run on their own worker thread. As such, all we need to do to cancel them
% is reinstall the worker promise --- which waits for new tasks --- and then
% invoke the cancel effect. As such, our worker code becomes
\noindent We can use this to cancel a task issued with \code{async}. Recall that
tasks issued with async-await run on their own thread; we can use the
\code{cancel} effect to throw away the continuation of the entire thread and
wipe the slate clean. To make our worker threads cancellable, we change the
interrupt handler for \code{work} interrupts to install the \code{canceller}
promise before the worker starts running the task:

% All we need to do to make our worker threads cancellable
% is install the \code{canceller} promise below;

\begin{lstlisting}
canceller : {Int -> Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
canceller wid callId (cancelCall callId') =
    if (callId == callId')
        { just {promise {s -> worker wid s}; cancel!} }
        { nothing }
canceller _ _ _ = nothing
\end{lstlisting}

\noindent The \code{canceller} promise installs the \code{worker} promise before
cancelling, so that the thread can one day run a task again. \todo{fix}

% workProm : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
% workProm wid (workIn p wid' callId) =
%     if (wid == wid')
%        { just {<@\texthighlight{promise \{s -> canceller wid callId s\}}@>;
%                let res = p! in
%                signal (result res callId);
%                worker wid; unit}}
%        { nothing }
% workProm _ _ = nothing
% \end{lstlisting}

The realisation of cancellable function calls in
\aeff(\cite{ahman2020asynchronous}) was to start awaiting a new promise that
will never be fulfilled. This leads to a space leak as unfulfilled promises
build up. Our approach improves on this as the cancelled calls do truly
disappear.

% However, a weakness of our system is that we have to modify the
% handler code for promises, even though cancellation of calls and promises should
% be orthogonal.

However, we have to modify the handler for the \textsf{Promise} effect to
correctly cancel threads. When we fulfill a promise, we take the result
computation and compose this with the interrupted computation and rehandle this
single computation with the promise handler. At this point, we also now handle
\code{Cancel} effects, so that we remove the whole thread. This is a point for
improvement; handling the \code{Cancel} effect and handling \code{Promise}
effects are orthogonal, and should be treated separately.

% We have to modify the handler for the \textsf{Promise} effect for this. Recall
% that when we install a promise, we convert it to a form that takes composes the
% body of the promise with the interrupted computation and rehandles the
% \code{Promise} effects that this might perform.
% %
% We need to then wrap this in a handler for \textsf{Cancel} effects again; this
% is because user-level promises could perform \textsf{Cancel} effects, and we
% want to cancel the \emph{whole} computation, not just the body of the promise.

% \begin{lstlisting}
% case (cbMod sig)
%     { nothing -> nothing
%     | (just susp) ->
%       just { <@\texthighlight{stopCancel}@> (hdl thId thrs (susp!; <LCancel, Promise> rest!)) }}
% \end{lstlisting}


\subsection{Interleaving}

With the \textsf{Cancel} effect, we can also define the useful \code{interleave}
combinator (\cite{leijen2017structured}).
%
This lets us issue two tasks on two different threads, using the \code{call}
signal as defined in Section~\ref{sec:async-await}. We then install an interrupt
handler which listens for \code{result} interrupt; if a \code{result} interrupt
corresponds to one of the installed threads we cancel the other thread using
\code{cancelCall} and return the received result.

%% \todo{Think of a better way to make reference to Daan's work}

% \begin{lstlisting}
% resultWaiter : {String -> Int -> Int -> Int
%     -> Maybe {<@\greytext{[Promise]}@> String}}
% resultWaiter res callNo callA callB =
%     if (callNo == callA)
%         { just { signal (cancelCall callB); res} }
%         { if (callNo == callB)
%             { just { signal (cancelCall callA); res} }
%             { nothing }}

% interleave : {{String} -> {String}
%     -> Ref Int -> <@\greytext{[Promise]}@> Pid String <@\greytext{[Promise]}@>}
% interleave procA procB callCounter =
%     let callA = read callCounter in
%     write callCounter (callA + 1);
%     let callB = read callCounter in
%     write callCounter (callB + 1);

%     let ileaveWaiter =
%         promise (prom {(result res callNo) ->
%             resultWaiter res callNo callA callB
%                       | _ -> nothing
%         }) in

%     signal (call procA callA);
%     signal (call procB callB);

%     ileaveWaiter
% \end{lstlisting}

% This will issue the two tasks on different threads. We then install an interrupt
% handler for \code{result} signals; whichever result is received first we return
% and cancel the other task.

This lets us write timeouts for functions, where we interleave a potentially
long-running request with a timer; we cancel the request if it takes too long.
We can also run two identical requests to different services and just take the
result of the one that returns first. The \code{interleave} operator can be
composed with itself to yield the $n$-ary operator \code{interleave} operator.

% Despite \code{interleave} being a more complex function than \code{async}, we
% can implement it with a small change to \code{async}.

Observe the similarity of \code{interleave} and \code{async}. By taking
asynchronous programming structures out of library code and into the
programmer's hands, we hope that programmers will be able to more easily produce
their own, useful tools.


\chapter{Conclusion}
\label{chap:conclusion}

We conclude with a discussion of the achievements, some limitations, and
possible future work.

Combining the pre-emptive concurrency of
Section~\ref{sec:preemptive-concurrency} with the promise library of
Section~\ref{sec:implementation} yields a direct and comfortable way to write
asynchronous programs. It is our hope that these results will be reproducible in
other effect-handling languages.
%
Moreover, we have shown how effect handlers as a programming tool can be used to
easily express complicated control flow.

\todo{Add more to end of paragraph}

\section{Limitations and Future Work}

\paragraph*{Type System}
The implementation of asynchronous effects as discussed does not track
asynchronous effects, and is untyped. \citeauthor{ahman2020asynchronous} have
shown that this is possible; it remains as future work to add types to our
implementation.

\paragraph*{Session Types for Communication Protocols}
Our system uses the fairly simple communication protocol where every message
gets sent to every thread. Naturally, two threads might want to communicate
secretly, without other threads eavesdropping. Finer control of this is
desirable for larger applications.

\paragraph*{A Higher Degree of Asynchrony}
There are several degrees of asynchrony possible with a system like ours. We
restrict one thread to run at any given time, with fulfilled promises only
evaluating when the corresponding thread gets processor time. \aeff~take the
other approach; any thread can compute at any time. There is an in-between,
where the bodies of interrupts may be evaluated out-of-turn. It would be
interesting to further explore the differences between different models of
asynchrony and their benefits and limitations.

\paragraph*{Sophisticated Yielding Strategies}
.....

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{plainnat}
\bibliography{bibliography}

%% You can include appendices like this:
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\appendix

\chapter{Remaining Formalisms}

\begin{figure} % \figrule
\flushleft
%% $\boxed{\kindchecksk{R}}$
%% \begin{mathpar}
%% \inferrule[K-Val]
%%   {\TyVar(A) \subseteq \kenv}
%%   {\kindchecksk{A}}

%% \inferrule[K-Eff]
%%   {\TyVar(\sigs) \subseteq \kenv}
%%   {\kindchecksk{[\sigs]}}
%% %
%% \end{mathpar}

$\boxed{\infersk{\Gamma}{\sigs}{m}{A}}$
\begin{mathpar}
\inferrule[T-Var]
  {
   x:A \in \Gamma}
  {\inferskgs{x}{A}}

\inferrule[T-PolyVar]
  {% \kindchecks{\kenv, \many{Z}}{A}\\
   \kindchecksk{\many{R}} \\
   f:\forall \many{Z}.A \in \Gamma}
  {\inferskgs{f~\many{R}}{A[\many{R}/\many{Z}]}}
\\
\inferrule[T-App]
  {\sigs' = \sigs \\
   (\adjact{\sigs}{\adj_i}{\sigs'_i})_i \\\\
   \inferskgs{m}{\thunk{\many{\effin{\adj}A \to}~ \effout{\sigs'}B}} \\
   (\checksk{\Gamma}{\sigs'_i}{A_i}{n_i})_i}
  {\infersk{\Gamma}{\sigs}{m~\many{n}}{B}}

\inferrule[T-Ascribe]
  {\checkskgs{A}{n}}
  {\inferskgs{\cu (n : A)}{A}}
%
\end{mathpar}

$\boxed{\checksk{\Gamma}{\sigs}{A}{n}}$
\begin{mathpar}
\inferrule[T-Switch]
  {\inferskgs{m}{A} \\ A = B}
  {\checkskgs{B}{\uc m}}

\inferrule[T-Data]
  {%(\kindchecksk{R_i})_i\\
   k~\many{A} \in D~\many{R} \\
   (\checkskgs{A_j}{n_j})_j}
  {\checkskgs{D~\many{R}}{k~\many{n}}}

\inferrule[T-Command]
  {\kindchecksk{\many{R}} \\
   c : \forall \many{Z}.\many{A \to}~ B \in \sigs \\
   (\checkskgs{A_j[\many{R}/\many{Z}]}{n_j})_j}
  {\checkskgs{B[\many{R}/\many{Z}]}{c~\many{R}~\many{n}}}

\inferrule[T-Thunk]
  {\checksdefkg{C}{e}}
  {\checkskgs{\thunk{C}}{\thunk{e}}}

\inferrule[T-Let]
  {P = \forall \many{Z}.A \\\\
   \checkbase{\kenv, \many{Z}}{\sigentails{\emptyset}}{\Gamma}{A}{n} \\
   \checksk{\Gamma, f : P}{\sigs}{B}{n'}}
  {\checkskgs{B}{\key{let}~f : P = n~\key{in}~n'}}

\inferrule[T-LetRec]
  {(P_i = \forall \many{Z}_i.\thunk{C_i})_i \\\\
   (\checkbase{\kenv, \many{Z}_i}{\vdash}{\Gamma, \many{f : P}}{C}{e_i})_i\\
   \checksk{\Gamma, \many{f : P}}{\sigs}{B}{n}}
  {\checkskgs{B}{\key{letrec}~\many{f : P = e}~\key{in}~n}}

\inferrule[T-Adapt]
  {\adjact{\sigs}{\adapt}{\sigs'} \\ \checksk{\Gamma}{\sigs'}{A}{n}}
  {\checkskgs{A}{\effin{\adapt}~n}}
\end{mathpar}

$\boxed{\checksdefkg{C}{e}}$
\begin{mathpar}
\inferrule[T-Comp]
  {(\matchesck{T_j}{r_{i,j}}{\sigs}{\exists \kenva_{i,j}.\Gamma'_{i,j}})_{i,j} \\
   (\checks{\kenv, (\kenva_{i,j})_j}{\Gamma, (\Gamma'_{i,j})_j}{\sigs}{B}{n_i})_i \\
   ((r_{i,j})_{i} \text{ covers } T_j)_j}
  {\checksdefkg{(T_j \to)_j~\effout{\sigs}B}{((r_{i,j})_j \mapsto n_i)_i}}
\end{mathpar}
\caption{Term Typing Rules}
\label{fig:term-typing}
% \figrule
\end{figure}

\begin{figure}%% \figrule
\flushleft
$\boxed{\adjact{\sigs}{\adj}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adj]{\adjact{\sigs}{\adapt}{\sigs'} \\
  \adjact{\sigs'}{\ext}{\sigs''}}
          {\adjact{\sigs}{\adapt\pipe\ext}{\sigs''}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\ext}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Ext-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Ext-Snoc]{\adjact{\sigs}{\ext}{\sigs'} }
          {\adjact{\sigs}{\ext, \sig~\many{R}}{\sigs', \sig~\many{R}}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\adapt}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Adapt-Snoc]{\adjact{\sigs}{\adapt}{\sigs'} \\
    \adpcom{\sigs'}{\sig}{S}{S'}{\sigs''}}
          {\adjact{\sigs}{\adapt, \sig(S \to S')}{\sigs''}}
\end{mathpar}
$\boxed{\adpcom{\sigs}{\sig}{S}{S'}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Com]
  {\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv} \\
   \itrinst{\ienv}{S'}{\sig}{\ext} \\
   \adjact{\sigs'}{\ext}{\sigs''}}
  {\adpcom{\sigs}{\sig}{S}{S'}{\sigs''}}
\end{mathpar}

$\boxed{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}$
\begin{mathpar}
\inferrule[I-Pat-Id]{ }
          {\itrbnd{\sigs}{\pid}{\sig}{\sigs}{s : \sigs}}

\inferrule[I-Pat-Bind]{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}
          {\itrbnd{\sigs,\sig~\many{R}}{S~a}{\sig}{\sigs'}
            {\ienv,a:\sig~\many{R}}}

\inferrule[I-Pat-Skip]{
  \itrbnd{\sigs}{S~a}{\sig}{\sigs'}{\ienv} \\
  \sig \neq \sig'}
  {\itrbnd{\sigs,\sig'~\many{R}}{S~a}{\sig}
          {\sigs',\sig'~\many{R}}{\ienv}}
\end{mathpar}


$\boxed{\itrinst{\ienv}{S}{\sig}{\ext}}$
\begin{mathpar}
\inferrule[I-Inst-Id]{s\in\meta{dom}(\ienv)}
          {\itrinst{\ienv}{\pid}{\sig}{\id}}

\inferrule[I-Inst-Lkp]{a\in\meta{dom}(\ienv) \\
  \itrinst{\ienv}{S}{\sig}{\ext} \\
  \ienv(a)=\sig~\many{R}}
          {\itrinst{\ienv}{S~a}{\sig}{\ext,\sig~\many{R}}}
\end{mathpar}
%% \caption{Action of an Adaptor's Interface Component on an Ability}
\label{fig:interface-components}

\begin{figure}[t]
%% \figrule
\flushleft
$\boxed{\inferskgs{m}{A}}$ \quad $\boxed{\checkskgs{A}{n}}$
\begin{mathpar}
\inferrule[T-Freeze-Use]
  {\neg(\EC \handles c) \\
   \inferskgs{\EC[c~\many{R}~\many{w}]}{A}}
  {\inferskgs{\freeze{\EC[c~\many{R}~\many{w}]}}{A}}

\inferrule[T-Freeze-Cons]
  {\neg(\EC \handles c) \\
   \checkskgs{A}{\EC[c~\many{R}~\many{w}]}}
  {\checkskgs{A}{\freeze{\EC[c~\many{R}~\many{w}]}}}
\end{mathpar}
\caption{Frozen Commands}
\label{fig:frozen-typing}
%% \figrule
\end{figure}

\caption{Action of an Adjustment on an Ability and Auxiliary Judgements}
\label{fig:act-adj}
%% \figrule
\end{figure}


\begin{figure} % \figrule
\flushleft

\[
\mathcal{X} ::= A \gor C \gor T \gor G \gor Z \gor R \gor P
                  \gor \seed \gor \sigs \gor \ext \gor \adapt \gor \adj
                  \gor \Gamma \gor \exists \kenva.\Gamma \gor \ienv
\]

$\boxed{\kindchecksk{\mathcal{X}}}$
%% \boxed{\kindchecksk{C}}\boxed{\kindchecksk{T}}
%% \boxed{\kindchecksk{G}}\boxed{\kindchecksk{Z}}\boxed{\kindchecksk{R}}\boxed{\kindchecksk{P}}
%% \boxed{\kindchecksk{\seed}}\boxed{\kindchecksk{\sigs}}
%% \boxed{\kindchecksk{\ext}}\boxed{\kindchecksk{\adapt}}\boxed{\kindchecksk{\adj}}
%% \boxed{\kindchecksk{S}}\boxed{\kindchecksk{\Gamma}}\boxed{\kindchecksk{\ienv}}
%% $
\begin{mathpar}
\inferrule[WF-Val]
  { }
  {\kindchecks{\kenv, X}{X}}

\inferrule[WF-Eff]
  { }
  {\kindchecks{\kenv, [E]}{E}}

\inferrule[WF-Poly]
  {\kindchecks{\kenv, \many{Z}}{A}}
  {\kindchecks{\kenv}{\forall \many{Z}.A}}
\\
\inferrule[WF-Data]
  {(\kindchecksk{R})_i}
  {\kindchecksk{D~\many{R}}}

\inferrule[WF-Thunk]
  {\kindchecksk{C}}
  {\kindchecksk{\thunk{C}}}

\inferrule[WF-Comp]
  {(\kindchecksk{T})_i \\ \kindchecksk{G}}
  {\kindchecksk{\many{T \to}~ G}}

\inferrule[WF-Arg]
  {\kindchecksk{\adj} \\ \kindchecksk{A}}
  {\kindchecksk{\effin{\adj}A}}

\inferrule[WF-Ret]
  {\kindchecksk{\sigs} \\ \kindchecksk{A}}
  {\kindchecksk{\effout{\sigs}A}}

\inferrule[WF-Ability]
  {\kindchecksk{\sigs}}
  {\kindchecksk{[\sigs]}}

\inferrule[WF-Pure]
  { }
  {\kindchecksk{\nowt}}

\inferrule[WF-Id]
  { }
  {\kindchecksk{\id}}

\inferrule[WF-Ext]
  {\kindchecksk{\ext} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ext, \sig~\many{R}}}

\inferrule[WF-Adapt]
  {\kindchecksk{\adapt}}
  {\kindchecksk{\adapt, \sig~(S \to S')}}
\\
\inferrule[WF-Empty]
  { }
  {\kindchecksk{\cdot}}

\inferrule[WF-Mono]
  {\kindchecksk{\Gamma} \\ \kindchecksk{A}}
  {\kindchecksk{\Gamma, x : A}}

\inferrule[WF-Poly]
  {\kindchecksk{\Gamma} \\ \kindchecksk{P}}
  {\kindchecksk{\Gamma, f : P}}
\\

\inferrule[WF-Existential]
  {\kindchecks{\kenv, \kenva}{\Gamma}}
  {\kindchecksk{\exists \kenva.\Gamma}}

\inferrule[WF-Interface]
  {\kindchecksk{\ienv} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ienv, x : \sig~\many{R}}}

\end{mathpar}


\caption{Well-Formedness Rules}
\label{fig:well-formedness}

% \figrule
\end{figure}

\begin{figure} % \figrule
\flushleft
$\boxed{\matchesvk{A}{p}{\Gamma}}$
\begin{mathpar}
\inferrule[P-Var]
  { }
  {\matchesvk{A}{x}{x:A}}

\inferrule[P-Data]
  {k~\many{A} \in D~\many{R} \\
   (\matchesvk{A_i}{p_i}{\Gamma})_i}
  {\matchesvk{D~\many{R}}{k~\many{p}}{\many{\Gamma}}}
\end{mathpar}
$\boxed{\matchesck{T}{r}{\sigs}{\exists \kenva.\Gamma}}$
\begin{mathpar}
\inferrule[P-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\ \matchesvk{A}{p}{\Gamma}}
  {\matchesck{\effin{\adj}A}{p}{\sigs}{\Gamma}}

\inferrule[P-CatchAll]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\matchesck{\effin{\adj}A}{\effin{x}}{\sigs}{x:{\thunk{\effout{\sigs'}A}}}}

\inferrule[P-Command]
  {
   \adjact{\sigs}{\adj}{\sigs'} \\
   \adj = \adapt\pipe\ext \\
   c:\forall \many{Z}.\many{A \to} B \in \ext \\
   (\matchesv{\kenv, \many{Z}}{A_i}{p_i}{\Gamma_i})_i}
  {\matchesc{\kenv}
            {\effin{\adj}B'}
            {\effin{\handle{c~\many{p}}{z}}}
            {\sigs}
            {\exists \many{Z}.\many{\Gamma}, z:\{\effin{\id\pipe\id}B \to \effout{\sigs'}B'\}}}
\end{mathpar}
\caption{Pattern Matching Typing Rules}
\label{fig:pattern-typing}
%% \figrule
\end{figure}

% \section{First section}
% 
% Markers do not have to consider appendices. Make sure that your contributions
% are made clear in the main body of the dissertation (within the page limit).

\end{document}
