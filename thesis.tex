\documentclass[msc,deptreport,cs]{infthesis} % Do not change except to add your degree (see above).

%% Imports poached from frankly
%% STILL can't find what makes \figrule work
\usepackage{natbib}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{thmtools,thm-restate}
\usepackage{comment}
\usepackage{flushend}
\usepackage{listings}
\usepackage{lstlinebgrd}
%% \usepackage{beramono}

%% \lstdefinestyle{mystyle}{
%%     %% backgroundcolor=\color{backcolour},
%%     %% commentstyle=\color{codegreen},
%%     %% keywordstyle=\color{magenta},
%%     %% numberstyle=\tiny\color{codegray},
%%     %% stringstyle=\color{codepurple},
%%     breakatwhitespace=false,
%%     breaklines=true,
%%     captionpos=b,
%%     keepspaces=true,
%%     %% numbers=left,
%%     %% numbersep=5pt,
%%     showspaces=false,
%%     showstringspaces=false,
%%     showtabs=false,
%%     tabsize=2,
%%     %% basicstyle=\small\ttfamily
%%     basicstyle=\ttfamily\footnotesize,
%%     %% breaklines=true
%% }

%% \lstset{style=mystyle}

%% \lstset{escapeinside={<@}{@>}}

\lstset{
  %% basicstyle=\small\ttfamily\bfseries,
  basicstyle=\footnotesize\ttfamily\bfseries,
  %% basicstyle=\footnotesize\ttfamily,
  %% basicstyle=\small\ttfamily,
  breaklines=true,
  % For having lighter-coloured text inside listings
  % https://tex.stackexchange.com/questions/144448/color-a-text-line-in-a-code-lstlisting
  escapeinside={<@}{@>}
}


\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{xspace}
%% \usepackage[pdftex,
%%             pdfauthor={Sam Lindley, Conor McBride, and Craig McLauglin},
%%             pdftitle={Doo bee doo bee doo}]{hyperref}
%\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue}
%% \hypersetup{colorlinks=true,allcolors=black}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{url}

% get rid of hypertext link on \citeauthor
\usepackage{etoolbox}

\usepackage{amssymb}

\usepackage{mathtools} % allows flush-left align environments and paired
                       % delimiters.
                       %
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}


%% abstract for inline code
\newcommand{\code}[1]{\lstinline{#1}}
\newcommand{\codem}[1]{\lstinline[mathescape]{#1}}


\newcommand{\highlight}[1]{%
  \colorbox{red!20}{$\displaystyle#1$}}

\newcommand{\texthighlight}[1]{%
  \colorbox{red!20}{#1}}

\newcommand{\highlightout}[1]{%
  \colorbox{black!20}{$\displaystyle#1$}}

\newcommand{\greytext}[1]{\textcolor{black!40}{#1}}

\newcommand\aeff{{\AE}ff\xspace}

\newcommand\figscale{0.85}

\newcommand\nondetfrank{$\mathbb{F}_{\cal{ND}}$}
\newcommand\countingfrank{$\mathbb{F}_{\cal{C}}$}
\newcommand\treefrank{$\mathbb{F}_{\cal{T}}$}

\newcommand\feed{$\mathcal{F}$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\counter}{{\color{blue}c_y}}
\newcommand{\justc}[1]{{\color{blue} c({#1})}}
\newcommand{\yieldc}{{\color{blue}{\textsf{yield}}}}
\newcommand{\plusc}{{\color{blue} +_c}}
\newcommand{\threshc}{{\color{blue} t_y}}
\newcommand{\succc}[1]{\bluetext{#1 \plusc 1}}

\newcommand{\bluetext}[1]{{\color{blue}#1}}

\newcommand\yield{\textsf{yield}\xspace}
\newcommand\Yield{\textsf{Yield}\xspace}
\newcommand\allows{\textsf{allows}\xspace}


\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newcommand{\todo}[1]
           {{\par\noindent\small\color{RoyalPurple}
  \framebox{\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
    {\textbf{TODO:} #1}}}}

\newcommand{\interrupt}[1]{!(#1)}

\newcommand{\fighead}{\textbf}

\newcommand{\lameff}{$\lambda_{\text{eff}}$\xspace}
\newcommand{\lameffrow}{$\lambda_{\text{eff}}^\rho$\xspace}
\newcommand{\feff}{$F_\textrm{eff}$\xspace}
\newcommand{\impeff}{Implicit \lameff}
\newcommand\Frank{\emph{Frank}\xspace}

\newcommand\Cse{\textbf{Case}}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\many}{\overline}
\newcommand{\opt}[1]{#1^?}
\newcommand{\medvert}{\mid}

\newcommand{\sem}[1]{\llbracket{#1}\rrbracket}
\newcommand{\seml}{\left\llbracket}
\newcommand{\semr}{\right\rrbracket}

\newcommand{\mdo}{~\textbf{do}~}
\newcommand{\seq}{~\textbf{;}~}
\newcommand{\assn}[2]{{#1}~\leftarrow~{#2}}
\newcommand{\func}[2]{\text{#1}~{#2}}

\newcommand{\deno}[1]{\sem{#1}\rho}
\newcommand{\denoex}[2]{\sem{#1}#2}
\newcommand{\pc}[1]{\llparenthesis{#1}\rrparenthesis}

\newcommand{\TyVar}{\mathit{Var}}
\newcommand{\dom}{\mathit{dom}}
%\newcommand{\sub}{\subseteq}
\newcommand{\Star}{{\Large$\star$}}

\newcommand{\reducesto}{\longrightarrow}

\newcommand\ba{\begin{array}}
\newcommand\ea{\end{array}}

\newcommand{\bl}{\ba[t]{@{}l@{}}}
\newcommand{\el}{\ea}

\newcommand{\bstack}{\begin{array}[t]{@{}l@{}}}
\newcommand{\estack}{\end{array}}

\newenvironment{equations}{\[\ba{@{}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}
\newenvironment{eqs}{\ba{@{}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{clauses}{\ba{@{}l@{~}c@{~}l@{}}}{\ea}

\newenvironment{syn}{\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{syntax}{\[\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}

\newcommand{\judgeword}[1]{~\mathbf{#1}~}

%\renewcommand{\sig}{\Sigma}
%\renewcommand{\sigs}{\Sigma s}
\newcommand{\sigentails}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\hspace{-0.4ex}\text{-\!-}}\,}

%% \newcommand{\sigmodels}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\!\mathord{=}}\,}
% \newcommand{\sigentails}[1]{\vdash_{#1}}

\newcommand{\val}[3]  {#1 \vdash {#2} : {#3}}

\newcommand{\rt}[1]{\langle{#1}\rangle}   % returner type

\newcommand{\valg}{\val{\Gamma}}

%% \newcommand{\is}[4]  {#1 \sigentails{#2} {#3} \judgeword{is} {#4}}
%% \newcommand{\isgs}{\is{\Gamma}{\sigs}}

%% \newcommand{\cdoes}[4]{#1 \sigentails{#2} {#3} \judgeword{has} {#4}
%% \newcommand{\cdoesgs}{\cdoes{\Gamma}{\sigs}}


%% some options for rendering bidirectional typing judgements

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \in {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \ni {#4}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

\newcommand{\kindcheckbase}[3]{#2 \mathbin{#1} #3} % For well-kindedness of types
\newcommand{\inferbase}[5]{#1; #3 \mathbin{#2} {#4} \Rightarrow {#5}}
\newcommand{\checkbase}[5]{#1; #3 \mathbin{#2} #5 \mathbin{:} #4}
\newcommand{\patbase}[5]{{#1} \vdash {#4} \mathbin{:} {#3} \mathbin{#2} {#5}}
\newcommand{\bindbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \Rightarrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \Leftarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \uparrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \downarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \judgeword{infers} {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \judgeword{checks} {#4}}
%% \newcommand{\patbase}[4]{{#2} \judgeword{matches} {#3} \mathbin{#1} #4}

\newcommand{\makes}[5]{\inferbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\has}[5]{\checkbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\does}[4]{\checkbase{#1}{\vdash}{#2}{#3}{#4}}
\newcommand{\can}[4]{\makes{\kenv}{#1}{#2}{#3}{#4}}

\newcommand{\effs}[2]{{#1} \judgeword{does} {#2}}


% redefinitions for cbv type system
\newcommand{\kindchecks}[2]{\kindcheckbase{\vdash}{#1}{#2}} % Checks that a type is well-kinded
\newcommand{\infers}{\makes}
\newcommand{\checks}{\has}
\newcommand{\checksdef}{\does}
\newcommand{\matchesc}{\matches}
\newcommand{\matchesck}{\matchesc{\kenv}}

\newcommand{\infersk}{\makes{\kenv}}
\newcommand{\checksk}{\has{\kenv}}
\newcommand{\checksdefk}{\does{\kenv}}

\newcommand{\kindchecksk}{\kindchecks{\kenv}} % Checks that a type is well-kinded
\newcommand{\inferskgs}{\makes{\kenv}{\Gamma}{\sigs}}
\newcommand{\checkskgs}{\has{\kenv}{\Gamma}{\sigs}}
\newcommand{\checksdefkg}{\does{\kenv}{\Gamma}}


\newcommand{\adj}{\Delta}
\newcommand{\adapt}{\Theta}
\newcommand{\ext}{\Xi}
\newcommand{\sigs}{\Sigma}
\newcommand{\sig}{I}

\newcommand{\seed}{\sigma}

\newcommand{\effbox}[1]{[#1]}

\newcommand{\key}[1]{\mathbf{#1}} % keyword
\newcommand{\var}{\mathit}        % local variable or meta variable
\newcommand{\defaultvarname}[0]{x}

\newcommand{\op}{\mathsf}  % operator (command or computation)
\newcommand{\con}{\mathsf} % constructor (type or data)
\newcommand{\inter}{\mathsf} % interface
\newcommand{\str}[1]{\textrm{``#1''}} % string literal


\newcommand{\handleSymbol}{\rightarrow}
\newcommand{\handle}[2]{{#1} \handleSymbol {#2}}

\newcommand{\thunk}[1]{\{{#1}\}}

\newcommand{\force}[1]{{#1}!}

\newcommand{\emptylist}{[]}
\newcommand{\cons}{\mathbin{::}}
\newcommand{\concat}{\,\texttt{++}\,} %mathbin{+\!+}}
%\newcommand{\snoc}{\mathbin{:<}}
\newcommand{\snoc}{\ }


\newcommand{\NN}{\mathbb{N}}

\newcommand\slab[1]{(\textrm{#1})}

\newcommand{\ev}{E}
\newcommand{\evd}{\varepsilon}

\newcommand{\effin}[1]{\langle {#1} \rangle}
\newcommand{\effout}[1]{[{#1}]}

\newcommand{\nowt}{\emptyset}
\newcommand{\id}{\iota}
\newcommand{\pid}{\var{s}} % Pattern identity variable

\newcommand{\EC}{\mathcal{E}}
\newcommand{\EF}{\mathcal{F}}
\newcommand{\PC}{\mathcal{P}} % Syntactic phrase class for af operation
\newcommand{\venv}{\theta}

\newcommand{\freeze}{\ceil}

\newcommand{\uc}{\mathord{\downarrow}}
\newcommand{\cu}{\mathord{\uparrow}}

\newcommand{\redtou}{\leadsto_{\mathrm{u}}}
\newcommand{\redtoc}{\leadsto_{\mathrm{c}}}
\newcommand{\stepsto}{\longrightarrow}

\newcommand{\stepstou}{\longrightarrow_{\mathrm{u}}}
\newcommand{\stepstoc}{\longrightarrow_{\mathrm{c}}}

\newcommand{\sigat}{\mathbin{@}}

\newcommand{\meta}{\mathsf}
\newcommand{\level}{\meta{level}}
\newcommand{\af}{\meta{af}}
\newcommand{\handles}{~\meta{handles}~}

\newcommand{\poised}{~\meta{poisedfor}~}
\newcommand{\insts}{\meta{inst}}
\newcommand{\remap}{\meta{remap}}

\newcommand{\sigyields}[1]
           {\mathbin{\text{-\!-\!}[{\text{\scriptsize ${#1}$}}]\,}}

\newcommand{\matches}[5]{\patbase{#1}{\sigyields{#4}}{#2}{#3}{#5}}
\newcommand{\matchesv}[4]{\patbase{#1}{\dashv}{#2}{#3}{#4}}
\newcommand{\matchesvk}{\matchesv{\kenv}}

\newcommand{\bindsv}[4]{\bindbase{\dashv}{#2 \leftarrow #3}{#1}{#4}}
\newcommand{\bindsc}[5]{\bindbase{\sigyields{#4}}{#2 \leftarrow #3}{#1}{#5}}

\newcommand{\letin}[4][\defaultvarname]
           {\key{let}\;{#1}:{#2}={#3}\;\key{in}\;{#4}}
\newcommand{\letxin}[3][\defaultvarname]
           {\key{let}\;{#1}={#2}\;\key{in}\;{#3}}
\newcommand{\letrec}[4][f]{\key{letrec}~\many{{#1}:{#2} = {#3}}~\key{in}~{#4}}
\newcommand{\letrecU}[3][f]{\key{letrec}~\many{{#1} = {#2}}~\key{in}~{#3}}
\newcommand{\Gt}{\theta} % Substitution meta variable
\newcommand{\submap}[2]{{{#1}\vDash{#2}}}
\newcommand{\sub}[4]{#1 \vdash {{#2}:\submap{{#3}}{{#4}}}}
\newcommand{\subk}{\sub{\kenv}}
\newcommand{\subext}[2]{{{#1}{#2}}}
\newcommand{\subst}[3][\defaultvarname]{{#2}[{#3}/{#1}]}

% Frank letrec substitution
\newcommand{\recsub}[5][f]
      {[\many{\cu (\thunk{\many{\many{#2}\mapsto\letrec[{#1}]{#5}{#3}{#4}}}
            : {#5})/{#1}}]}


%%%% START inference rule system for action of adjustment on ability %%%%
\newcommand{\semi}{;}
\newcommand{\kenv}{\Phi}  % kind environment
\newcommand{\kenva}{\Psi} % another kind environment
%% \newcommand{\kenv}{\mathcal{T}} % kind environment
\newcommand{\ienv}{\Omega} % Instance environment
\newcommand{\adjact}[3]{{#1}\vdash{#2}\dashv{#3}}
\newcommand{\adpcom}[5]{{{#1}\vdash{#2}({#3} \to {#4})\dashv{#5}}}
\newcommand{\itrbnd}[5]{{{#1}\vdash{#2}:{#3}\dashv{#4}\semi{#5}}}
% \newcommand{\wf}[2]{{{#1}\vdash{#2}}}
\newcommand{\itrinst}[4]{{{#1}\vdash{#2}:{#3}\dashv{#4}}}

%%% END inference rule system for action of adjustment on ability %%%%%

% Untyped machine letrec substitution
\newcommand{\recsubst}[5]
 {{#1}[\many{(\thunk{\many{\many{#2} \mapsto \letrecU{#3}{#4}}}:{#5})/f}]}

%% Abstract machine commands
% Typing
\newcommand{\HAbs}[2]{{{#1}\to{#2}}}

\newcommand{\fail}{\textbf{fail}}

%% Translation function: Frank Terms to Untyped A-Normal Form
\newcommand{\UANF}[1]{{\llbracket{{#1}}\rrbracket}}

% Terms
\newcommand{\mtrns}[3][]{{#2} & \Rightarrow^{#1} & {#3}} % For array env
\newcommand{\mtrnsR}[3][]{{#2}\Rightarrow^{#1}{#3}}

\newcommand{\confg}[2]{{\langle{{#1}},{{#2}}\rangle}}
\newcommand{\term}[3]
           {{\langle{{#1}},{{#2}}\rangle\downarrow{#3}}}

\newcommand{\admin}[2]{{\langle{{#1}}\mid{{#2}}\rangle}}
\newcommand{\mat}[3]
           {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\rangle}}
\newcommand{\matc}[5]
        {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\mid{{#4}}\mid{{#5}}\rangle}}

\newcommand{\msub}[3][\defaultvarname]{{#2}[{#1}\mapsto{#3}]}

\newcommand{\FHan}[4][\many{\effin{\adj}}]{{({#2}:{#1},{#3}\mid{#4})}}
\newcommand{\FSeq}[2][\defaultvarname]
           {{({#1}.{#2})}}
\newcommand{\SCons}[2]{{{#1}\circ{#2}}}


\newcommand{\HSHan}[5][C]{{{#2}\circ({#3},{#1},{#4}\mid{#5})}}
\newcommand{\HSSeq}[4][\defaultvarname]
           {{#2}\circ({#1}:{#3}.{#4})}
\newcommand{\HSCons}[2]{{{#1}\circ{#2}}}
\newcommand{\NF}[2]{{{#1}~\star~{#2}}}

\newcommand{\evalto}{\Longrightarrow}


\newcommand{\para}[1]{\paragraph{#1.}}

\newcommand{\gor}{\mid}
\newcommand{\pipe}{\texttt{|}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of main text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{preliminary}

\title{Asynchronous Effect Handling}

\author{Leo Poulson}

\abstract{
  Features for asynchronous programming are commonplace in the programming
  languages of today, allowing programmers to issue tasks to run on other
  threads and wait for the results to come back later. These features are often
  built into the language, and are opaque to the user.

  In this thesis we show how a library for asynchronous programming can be very
  easily implemented in a language with existing support for effect handlers. We
  show how, with a small change to the language implementation, truly
  asynchronous programming with pre-emptive concurrency is achieved.

  Our system is expressive enough to define common asynchronous programming
  constructs, such as async-await and futures, within the language itself.
}

\maketitle

\section*{Acknowledgements}
thanks!

\tableofcontents

\end{preliminary}

\chapter{Introduction}

Effects, such as state and nondeterminism, are pervasive when programming; for a
program to do anything beyond compute a pure mathematical function, it must
interact with the outside world, be this to read from a file, make some random
choice, or run concurrently with another program. Algebraic effects and their
handlers (\cite{plotkin2013handling}) are a novel way to encapsulate, reason
about and specify computational effects in programming languages. For instance,
a program that reads from and writes to some local state can utilise the
\textsf{State} effect, which supports two \emph{operations}; \textsf{get} and
\textsf{put}. A handler for the \textsf{State} effect gives a meaning to these
abstract operations. Programming with algebraic effects and handlers is
increasingly popular; they have seen adoption in the form of libraries for
existing languages (\cite{kammar2013handlers, kiselyov2013extensible,
  brady2013programming}) as well as in novel languages designed with effect
handling at their core (\cite{bauer2015programming, leijen2017type, convent2020doo}).

Traditional effect handling is \emph{synchronous}; when an operation is invoked,
the rest of the computation pauses whilst the effect handler performs the
requisite computation and then resumes the original caller.
%
For many effects, this blocking behaviour is not a problem; the handler usually
returns quickly, and the user notices no delay. However, not every possible
computational effect behaves like this. Consider an effect involving a query to
a remote database. We might not want to block the rest of the computation whilst
we perform this, as the query might take a long time; this case is even stronger
if we do not immediately want the data. To support this kind of behaviour, we
need to be able to invoke and handle effects in an asynchronous, non-blocking
manner.

In this project we investigate the implementation and applications of
asynchronous effect handling. Our lens for this is the language
Frank~(\cite{convent2020doo}), a functional programming designed with effect
handlers at its core. We follow the design
of~\aeff~(\cite{ahman2020asynchronous}), a small programming language designed
around asynchronous effects but supporting little else.
%
% We show how, with a small change to the semantics of Frank, we can recreate the
% asynchronous effect handling behaviour of~\aeff~whilst enjoying the benefits of
% traditional effect handlers.
We show how by making a simple change to the semantics of Frank, in order to
yield pre-emptible threads, we can recreate the asynchronous effect handling
behaviour of \aeff~whilst still enjoying the benefits of traditional effect
handlers.

\todo{Last paragraph could be fixed}

Frank is well-suited to implement an asynchronous effects library. The fine-grained control over suspended computations makes it easy to treat code as data, and
\todo{Something else after the end}
% Frank is a well-suited language for an asynchronous effects library, especially
% because of the fine-grained control over suspended computations, making it very
% easy to treat code as data.
%
Despite this, our approach does not use any specific
Frank features; furthermore, the changes made to the semantics of Frank are
easily recreateable. It is our hope that these methods could be recreated in
another language equipped with first-class effect handlers.


\todo{Rewrite. Want to say that the change to the semantics is simple enough and
  the implementation simple enough that there should be no problems recreating
  our work in another language.}

Effect handlers have
already proven to make complicated control flow easy to implement
(\textbf{refs}), and our work further cements this viewpoint.

Our contributions are as follows;

\begin{itemize}
  %% \subparagraph*{Asynchronous Effects Library}
\item We present a library for programming with asynchronous effects, built in
  Frank. We show how a complex system can be expressed concisely and elegantly
  when programming in a language with effect handlers.
%% \todo{Rewrite the end of this; slightly
  %% messy}.

%% \subparagraph*{Pre-emptive Concurrency}
\item We show how, by making a small change to the operational semantics of
  Frank, we achieve \emph{pre-emptive concurrency}; that is, the suspension of
  running threads \emph{without} co-operation. It is our hope that this change
  is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples}
\item We also deliver a set of examples of the uses of asynchronous effects, and
  show how they have benefits to other models.
\end{itemize}

\section{Related Work}

Asynchronous programming with effect handlers is a fairly nascent field.
%
Koka (\cite{leijen2014koka}) is a programming language with built-in effect
handlers and a Javascript backend. \citeauthor{leijen2017structured} later shows
us how Koka can naturally support asynchronous programming
(\cite{leijen2017structured}). The asynchronous behaviour relies on offloading
asynchronous tasks with a \textsf{setTimeout} function supplied by the NodeJS
backend.

Multicore OCaml (\cite{dolan2014multicore}) also supports asynchronous
programming through effect handling (\cite{dolan2017concurrent}). They handle
effects and signals, which can be received asynchronously, and show how to
efficiently and safely write concurrenct systems programs. However, in a similar
way to Koka, the asynchrony relies on the operating system supplying operations,
such as \textsf{setSignal} and \textsf{timer} signals.

A problem shared by both Koka and Multicore OCaml is they have no support for
\emph{user-defined} asychronous effects; the asynchronous signals that can be
received are predefined. This problem is solved by
\aeff~(\cite{ahman2020asynchronous}), a small language built around asynchronous
effect handling. \citeauthor{ahman2020asynchronous} approach the problem of
asynchrony from a different perspective, by decoupling the invocation of an
effect from its handling and resumption with the handled value. When an effect
is invoked the rest of the computation is not blocked whilst the handler is
performed. Programs then install interrupt handlers that dictate how to act on
receipt of a particular interrupt. To recover synchronous behaviour, these
interrupt handlers can be \textsf{await}ed; this will block the rest of the code
until the interrupt is received.

\citeauthor{ahman2020asynchronous} then show how the simple building blocks of
interrupt handlers can be used to build common constructs for asynchronous
programming, such as cancellable remote function calls and a pre-emptive
scheduler.

\todo{Section on the expressivity?}

% We design our system based on \aeff, embedding its behaviour into Frank. We show
% that we can easily recover the behaviour of \aeff~when equipped with effect
% handlers, and show that asynchronous effects can still be used in conjunction
% with traditional, synchronous effects.

%
%The most prominent work is \aeff~(\cite{ahman2020asynchronous}),

%% \paragraph*{Contributions}

%% \subparagraph*{Asynchronous Effects Library} We present a library for programming
%% with asynchronous effects in the style of \aeff, built in Frank. We show how a
%% complex system can be expressed concisely and elegantly when programming in a
%% language with effect handlers, further cementing the case for effects as a
%% foundation for concurrent programming. \todo{Rewrite the end of this; slightly
%%   messy}.

%% \subparagraph*{Pre-emptive Concurrency} We show how, by making a small change to
%% the operational semantics of Frank, we achieve pre-emptive concurrency; that is,
%% the suspension of running threads \emph{without} co-operation. It is our hope
%% that this change is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples} We also deliver a set of examples of the uses of
%% asynchronous effects, and show how they have benefits to other models.

\section{Structure}

In Chapter~\ref{chap:programming-in-frank} we give an introduction to
programming with effects in Frank. We skip over some unneeded (and previously
well-covered) parts of the language, such as adaptors, in the interests of time.

In Chapter~\ref{chap:formalisation} we give the formalisation of Frank. Again,
we skip over extraneous details which can be seen in past work
(\cite{convent2020doo}), opting to only describe the parts needed to understand
the changes to the semantics for the following chapter.

In Chapter~\ref{chap:preemptive-concurrency} we show how by making a small
change to the semantics of Frank we yield pre-emptible threads; that is, we can
interrupt a function in the same co-operative style but without co-operation.

In Chapter~\ref{chap:implementation} we describe the implementation of our
asynchronous effect handling library in Frank. In Chapter~\ref{chap:examples} we
give examples of the new programs that become easily expressible when combined
with the changes made in Chapter~\ref{chap:preemptive-concurrency}.

In Chapter~\ref{chap:conclusion} we conclude.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Programming in Frank}
\label{chap:programming-in-frank}

Frank is a typed functional programming language, designed around the
definition, control and handling of algebraic effects. As such, Frank has an
effect type system used to track which effects a computation may use.

\todo{Extend this a bit - talk about ambient ability, computation vs. value, etc}

% Frank offers very fine-grained control over computations. It clearly
% distinguishes between computation and value, and offers \emph{multihandlers} to
% carefully control when computations are evaluated. This combined with effect
% handling provides a very rich foundation for expressing complex control
% structures.

In this chapter we introduce Frank, and show why it is so well-suited to our
task. We assume some familiarity with typed functional programming, and skip
over some common features of Frank --- algebraic data types, pattern matching,
etc. --- so we can spend more time with the novel, interesting parts. We also
skip some novel features of Frank, such as
adaptors~(\cite{convent2017enhancing}), as they are not essential for
understanding the work of this project.

\section{Types, Values and Operators}

Frank types are distinguished between \emph{effect types} and \emph{value
  types}. Value types are the standard notion of type; effect types are
used to describe where certain effects can be performed and handled. Value types are further divided into traditional data types, such a \code{Bool},
\code{List X}, and \emph{computation types}.

A computation type
%
\lstinline[mathescape]!{X$_1$ -> $\ldots$ -> X$_m$ -> [I$_1$, $\ldots$, I$_n$] Y}!
%
%% This type expresses that the operator can handle some effect in the first
%% argument and then performs some other effects as a result, returning a value of
%% type \code{Y}.
describes an operator that takes $m$ arguments and returns a value of type
\code{Y}. The return type also expresses the \emph{ability} the computation
needs access to, being a list of $n$ \emph{interface} instances. An interface is
a collection of \emph{commands} which are offered to the computation.

\todo{Go more into depth about 'abilities'?}

%% Frank then specialises effect handling to traditional function application; a
%% function is the special case of an operator that handles no arguments. We see
%% that a function type \code{\{X -> Y -> Z\}} is just a special case of the
%% general operator type where no effects are handled or performed. Throughout this
%% thesis, we call

\emph{Thunks} are the special case of an $n$-ary function that takes 0
arguments. We can evaluate them --- performing the suspended computation ---
with the 0-ary sequence of arguments, denoted \code{!}.
%
% Computations are suspended by wrapping them in braces.
The opposite action --- suspending a computation --- is done by surrounding the computation in braces, such that for a suspended computation \code{comp}, \code{\{comp!\}} is the identity.
%
This gives us fine-grained control over when we want to evaluate computations.


% For instance, we might want the sequential composition operator \code{snd} (also
% commonly known as the semicolon operator);

% \begin{lstlisting}
%   snd : {X -> Y -> Y}
%   snd x y = y
% \end{lstlisting}

% Frank is a left-to-right call-by-value language; arguments to functions are
% evaluated from left-to-right, until they become a value. In the case of
% \code{snd}, \code{x} is first evaluated, then \code{y}, which is finally
% returned. Compare this to \code{if};

% \begin{lstlisting}
% if : {Bool -> {X} -> {X} -> X}
% if true  yes no = yes!
% if false yes no = no!
% \end{lstlisting}

% \noindent The branches are given as thunks, where a single thunk is evaluated
% depending on the condition. If we did not take this approach both cases would be
% evaluated, which is clearly not the intended semantics of \code{if}. Frank's
% distinction between computation and value make controlling evaluation simple and
% pleasing.

Consider the operator \code{badIf} below;

\begin{lstlisting}
badIf : {Bool -> X -> X -> X}
badIf true  yes no = yes
badIf false yes no = no
\end{lstlisting}

\noindent Frank is a \emph{left-to-right}, \emph{call-by-value} language; all
arguments to operators are evaluated from left-to-right until they become a
value. As such, in the case of \code{badIf}, both of the branches will be
evaluated before the result of one of them is returned. We can recover the
correct semantics for \code{if} by giving the branches as thunks;

\begin{lstlisting}
if : {Bool -> {X} -> {X} -> X}
if true  yes no = yes!
if false yes no = no!
\end{lstlisting}

\noindent Here a single thunk is evaluated depending on the value of the
condition. Frank's distinction between computation and value make controlling
evaluation simple and pleasing.


%% \todo{Example --- maybe fire missiles one?}

\section{Effects and Effect Handling}
\label{sec:effects}

\paragraph*{Interfaces and Operations}

Frank encapsulates effects through \emph{interfaces}, which offer
\emph{commands}. For instance, the \code{State} effect (interface) offers two
operations (commands), \code{get} and \code{put}. In Frank, this translates to

\begin{lstlisting}
  interface State X = get : X
                    | put : X -> Unit

  interface RandInt = random : Int
\end{lstlisting}

The type signatures of the operations mean that \code{get} is a 0-ary operation
which is \emph{resumed} with a value of type \code{X}, and \code{put} takes a
value of type \code{X} and is resumed with \code{unit}. Computations get access
to an interface's commands by including them in the \emph{ability} of the
program. Commands are invoked just as normal functions;

\begin{lstlisting}
  xplusplus : {[State Int] Unit}
  xplusplus! = put (get! + 1)
\end{lstlisting}

\noindent This familiar program increments the integer in the state by 1.

\paragraph*{Handling Operations}

%% Traditional functions in Frank are a specialisation of Frank's handlers; that is
%% to say, functions are handlers that handle no effects. A handler for an
%% interface pattern matches \emph{on the operations} that are invoked, as well as
%% on the \emph{values} that the computation can return. Furthermore, the handler
%% gets access to the \emph{continuation} of the calling function as a first-class
%% value. Consider the handler for \code{State};

A handler for a specific interface can also pattern match on the
\code{operations} that are performed, and not just the values that can be
returned. As an example, consider the canonical handler for the \code{State S}
interface.

\begin{lstlisting}
  runState : {<State S> X -> S -> X}
  runState <get -> k>   s = runState (k s) s
  runState <put s -> k> _ = runState (k unit) s
  runState x            _ = x
\end{lstlisting}

%% \noindent The type of \code{runState} expresses that the first argument is a
%% computation that can perform \code{State S} effects and will eventually return a
%% value of type \code{X}, whilst the second argument is a value of type \code{S}.

\noindent Observe that the type of \code{runState} contains \code{<State S>},
called an \emph{adjustment}. This expresses that the first argument can perform
commands in the \code{State S} interface, and that \code{runState} must handle
these commands if they occur.

\subparagraph*{Computation Patterns}
The second and third lines specify how we handle \code{get} and \code{put}
commands. Observe that we use a new type of pattern, called a \emph{computation
  pattern}; these are made up of a command and some arguments (which are also
values), plus the continuation of the calling code. The types of arguments and
the continuation are determined by the interface declaration and the type of the
handler; for instance, in \code{<get -> k>} the type of \code{k} is \code{\{S ->
  [State S] X\}}. The continuation can then perform more \code{State S} effects.
This differs to some other implementations of effect handling languages
\todo{Add references} where the handlers are \emph{deep}, meaning the
continuation has been re-handled by the same handler automatically. Frank's
\emph{shallow} handlers mean we have to explicitly re-handle the continuation,
but have the benefit of giving more control over how we would like to do so.

%% What happens when we run \code{runState xplusplus! 0}? When a computation is
%% invoked, it is performed until it results in either a \emph{value} or a
%% \emph{command}. Thus, \code{runState} will be paused until \code{xplusplus!}
%% reduces; \code{runState} is resumed when \code{xplusplus} is in one of these two
%% forms.

%% \code{xplusplus} instantly invokes \code{get!}. At this point, control is given
%% to the handler \code{runState}; both in the sense that \code{runState} is now
%% being executed by the interpreter, and that \code{runState} has control over the
%% \emph{continuation} of \code{xplusplus}, which is a function of type \code{Int
%%   -> [State Int] Unit}. We see that \code{runState} chooses to resume this
%% continuation with the value of the state at that time.

\paragraph*{Effect Forwarding}

Effects that are not handled by a particular handler are left to be forwarded up
to the next highest one. For instance, we might want to write a random number to
the state;

\begin{lstlisting}
  xplusrand : {[State Int, RandomInt] Unit}
  xplusrand! = put (get! + random!)
\end{lstlisting}

\noindent We then have to handle both the \code{State Int} and \code{Random}
effect in this computation. Of course, we could just define one handler for both
effects; however in the interests of \emph{modularity} we want to define two
different handlers for each effect and \emph{compose} them. We can reuse the
same \code{runState} handler from before, and define a new handler for
\code{RandomInt} to generate pseudorandom numbers;

\begin{lstlisting}
  runRand : {Int -> <RandomInt> X -> X}
  runRand seed <random -> k> = runRand (mod (seed + 7) 10) (k seed)
  runRand _ x = x
\end{lstlisting}

\noindent And compose them in the comfortable manner, by writing \code{runRand
  (runState xplusrand!)}.

Observe that the interaction between \code{xplusrand} and the handlers becomes
like a conversation; the caller asks the handler for a result and waits,
blocking, until the handler responds. We can characterise this as
\emph{synchronous} effect handling. But what if we want to make a request for
information --- such as the pseudorandom number --- and do something else, then
pick it up later? We cannot just invoke \code{random} as this would block whilst
the number is generated, which could possibly take a long time. This
\emph{asynchronous} behaviour is exactly what we look for in this project.

\todo{Maybe show example of how the order of composition can change the ending
  semantics --- a la state + aborting}

\paragraph*{Top-Level Effects}
Some effects need to be handled outside of pure Frank, as Frank is not
expressive or capable enough on its own. Examples are console I/O, web requests,
and ML-style state cells. These effects will pass through the whole stack of
handlers up to the top-level, at which point they are handled by the
interpreter.



\paragraph*{Implicit Effect Polymorphism}

Consider the type of the well-known function \code{map} in Frank;

\begin{lstlisting}
  map : {{X -> Y} -> List X -> List Y}
  map f [] = []
  map f (x :: xs) = (f x) :: (map f xs)
\end{lstlisting}

\noindent One might expect that the program \code{map \{_ -> random!\} [1, 2, 3]}
would give a type error; we are mapping a function of type \code{\{Int ->
  [RandomInt] Int\}}, which does not match the argument type \code{\{X -> Y\}}.
However, Frank uses a shorthand for \emph{implicit effect variables}. The
desugared type of \code{map} is actually

\begin{lstlisting}[mathescape]
  map : {{X -> [$\epsilon$|] Y} -> List X -> [$\epsilon$|] List Y}
\end{lstlisting}

\noindent This type expresses that whatever the ability is of \code{map f xs} will be
offered to the element-wise operator \code{f}. As such, the following
typechecks;

\begin{lstlisting}
  writeRand : {List Int -> [RandomInt] List Int}
  writeRand xs = map {_ -> random!} xs
\end{lstlisting}

%% \todo{Talk about deliberately stopping this}

%% \todo{Talk about what the bar means. }

A similar thing happens in interface declarations. We might define the
\code{Choose} effect, which non-deterministically asks for one of two
computations to be picked for it to continue with;

\begin{lstlisting}
  interface Choose X =
      choose : {[Choose X] X} -> {[Choose X] X} -> X
\end{lstlisting}

\noindent This definition desugars to

\begin{lstlisting}[mathescape]
  interface Choose X [$\epsilon$] =
      choose : {[$\epsilon$| Choose X] X} -> {[$\epsilon$| Choose X] X} -> X
\end{lstlisting}

\noindent Once again, an implicit effect variable is inserted in every ability
available.

%% \paragraph*{Synchronicity and Conversations}
%% Observe how the interaction between the effect invoking function and the handler
%% of this effect becomes like a conversation; the caller asks the handler for a
%% response to an operation, and the caller will then wait, blocking, for a
%% response. We characterise this as \emph{synchronous} effect handling; the
%% operation caller and the handler synchronise to communicate.

%% But what if we want to make a request for information, then do something else,
%% then pick up the result later when we need it? This is the canonical example of
%% asynchronous programming. It is not as simple as just invoking our e.g.
%% \code{getRequest} effect; computation would block once this is invoked, meaning
%% we are stuck waiting for the request to return. This sort of behaviour is
%% exactly what we want to explore in this project.

%% \todo{Move this elsewhere}

%% \paragraph*{Multihandlers}

%% Recall that in Frank pure functions are just the special case of handlers that
%% handle no effects. Naturally, this notion extends to the $n$-ary case; we can
%% handle multiple effects from different sources are once. Handlers which handle
%% multiple effects simultaneously are unsurprisingly called \emph{multihandlers}.
%% This lets us write functions such as \code{pipe} (example due to~\cite{convent2020doo});

%% \begin{lstlisting}[numbers=left]
%% interface Send X = send : X -> Unit
%% interface Receive X = receive : X
 
%% pipe : {<Send X>Unit -> <Receive X>Y -> [Abort]Y}
%% pipe <send x -> s> <receive -> r> = pipe (s unit) (r x)
%% pipe <_> y = y
%% pipe unit <_> = abort!
%% \end{lstlisting}

%% Line 5 states that \code{pipe} will handle all instances of the \code{Send}
%% effect in the first argument, all instances of the \code{Receive} effect in the
%% second, and might perform \code{Abort} commands along the way. The matching
%% clauses are also new to the reader; line 6 implements the communication between
%% the two functions. We reinvoke \code{pipe}, passing the payload \code{x} of
%% \code{send} to the continuation of \code{r}. Lines 7 and 8 make use of the
%% \emph{catch-all} pattern, \code{<m>}. This will match the invocation of any
%% effect that is handled by that argument, or a value, binding this to \code{m}.
%% In line 7, the catchall pattern matches either a \code{send} command or a value;
%% in this case, the receiver has produced a value, so we can return that. In line
%% 8 \code{<_>} matches either a value or a \code{receive}; but it must be a
%% \code{receive} command, as the value case would have been caught above. The
%% \code{abort} command is then invoked, as this is erroneous. A recovery strategy
%% can be implemented by a handler for \code{Abort}.

\paragraph*{Polymorphic Commands}

As well as having polymorphic interfaces, such as \code{State X}, parametrised
by e|.g.~the data stored in the state, Frank supports polymorphic
\emph{commands}. These are commands which can be instantiated for any type. An
example is ML-style references, realised through the \code{RefState} interface;

\begin{lstlisting}
interface RefState = new X   : X -> Ref X
                   | read X  : Ref X -> X
                   | write X : Ref X -> X -> Unit
\end{lstlisting}

\noindent For instance, \code{new X} can be instantiated by supplying a value as
an argument. A \code{Ref X} cell is then returned as answer.

\section{Case Study: Cooperative Concurrency}
\label{sec:concurrency}

%% Frank is a single-threaded language. It is fortunate, then, that effect handlers
%% give us a malleable way to run multiple program-threads ``simultaneously'' \todo
%% {This is poorly written --- fix}.

Effect handlers have proved to be useful abstractions for concurrent programming
(\cite{dolan2015effective, dolan2017concurrent, hillerstrom2016compilation}).
This is partly because the invocation of an operation not only offers up the
operation's payload, but also the \emph{continuation} of the calling
computation. In Frank, these continuations are first-class. The handler for this
operation is then free to do what it pleases with the continuation. For many
effects, such as \code{getState}, nothing interesting happens to the
continuation and it is just resumed immediately. But these continuations are
first-class; they can resumed, but also stored elsewhere or even thrown away.

We illustrate this with some examples of concurrency in this section.

%
%As such, by handling
%% \code{Yield} operations, we easily pause and switch between several threads.

\subsection{Simple Scheduling}
\label{subsec:simple-scheduling}

We introduce some simple programs and some scheduling multihandlers, to
demonstrate how subtly different handlers generate different scheduling
strategies.

\begin{lstlisting}
interface Yield = yield : Unit

words : {[Console, Yield] Unit}
words! = print "one "; yield!; print "two "; yield!; print "three "; yield!

numbers : {[Console, Yield] Unit}
numbers! = print "1 "; yield!; print "2 "; yield!; print "3 "; yield!
\end{lstlisting}

First note the simplicity of the \code{Yield} interface; we have one operation
supported, which looks very boring; the operation \code{yield!} will just return
unit. It is the way we \emph{handle} yield that is more interesting. These two
programs will print some information out and yield inbetween each print
operation.

We can write a \emph{multihandler} to schedule these two programs. A
multihandler is simply an operator that handles multiple effects from different
sources simultaneously.

\begin{lstlisting}[numbers=left]
schedule : {<Yield> Unit -> <Yield> Unit -> Unit}
schedule <yield -> m> <yield -> n> = schedule (m unit) (n unit)
schedule <yield -> m> <n> = schedule (m unit) n!
schedule <m> <yield -> n> = schedule m! (n unit)
schedule _ _ = unit
\end{lstlisting}

When we run \code{schedule words! numbers!} we read \code{one 1 two 2 three 3
  unit} from the console. What happened? First \code{words} is evaluated until
it results in a \code{yield} command. Recall that Frank is a left-to-right
call-by-value language; at this point, we start evaluating the second argument,
\code{numbers}. This again runs until a \code{yield} is performed, where we give
control again to the scheduler. Now that both arguments are commands or values
we can proceed with pattern matching; the first case matches and we resume both
threads, handling again. This process repeats until both threads evaluate to
\code{unit}. In this way, we can imagine multihandler arguments as running in
parallel and then \emph{synchronising} when pattern matching is performed.

If we omit line 2 we get quite a different result; the console output would be
\code{one 1 two three 2 3}. This is because both threads are first evaluated
until they are either a command or a value; this prints out \code{one 1}. Here
we see the first use of the catch-all pattern \code{<n>}, which matches either a
command or a value. At this point we resume the first thread, but the second
thread remains blocked as the \code{yield} invocation has not been handled. We
evaluate the first thread until it is \code{unit}, at which point we do the same
to the second thread.

%% If we omit the first line of pattern matching (line 2) we get quite a different
%% result; the console output would be \code{one 1 two three 2 3}. This is because
%% both threads are evaluated until they are \code{yield} invocations, printing out
%% \code{one 1}; but then only the first thread is resumed. We then evaluate
%% \code{words} until it becomes a \code{unit} value. At this point the patterns on
%% line 4 match, as the catchall pattern \code{<m>} will match commands or values.
%% We then evaluate \code{numbers} until this is also \code{unit}.

%% \begin{lstlisting}
%% -- Runs all of the LHS first, then the RHS.
%% scheduleA : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleA <yield -> m> <n> = scheduleA (m unit) n!
%% scheduleA <m> <yield -> n> = scheduleA m! (n unit)
%% scheduleA _ _ = unit

%% -- Lets two yields synchronise, then handles both
%% scheduleB : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleB <yield -> m> <yield -> n> = scheduleB (m unit) (n unit)
%% scheduleB <yield -> m> <n> = scheduleB (m unit) n!
%% scheduleB <m> <yield -> n> = scheduleB m! (n unit)
%% scheduleB _ _ = unit
%% \end{lstlisting}

%% \todo{Can maybe delete the 2nd and 3rd matches of scheduleB to make the point
%%   more clear?}

%% We see two multihandlers above. Each take two \code{yield}ing threads and
%% schedule them, letting one run at a time. \code{scheduleA} runs the first thread
%% to completion, and only then runs the second one; the first time that the second
%% thread \code{yield}s it is \emph{blocked}, and can no longer execute. As such,
%% the output of \code{scheduleA words! numbers!} is \code{one 1 two three 2 3
%%   unit}.

%% \code{scheduleB} is fairer and more profound. We run \code{scheduleB words!
%%   number!} and receive \code{one 1 two 2 three 3 unit}; \code{scheduleB} is fair
%% and will ``match'' the yields together. We step through slowly. First
%% \code{words!} will print \code{one}, then it will \code{yield}. At this point
%% --- recalling that multihandlers pattern match left-to-right --- the second
%% thread, \code{numbers!}, is allowed to execute. In the meantime, \code{words!}
%% is stuck as \code{<yield -> m>}; it cannot evaluate any further, it is
%% \emph{blocked}. Whilst \code{words} is blocked \code{numbers!} prints \code{1}
%% and then \code{yield}s. Great; now the first case matches. Both threads are
%% resumed and the process repeats itself.

%% \todo{ The second paragraph here is a more compelling explanation; maybe we can
%%   just get rid of all of the scheduleA business and /just/ have the scheduleB
%%   stuff? scheduleA is quite obvious i think whilst B is more subtle and compelling. }

%% \todo{ It's not true that it matches L-R as much as runs all computations L - R
%%   until they are all a command / value - fix this }

\subsection{Forking New Processes}

We can make use of Frank's higher-order effects to dynamically create new
threads at runtime. We strengthen the \code{Yield} interface by adding a new
operation \code{fork};

\begin{lstlisting}
  interface Co = fork : {[Co] Unit} -> Unit
               | yield : Unit
\end{lstlisting}

The type of \code{fork} expresses that \code{fork} takes a suspended computation
that can perform further \code{Co} effects, and returns unit when handled. We
can now run programs that allocate new threads at runtime, such as the below

\begin{lstlisting}
forker : {[Console, Co [Console]] Unit}
forker! = print "Starting! ";
          fork {print "one "; yield!; print "two "};
          fork {print "1 "; yield!; print "2 "};
          exit!
\end{lstlisting}

We can now choose a strategy for handling \code{fork} operations; we can either
lazily run them, by continuing our current thread and then running them, or
eagerly run them, suspending the currently executing thread and running the
forked process straight away. The handler for the former, breadth-first style of
scheduling, is;

\begin{lstlisting}
scheduleBF : {<Co> Unit -> [Queue Proc] Unit}
scheduleBF <fork p -> k> = enqueue {scheduleBF (<Queue> p!)};
                           scheduleBF (k unit)
scheduleBF <yield -> k>  = enqueue {scheduleBF (k unit)};
                           runNext!
scheduleBF unit          = runNext!
\end{lstlisting}

\noindent where the operations \code{enqueue} and \code{runNext} are offered by
the \code{Queue} effect. We have to handle the computation \code{scheduleBF
  forker!} with a handler for \code{Queue} effects afterwards. We can abstract
over different queue handlers for even more possible program combinations.
Moreover, notice how concisely we can express the scheduler; this is due to the
handler having access to te continuation of the caller, and treating it as a
first-class object that can be stored elsewhere. We can see a diagram of how
\code{scheduleBF} treats continuations in Figure~\ref{fig:scheduleBF}, and a
similar diagram of how the depth-first handling differs in
Figure~\ref{fig:scheduleDF}.

%% \begin{figure}
%%   \centering
%%   \begin{subfigure}
%%     \includegraphics[width=0.8\textwidth]{imgs/scheduleBF.png}
%%     \caption{Breadth-First scheduling}\label{fig:scheduleBF}
%%   \end{subfigure}
%%   \begin{subfigure}
%%     \includegraphics[width=0.8\textwidth]{imgs/scheduleDF.png}
%%     \caption{Depth-First scheduling}\label{fig:scheduleDF}
%%   \end{subfigure}
%% \end{figure}

\chapter{Formalisation of Frank}
\label{chap:formalisation}

The formalisation of the Frank language has been discussed at length in previous
work~(\cite{convent2020doo}). However, in order to illustrate changes made to
the language in this work, we explain some of the relevant parts of the
language.

\begin{figure}[h]  %\figrule
\scalebox{\figscale}{%
\[
\ba{@{}c@{}}
\ba{@{}c@{\quad\quad}c@{}}
\begin{syn}
  \slab{data types}            & D \\
  \slab{value type variables}  & X \\
  \slab{effect type variables} & E \\
  \slab{value types}           & A, B   &::= & D~\overline{R} \\
                               &        &\gor& \thunk{C} \gor X \\
  \slab{computation types}     & C      &::= & \many{T \to}~G \\
  \slab{argument types}        & T      &::= & \effin{\adj}A \\
  \slab{return types}          & G      &::= & \effout{\sigs}A \\

  \slab{type binders}          & Z      &::= & X \gor [E]\\
  \slab{type arguments}        & R      &::= & A \gor [\Sigma]\\
  \slab{polytypes}             & P      &::= & \forall \overline{Z}.A \\
\end{syn}
&
\begin{syn}
  \slab{interfaces}           & I \\
  \slab{term variables}       & x, y, z, f \\
  \slab{instance variables}   & \pid, a, b, c \\
  \slab{seeds}                & \seed  &::= & \nowt \gor \ev \\
  \slab{abilities}            & \sigs  &::= & \seed\pipe\ext \\
  \slab{extensions}           & \ext   &::= & \id \gor \ext, \sig~\many{R} \\
  \slab{adaptors}             & \adapt &::= & \id \gor \adapt, \sig(S \to S') \\
  \slab{adjustments}          & \adj   &::= & \adapt\pipe\ext \\
  \slab{instance patterns}    & S      &::= & \pid \gor S \snoc a \\
  \slab{kind environments}    & \kenv,
                                \kenva &::= & \cdot \gor \kenv, Z \\
  \slab{type environments}    & \Gamma &::= & \cdot \gor \Gamma, x:A %\\
%                              &        &    & \hphantom{\cdot}
                                              \gor \Gamma, f:P\\
 \slab{instance environments} & \ienv  &::= & \pid:\sigs \gor \ienv, a:\sig~\many{R}\\
\end{syn} \\
\ea \\
\ea
\]}
%% \\[0.25cm]

\caption{Types}
\label{fig:types}
%\figrule
\end{figure}

\paragraph*{Types}
Value types are either datatypes instantiated with type arguments
$D~\overline{R}$, thunked computations $\thunk{C}$, or value type variables $X$.
%
Computation types are of the form

\[
  C = \effin{\adapt_1\pipe\ext_1}A_1 \to \dots \to \effout{\sigs} B
\]

\noindent where a computation of type $C$ handles effects in $\ext_i$ or pattern
matches in $A_i$ on the $i$-th argument and returns a value of type $B$. $C$ may
perform effects in ability $\sigs$ along the way.
%
The $i$-th argument to $C$ can perform effects in $\sigs$ adapted by adaptor
$\adapt_i$ and augmented by extension $\ext_i$.

An ability $\sigs$ is an extension $\ext$ plus a seed, which can be closed
($\nowt$) or open $\ev$. This lets us explicitly choose whether a function can
be effect polymorphic, as discussed earlier. An extension $\ext$ is a finite
list of interfaces.

%% We deliberately leave out details on adaptors for the sake of brevity. We also
%% skip over the typing rules, as they are standard. These can be seen in the
%% appendix.

We omit details on adaptors as they are present in previous work
(\cite{convent2020doo}). The same goes for the typing rules, which we do not
change.

\begin{figure} %\figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
  %% \slab{monomorphic term variables} & x, y, z \\
  %% \slab{polymorphic term variables} & f \\
  \slab{constructors}               & k \\
  \slab{commands}                   & c \\
  \slab{uses}                 & m      &::= &
     x \gor f~\many{R} \gor m~\many{n} \gor \cu(n:A) \\
  \slab{constructions}        & n      &::= &
    \uc m \gor k~\many{n} \gor c~\many{R}~\many{n} \gor \thunk{e} \\
                              &        &\gor& \key{let}~f : P = n~\key{in}~n'
                                   \gor
                                   \key{letrec}~\many{f : P = e}~\key{in}~n \\
                              &        &\gor&  \effin{\adapt}~n \\
  \slab{computations}         & e      &::=& \many{\many{r} \mapsto n}
  \\
  \slab{computation patterns} & r      &::=& p
                                        \gor \effin{\handle{c~\many{p}\,}{z}}
                                        \gor \effin{x} \\
  \slab{value patterns}       & p      &::=& k~\many{p} \gor x        \\
\end{syntax}
}
%% \\[0.25cm]
%\textit{with} term variables $x$, $y$, $z$, polymorphic term variables $f$, constructors $k$, commands $c$\\[0.25cm]
\caption{Terms}
\label{fig:terms}
% \figrule
\end{figure}

\paragraph*{Terms} Frank uses bidirectional typing (\cite{pierce2000local}); as such, terms are
split into \emph{uses} whose types are inferred, and \emph{constructions}, which
are checked against a type. Uses are monomorphic variables $x$, polymorphic
variable instantiations $f~\many{R}$, applications $m~\many{n}$ and type
ascriptions $\cu(n:A)$. Constructions are made up of uses $\uc m$, data
constructor instances $k~\many{n}$, suspended computations $\thunk{e}$, let
bindings $\key{let}~f : P = n~\key{in}~n'$, recursive let $\key{letrec}~\many{f
  : P = e}~\key{in}~n$ and adaptors $\effin{\adapt}~n$. We can inject a use into
a construction and vice versa ($\uc$, $\cu$); in real Frank code these are not
present.

Computations are produced by a sequence of pattern matching clauses. Each
pattern matching clause takes a sequence $\many{r}$ of computation patterns.
These can either be a request pattern $\effin{\handle{c~\many{p}\,}{z}}$, a
catch-all pattern $\effin{x}$, or a standard value pattern $p$. Value patterns
are made up of data constructor patterns $k~\many{p}$ or variable patterns $x$.

\paragraph*{Runtime Syntax}

The operational semantics uses the runtime syntax of
Figure~\ref{fig:runtime-syntax}.
%
Uses and constructions are further divided into those which are values. Values
are either variable or datatype instantiations, or suspended computations.
%
We also declare a new class of \emph{normal forms}, to be used in pattern
binding. These are either construction values or \emph{frozen commands},
$\freeze{\EC[c~\many{R}~\many{w}]}$.
%
%% with a special term $\freeze{\EC[c~\many{R}~\many{w}]}$, of \emph{frozen
%%   commands}. We discuss these further later.
Frozen commands are used to capture a continuation's \emph{delimited
  continuation}. As soon as a command is invoked it becomes frozen. The entire
rest of the computation around the frozen command then also freezes (in the same
way that water behaves around ice), until we reach a handler for the frozen
command.

Finally we have evaluation contexts, which are sequences of evaluation frames.
The interesting case is $u~(\many{t}, [~],\many{n})$; it is this that gives us
left-to-right call-by-value evaluation of multihandler arguments.

\begin{figure}[t]
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{constructions}           & n   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}
\caption{Runtime Syntax}
\label{fig:runtime-syntax}
%% \figrule
\end{figure}

\paragraph*{Operational Semantics} Finally, the operational semantics are given
in Figure~\ref{fig:operational-semantics}.

The essential rule here is \textsc{R-Handle}. This relies on a new relations
regarding \emph{pattern binding} (Figure~\ref{fig:pattern-binding}).
$\bindsc{r}{T}{t}{\sigs}{\venv}$ states that the computation pattern $r$ of type
$T$ at ability $\sigs$ matches the normal form $t$ yielding substitution
$\venv$. The index $k$ is then the index of the earliest line of pattern matches
that all match. The conclusion of the rule states that we then perform the
substitutions $\many{\venv}$ that we get on the return value $n_k$ to get our
result. This is given type $B$.

\textsc{R-Ascribe-Use} and \textsc{R-Ascribe-Cons} remove unneeded conversions
from use to construction. \textsc{R-Let} and \textsc{R-LetRec} are standard.
\textsc{R-Adapt} shows that an adaptor applied to a value is the identity.

We have several rules regarding the freezing of commands. When handling a
command, we need to capture its delimited continuation; that is, the largest
enclosing evaluation context that does \emph{not} handle it.
\textsc{R-Freeze-Comm} expresses that invoked commands instantly become frozen;
\textsc{R-Freeze-Frame-Use} and \textsc{R-Freeze-Frame-Cons} show how the rest
of the context becomes frozen. These two rules rely on the predicate $\EC~
\textsf{handles}~c$. This is true if the context does indeed handle the
command $c$; i.e.\ it is a context of the form $u~(\many{t}, [~], \many{u'})$
where $u$ is a handler that handles $c$ at the index corresponding to the hole.
Thus, the whole term is frozen up to the first handler, at which point is it
handled with \textsc{R-Handle}.

The $\textsc{R-Lift}$ rules then express that we can perform any of these
reductions in any evaluation context.

\begin{figure}
%% \figrule
\flushleft
\scalebox{\figscale}{%
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
    \stepstou m'} \quad \boxed{n \stepstoc n'}$}

\centering
\scalebox{\figscale}{%
\\
\begin{mathpar}
\inferrule[R-Handle]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A \to}~\effout{\sigs}B})~\many{t} \redtou \cu ((\many{\venv}(n_k) : B)}

\inferrule[R-Ascribe-Use]
  { }
  {\cu(\uc u:A) \redtou u}

\inferrule[R-Ascribe-Cons]
  { }
  {\uc \cu (w : A) \redtoc w}

\inferrule[R-Let]
  { }
  {\key{let}~f:P = w~\key{in}~n \redtoc n[\cu (w : P)/f]}

\inferrule[R-LetRec]
  {\many{e = \many{\many{r} \to n}}}
  {%\vphantom{\many{\many{\many{\many{f}}}}}
   \key{letrec}~\many{f:P = e}~\key{in}~n' \redtoc
    n'[\many{\cu (\thunk{\many{\many{r} \to \key{letrec}~\many{f:P = e}~\key{in}~n}}: P)/f}]}

\inferrule[R-Adapt]
  { }
  {\effin{\adapt}~w \redtoc w}

\inferrule[R-Freeze-Comm]
  { }
  {c~\many{R}~\many{w} \redtoc \freeze{c~\many{R}~\many{w}}}\\

\inferrule[R-Freeze-Frame-Use]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtou \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\inferrule[R-Freeze-Frame-Cons]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtoc \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\\
\inferrule[R-Lift-UU]
  {m \redtou m'}
  {\EC[m] \stepstou \EC[m']}

\inferrule[R-Lift-UC]
  {m \redtou m'}
  {\EC[m] \stepstoc \EC[m']}

\inferrule[R-Lift-CU]
  {n \redtoc n'}
  {\EC[n] \stepstou \EC[n']}

\inferrule[R-Lift-CC]
  {n \redtoc n'}
  {\EC[n] \stepstoc \EC[n']}
\end{mathpar}
}

\caption{Operational Semantics}
\label{fig:operational-semantics}
%% \figrule
\end{figure}

\paragraph*{Pattern Binding}

We now discuss the pattern binding rules of Figure~\ref{fig:pattern-binding}.

\begin{figure}
%% \figrule
\flushleft
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
$\boxed{\bindsc{r}{T}{t}{\sigs}{\venv}}$
}


\centering
\scalebox{\figscale}{%
\begin{mathpar}
\inferrule[B-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\\\ \bindsv{p}{A}{w}{\venv}}
  {\bindsc{p}{\effin{\adj}A}{w}{\sigs}{\venv}}

  \inferrule[B-Request]
    {%I~\many{R} \in \ext \\ %\capturesI{\Delta}{I}{\iota}\\
    \adjact{\sigs}{\adj}{\sigs'} \\
    \EC \poised c \\\\
    \adj = \adapt\pipe\ext \\
    c : \forall \many{Z}. \many{B \to}~B' \in \ext \\
    (\bindsv{p_i}{B_i}{w_i}{\venv_i})_i}
    {\bindsc{\effin{c~\many{p} \to z}}{\effin{\adj}A}
    {\freeze{\EC[c~\many{R}~\many{w}]}}{\sigs}{\many{\venv}[\cu (\thunk{x \mapsto \EC[x]} : \thunk{B' \to \effout{\sigs'}A})/z]}}
\\
\inferrule[B-CatchAll-Value]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{w}{\sigs}{[\cu (\thunk{w}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\\
\inferrule[B-CatchAll-Request]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  \EC \poised c \\\\
  \adj = \adapt\pipe\ext \\
  c : \forall \many{Z}. \many{B \to}~B' \in \ext
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}

\end{mathpar}

}

\flushleft
%~~ \textit{Value pattern $p$ for type $A$ matches $w$ and binds $\venv$.}
%
\scalebox{\figscale}{%
  $\boxed{\bindsv{p}{A}{w}{\venv}}$
  }

\centering
\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[B-Var]
  { }
  {\bindsv{x}{A}{w}{[\cu (w : A)/x]}}

\inferrule[B-Data]
  {k~\many{A} \in D~\many{R} \\
   (\bindsv{p_i}{A_i}{w_i}{\venv_i})_i}
  {\bindsv{k~\many{p}}{D~\many{R}}{k~\many{w}}{\many{\venv}}}
\end{mathpar}
  }

\caption{Pattern Binding}
\label{fig:pattern-binding}
%% \figrule
\end{figure}



\chapter{Pre-emptive Concurrency}
\label{chap:preemptive-concurrency}

\section{Motivation}
\label{sec:interrupt-motivation}

Our scheduler in Section~\ref{sec:concurrency} relies on threads \yield{}ing.
This is fine for small examples, but when working with longer programs this is
inconvenient; the programmer must insert \yield{}s with a consistent frequency,
so as to avoid process starvation. It would be better to just use some automatic
way of \yield{}ing.


%% One important part of our asynchronous effect handling system is the ability to
%% interrupt arbitrary computations. If two threads are running concurrently and
%% are communicating with one another, we have to stop running one to let messages
%% come in from the other. This is achievable with explicitly yielding, as in
%% Section~\ref{sec:concurrency}, however we would prefer for this behaviour to be
%% done automatically.

Consider the two programs below;

\begin{lstlisting}
controller : {[Stop, Go, Console] Unit}
controller! =
    stop!; print stop ; sleep 200000; go!; controller!

runner : {[Console] Unit}
runner! = print ``1 ``; print ``2 ``; print ``3 '';
\end{lstlisting}

%% \noindent We ideally want a multihandler that can run these two programs in
%% parallel, such that the console output will be \code{1 stop 2 stop 3 stop}; that
%% is to say, the \code{stop} and \code{go} operations from \code{controller} can
%% control the execution of \code{runner}.

\noindent We want a multihandler that uses the \code{stop} and \code{go} commands from
\code{controller} to control the execution of \code{runner}. The console output
of this multihandler should be then \code{1 stop 2 stop 3 stop}.
%
%We need
%% pre-emptive interruptions for this, as otherwise there would be no way for the
%% \code{stop} and \code{go} messages to be registered.

%% \section{Interruption with Yields}
%% \label{sec:yield-interruption}

%% One way we can get this behaviour is using the \code{Yield} interface. This
%% offers a single operation, \code{yield : Unit}. With this, we can write a
%% multihandler \code{suspend};

We can simulate this behaviour by using the familiar \code{Yield} interface from
Section~\ref{subsec:simple-scheduling}.

\begin{lstlisting}
runner : {[Console, Yield] Unit}
runner! = print "1 "; yield!; print "2 "; yield!; print "3 "; yield!

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

\noindent Running \code{suspend runner! controller! nothing} then prints out
\code{1 stop 2 stop 3} as desired.
%
This is due to the same synchronisation behaviour that we saw in
Section~\ref{subsec:simple-scheduling}; \code{runner} is evaluated until it
becomes a command or a value, and then \code{controller} is given the same
treatment. Once both are a command or a value, pattern matching is done.

This gives us the desired behaviour; the use of \code{yield} gives the
controller a chance to run, and also gives us access to the continuation of
\code{runner}. We can then use this to implement whatever scheduling strategy we
like.
%
We are, however, still operating co-operatively; the programmer has to manually
insert \code{yield} commands. If the programmer does not do so evenly enough
then either process could become starved. As such, we continue searching for a
better solution.

%% So far so good; this works as we hoped. However, observe that we had to change
%% the code of the \code{runner} to \code{yield} every time it prints.
%% %
%% %% We would rather not have this requirement; the threads should be suspendable
%% %% without knowing in advance they will be suspended, and thus without needing to
%% %% explicitly \code{yield}.
%% %
%% This is not in the spirit of pre-emptive concurrency; we are still operating
%% co-operatively. Threads should be unaware of the fact they are even being
%% pre-empted.
%% % The below line could maybe go...
%% Furthermore, see that the \code{yield} operation adds no more information; it is
%% just used as a placeholder operation; any operation would work.
%% %
%% As such, we keep searching for a better solution.

\section{Relaxing Catches}
\label{sec:relaxing-catches}

One approach is to relax the rules for pattern matching with the catchall
pattern $\effin{x}$. This would let us match generic commands that may not be
handled by the current handler. The key to implementing this lies in the pattern
binding rules of Figure~\ref{fig:pattern-binding}; specifically
\textsc{B-CatchAll-Request}.

%% The key to this lies in the catchall pattern, $\effin{x}$, and the pattern
%% binding rules of Figure~\ref{fig:pattern-binding}; specifically
%% \textsc{B-CatchAll-Request}. %We quickly go into detail on this rule now.
%
%% $\effin{x} : {\effin{\adj}A}$ states that $\effin{x}$ is a term with value type
%% $A$ and \emph{adjustment} $\adj = \adapt\pipe\ext$, made up of an adaptor
%% $\adapt$ and an extension $\ext$. This extension is made up of a list of
%% interface instantiations $\sig~\many{R}$.

The crux is that the command $c$ that is invoked in the frozen term
$\freeze{\EC[c~\many{R}~\many{w}]}$ must be a command offered by the extension
$\ext$; that is, it must be handled by the current use of \textsc{R-Handle}.
Refer back to the example of Section~\ref{sec:yield-interruption}. This rules
means that the catch-all pattern \code{<_>} in the final pattern matching case
of \code{suspend} can match against \code{stop} or \code{go}, as they are
present in the extension of the second argument, but not \code{print} commands;
although the \code{Console} interface is present in the ability of
\code{controller}, it is not in the extension in \code{suspend}.



%% Recall that the catchall pattern $\effin{x}$ matches either a value or a command
%% that is present in the term's ability. For instance, the pattern \code{<k>} in
%% the code above matches either \code{unit} or \code{<yield -> k>}. The variable
%% \code{k} is then bound to whatever this match is, leaving the (potentially)
%% invoked command unhandled. This is expressed in the \textsc{B-CatchAll-Request}
%% rule in Figure~\ref{fig:pattern-binding} (restated in
%% Figure~\ref{fig:loose-catchall-request}).

%% \todo{'Present in the term's ability' is incorrect, fix }


%% Important to note is that only effects that are handled in that position are
%% able to be caught. \code{runner} also makes use of the \code{print} effect, but
%% these are not able to be caught by the catchall command. Formally, this is due
%% to the fourth requirement of \textsc{B-CatchAll-Request}; that the command $c$
%% that is invoked is a member of $\ext$.

\begin{figure}[h]
%% \figrule
%% \flushleft
%% \centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
\begin{mathpar}
%% \\

\inferrule[B-CatchAll-Request-Loose]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  %% \EC \poised c \\\\
  %% \adj = \adapt\pipe\ext \\
  %% c : \forall \many{Z}. \many{B \to}~B' \in \ext
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}
\caption{Updated \textsc{B-CatchAll-Request}}
\label{fig:loose-catchall-request}
%% \figrule
\end{figure}

In the interests of pre-emption, we propose to remove this constraint from
\textsc{B-CatchAll-Request}, replacing the rule with
\textsc{B-CatchAll-Request-Loose} as seen in
Figure~\ref{fig:loose-catchall-request}. This lets us update the previous
\code{suspend} code to the following, which yields the same results as last
time;

\begin{lstlisting}
runner : {[Console] Unit}
runner! = print "1 "; print "2 "; print "3 "

suspend : {Unit -> <Stop, Go> Unit
    -> Maybe {[Console] Unit} -> [Console] Unit}
suspend <r> <stop -> c> _ =
    suspend unit (c unit) (just r)
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

\noindent Now when we run \code{suspend runner! controller! nothing}, the
\code{suspend} handler can match the catchall pattern \code{<r>} against the
\code{print} commands in \code{runner}.

The no-snooping policy with respect to effect handlers (\cite{convent2020doo})
states that a handler should not be able to intercept effects that it does not
handle. This change breaks this policy, as we can now tell when an command is
used. Whilst we can not handle it as per usual, we get the option to throw away
the continuation. A system that does not allow for snooping is much preferred.

\section{Freezing Arbitrary Terms}
\label{sec:freezing-terms}

The approach of Section~\ref{sec:relaxing-catches} can only interrupt command
invocations. If \code{runner} were instead a sequence of pure
computations\footnote{I.e. \code{runner! = 1 + 1; 1 + 1; 1 + 1}; $\ldots$} we would
be unable to interrupt it; it does not invoke commands.

As such, we need to further change the pattern binding rules of Figure
\ref{fig:pattern-binding}. This is to let us interrupt arbitrary computation
terms. In Figure~\ref{fig:runtime-syntax-freeze}, we see an updated version of
the runtime syntax; this allows for the suspension of arbitrary \emph{uses}.

\begin{figure}[t]
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & {\dots} \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{constructions}           & n   &::= & \dots \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}}\\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}

\caption{Runtime Syntax, Updated with Freezing of Uses}
\label{fig:runtime-syntax-freeze}
%% \figrule
\end{figure}


\begin{figure}[h]
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'}$
}

\scalebox{\figscale}{%
\centering
\begin{mathpar}

\inferrule[R-Freeze-Use]
  {  }
  { m \redtou \freeze{m} }

\inferrule[R-Freeze-Frame-Use]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtou \freeze{\EF[\EC[m]]} }

\inferrule[R-Freeze-Frame-Cons]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtoc \freeze{\EF[\EC[m]]} }

\end{mathpar}
}

\caption{Updated Freezing}
\label{fig:Freezing}
%% \figrule
\end{figure}

Note that frozen terms here behave in a similar way to frozen commands, by
freezing the rest of the term around it as well. This continues up until a
handler is reached, at which point the term is unfrozen and resumed. This
process of freezing up to a handler is enforced by the predicate $\EF \textsf{
  not handler }$, which is true only when $\EF$ is of the form $u~(\many{t},
[~], \many{n})$.

With this in mind, we now give the updated rule for the catchall pattern
matching on frozen terms. This can be seen in Figure \ref{fig:catchall-freeze}.
It expresses that an arbitrary frozen term can be matched against the
computation pattern $\effin{x}$. The suspended, unfrozen computation $\thunk{m}$
is then bound to $x$, in a similar way to other \textsc{B-CatchAll} rules.
Observe that this maintains no-snooping; we don't know that the frozen
computation performed an effect.

\begin{figure}[t]
%% \figrule
\flushleft

\scalebox{\figscale}{%
\centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\begin{mathpar}

\inferrule[B-CatchAll-Freeze]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{\freeze{m}}{\sigs}{[\cu (\thunk{m}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}

\caption{Unfreezing Computations Rule.}
\label{fig:catchall-freeze}
%% \figrule
\end{figure}

%% \begin{lstlisting}
%% suspend : {Unit -> <Stop, Go> Unit -> Maybe {[Console] Unit} -> [Console] Unit}
%% suspend <r> <stop -> c> _ =
%%     suspend unit (c unit) (just r)
%% suspend <_>          <go -> c>   (just res) =
%%     suspend res! (c unit) nothing
%% suspend unit         <_>         _ = unit
%% \end{lstlisting}

We can simply reuse the \code{suspend} handler from
Section~\ref{sec:relaxing-catches}. Everything works largely the same; we run the
leftmost argument until it freezes or invokes a command, at which point we run
the next argument. The frozen term can then be bound to the catch-all pattern, if
this is the pattern that matches.


\section{Yielding}
\label{sec:inserting-yields}

Observe that the freezing approach of Section~\ref{sec:freezing-terms} ends up
reimplementing a lot of the behaviour of the freezing of ordinary commands,
without adding much new behaviour. Furthermore, the term gets automatically
unfrozen at the closest handler, which may not be what we want. It turns out that
we can get the exact same behaviour by just inserting a command invocation into
the term instead, and handling this as normal.
%
%% This
%% will also freeze the computation up until the nearest handler of the inserted
%% command.

%% We use the familair \Yield~effect from Section~\ref{sec:concurrency} for this
%% task.

%% Observe that the approach of Section~\ref{sec:relaxing-catches} can only
%% interrupt command invocations. If \code{runner} were instead a sequence of pure
%% computations\footnote{I.e. \code{runner! = 1 + 1; 1 + 1; 1 + 1; ...}}, we would
%% be unable to interrupt it; it does not invoke commands. In this section we show
%% how we can easily interrupt \emph{arbitrary terms}, without defining any special
%% new syntax or constructions. Furthermore, we do this in a
%% way that lets the programmer choose how to resume the term, without being set in
%% stone.

Recall the simple \Yield~effect from Section~\ref{sec:concurrency}; it
supports one operation, $\yield : \textsf{Unit}$.
%
Whilst it sounds boring from the type, remember that the invocation of an effect
offers up the continuation of the program as a first-class value, so that they
might concurrently run the function with other functions or control execution by
some other means.

Our solution is simple; whenever we are in an evaluation context where the
ability contains the \Yield effect, we insert an invocation of \yield before the
term in question. This is expressed formally in Figure~\ref{fig:insert-yield}.
We refer to this system as \nondetfrank.

\todo{Add rules for eval ctxs converting use to const, use to use, etc}

\begin{figure}[h]
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{n \redtou n'} $
}

\scalebox{\figscale}{%
\begin{mathpar}

%
%
\inferrule[R-Yield-EF]
          { \EC~\textsf{allows}~\yield }
          { \EC[n] \redtou \EC[\textsf{yield!}; n] }
\end{mathpar}
}
%
%
\caption{Inserting Yields}
\label{fig:insert-yield}
%% \figrule
\end{figure}

%% Note that \textsc{R-Yield-EF} relies on the predicate
%% $\EF[\EC]~\allows~c$. This states that the \yield
%% interface is in the ability of the term in the evaluation context.

Note that \textsc{R-Yield-EF} relies on the predicate $\EC~\allows~c$. For any
frame apart from argument frames, $\EF[\EC]~\allows~c = \textsf{false}$. In this
case, it is defined as follows;

\begin{align*}
  \cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},[~],\many{n})~\allows~c =
  &~\ext_{|\many{t}|}~\allows~c ~ \\
  & \text{where}~\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|}% \adjact{\sigs}{\adj_{|\many{t}|}}{\sigs'}
\end{align*}


%% \noindent For an ability $\sigs = \seed\pipe\ext$, the predicate $\sigs~ \allows~c$ is true if
%% $c \in I$ for some $I \in \ext$.

\noindent For an extension $\ext$, the predicate $\ext~\allows~c$ is true if $c
\in I$ for some $I \in \ext$.

Informally, $\EC~\allows~c$ is true when $\EC$ is a handler, and the extension at
the hole contains an interface which offers \yield~as a command. For instance,
if a handler had type \code{\{<Yield>X -> Y -> [Yield]X\}}, the first argument
would be allowed to yield but the second would not.

We also make use of an auxiliary combinator $\_ ; \_$. This is the traditional
sequential composition operator $\textsf{snd}~x~y~\mapsto~y$, where both
arguments are evaluated and the result of the second one is returned. We see
that it would be a type error if we were to insert a \code{yield} command in a
context where \yield~was not a part of the ability. In the context of
\textsc{R-Yield-EF} this means we will perform the \yield~operation and then the
use $m$, but discard the result from \yield.

Observe that this gives us fine-grained control over which parts of our program
become asynchronous. One might want a short-running function to not be
pre-emptible and just run without pause; conversely, one might want a
long-running function to be interruptible. The programmer gets to choose this by
labelling the functions with \yield in the ability. This is one improvement over
the system of Section~\ref{sec:freezing-terms}, another being that we define
fewer new rules and constructs.

%% \todo{Talk about how this differs to the Freezing system}.

\paragraph*{Nondeterminism}

This system, and the system from Section~\ref{sec:freezing-terms}, are both
nondeterministic. This is because at any point we have the opportunity to either
invoke yield (respectively freeze the term), or continue as before.

Consider running \code{hdl (print "A") (print "B")}, for some binary
multihandler \code{hdl}. We could evaluate
\code{print "A"} first and then \code{print "B"}, or freeze \code{print "A"} and
evaluate \code{print "B"} first. Both of these would obviously result in
different things printed to the console.

\section{Counting}

%% The semantics given by Section~\ref{sec:inserting-yields} is fine, but is
%% non-deterministic; at any point, we can choose to either insert a \yield
%% invocation or carry on as normal. Furthermore, we do not particularly need to
%% yield very frequently; we might rather yield every 1000 reduction steps or so.

The system described in Section~\ref{sec:inserting-yields} is slightly
problematic; not only is it nondeterministic, but we can insert a \yield
whenever we want. If we spend too much time inserting and handling \yield
commands little other computation will be done.

To combat this we supplement the operational semantics with a counter
$\counter$. This counter has two states; it could either be counting up, which
is the form $\justc{n}$ for some $n$, or it is a signal to yield as soon as
possible, which is the form $\yieldc$.

To increment this counter, we use a slightly modified version of addition,
denoted $\plusc$. This is simply defined as

\begin{equations}
  x \plusc y =
          \left\{ \ba{@{}l@{\quad}l@{}}
              \justc{x + y} & \text{if } x + y \leq \threshc \\
              \yieldc & \text{otherwise}
          \right.
\end{equations}

\noindent where $\threshc$ is the threshold at which we force a yield.

The transitions in our operational semantics now become of the form $m; \counter
\redtou m'; \counter '$. In Figure~\ref{fig:counting-rules} we give an updated
rule for \textsc{R-Handle} --- overwriting the previous rule --- and two new
rules for inserting yields. We refer to this system as \countingfrank.

\begin{figure}
%% \figrule
\scalebox{\figscale}{%
\flushleft
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
    \stepstou m'} \quad \boxed{n \stepstoc n'}$
}

\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[R-Handle-Count]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~\many{t}; \justc{n}~
    \redtou~
    \cu ((\many{\venv}(n_k) : B)); n \plusc 1}

\\
\inferrule[R-Yield-Can]
          { \EC~\textsf{allows}~\yield }
          { \EC[m]; \yieldc~\redtou~\EC[\textsf{yield!}; m]; \justc{0} }
\\
\inferrule[R-Yield-Can't]
          { \neg (\EC~\textsf{allows}~\yield) \\
            m; \justc{n} \redtou m'; c' }
          { \EC[m]; \yieldc~\redtou~\EC[m]; \yieldc }
\\

\end{mathpar}
}

\caption{Yielding with Counting}
\label{fig:counting-rules}
%% \figrule
\end{figure}

\textsc{R-Handle-Count} replaces the previous rule \textsc{R-Handle}. If the
counter is in the state $\justc{n}$, we perform the handling as usual,
incrementing the counter by 1. Here we use $\plusc$, which will set the counter
to be $\yieldc$ if the addition brings it over the threshold value.

\textsc{R-Yield-Can} and \textsc{R-Yield-Can't} dictate what to do if we have to
yield as soon as possible. If the evaluation context allows \yield~
commands to be inserted we do so and reset the counter. If not, but the term
could otherwise reduce if the counter had a different value, then we make that
transition, still maintaining the $\yieldc$ signal.

\citeauthor{dolan2017concurrent} take a similar approach to this when
investigating asynchrony in Multicore OCaml (\cite{dolan2017concurrent}). They
rely on the operating system to provide a timer interrupt, which is handled as a
first-class effect. Our system is more self-contained; the timing is implemented
within the language itself and doesn't rely on the operating system providing
interrupts. Furthermore, we get fine-grained control over when the timer can
fire, as we can choose to put \yield~in the ability of interruptible
terms.

\paragraph*{Determinism}
Observe that the semantics of Frank equipped with the rules in
Figure~\ref{sec:counting-rules} are now deterministic; for any term and counter
pair, there is only one possible reduction we can make. This is a clear
improvement on the nondeterministic semantics of Section~\ref{sec:inserting-yields},
whilst still maintaining a similar behaviour; we are simply \emph{restricting}
the parts of the program where we can yield.

We can characterise this by saying that \countingfrank~\emph{implements}~
\nondetfrank; that is to say the counting system gives a deterministic way to
perform the nondeterministic system.

\begin{theorem}[Counting Implements Nondeterminism]
%% \begin{restatable}[Counting Implements Nondeterminsim]{theorem}{countimplynondet}\label{thm:count-impl-nondet}
\begin{itemize}
\item For any use $m$ and counter $\counter$, if $m, \counter~\redtou~
  m',\counter'$ in \countingfrank~ then $m~\redtou~m'$ in \nondetfrank.
\item For any construction $n$ and counter $\counter$, if $n, \counter~\redtou~
  n',\counter'$ in \countingfrank~ then $n~\redtou~n'$ in \nondetfrank.
\end{itemize}
%% \end{restatable}
\end{theorem}

One might consider a different approach, rather than a global counter, which
would also implement the nondeterministic semantics.

\section{Handling}
\label{sec:handling}

Observe that we can now use the same \code{suspend} handler from
Section~\ref{sec:interruption-with-yields}, without having to manually insert
\yield~commands in \code{runner}. Assuming the threshold $\threshc$ is set to 1, the
following code will give the desired output.

\begin{lstlisting}
runner : {[Console] Unit}
runner! = print "1 "; print "2 "; print "3 "

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend <yield -> r> <c>           = suspend (r unit) c!
suspend unit         <_>         _ = unit
\end{lstlisting}

The first argument is evaluated until the counter is greater than the threshold,
at which point a yield command is performed; the rest of the computation is then
frozen and the second argument is evaluated. Observe that the \Yield~interface
is not present in the adjustment of the second argument, so it is left to run
as normal.

We might also want to make the controller --- being the second argument ---
preemptible; it might do some other long-running computation in between
performing \code{stop} and \code{go} operations. We have to add \Yield to the
adjustment at the second argument, but also more pattern matching cases.

\begin{lstlisting}[]
suspend : {<Yield> Unit -> <Stop, Go, <@\texthighlight{Yield}@>> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
<@\texthighlight{
suspend <yield -> r> <yield -> c>  = suspend (r unit) (c unit)
}@>
<@\texthighlight{
suspend <yield -> r> <c>           = suspend (r unit) c!
}@>
<@\texthighlight{
suspend <r>          <yield -> c>  = suspend r! (c unit)
}@>
suspend unit         <_>         _ = unit
\end{lstlisting}

These let \yield~commands synchronise with each other, achieving fair scheduling,
as discussed in Section~\ref{sec:concurrency}. It is a bit annoying to write
these by hand, as they take up a lot of space and are orthogonal to the rest of
the logic of the handler.

It is fortunate then that this process of resuming as many yields as possible
can be automated completely. Given a multihandler with $m$ arguments, $n$ of
which have \Yield~in their adjustment, we first try and resume all $n$
\yield~commands. After this we try and resume all of the different permutations
of $n-1$ \yield~commands, and so on until we are trying to resume 0
\yield~commands.
%
%The resuming clauses for the 3-ary case can be seen below.

%% \begin{lstlisting}
%% sch3 : {<Yield> Unit -> <Yield> Unit -> <Yield> Unit -> Unit}
%% sch3 <yield -> h> <yield -> j> <yield -> k> =
%%     sch3 (h unit) (j unit) (k unit)

%% sch3 <yield -> h> <yield -> j> <k> = sch3 (h unit) (j unit) k!
%% sch3 <yield -> h> <j> <yield -> k> = sch3 (h unit) j! (k unit)
%% sch3 <h> <yield -> j> <yield -> k> = sch3 h! (j unit) (k unit)

%% sch3 <yield -> h> <j> <k> = sch3 (h unit) j! k!
%% sch3 <h> <yield -> j> <k> = sch3 h! (j unit) k!
%% sch3 <h> <j> <yield -> k> = sch3 h! j! (k unit)
%% \end{lstlisting}

These commands can be inserted generically at runtime. If no other hand-written
patterns match, we insert these patterns and try all of these. It is important
to try these after the rest of the patterns, as the use may want to handle
\yield~commands some other way; we do not want to interfere with this. This
means we can program in a direct manner, easily toggling which arguments
should be interruptible by adding \Yield~to the corresponding interface.

Automatically inserting \yield-handling clauses when combined with automatically
\emph{inserting} \yield~commands then gives us pre-emptive concurrency at no
overhead to the programmer.

\section{Starvation}

Consider the following program;

\begin{lstlisting}
  echo : {String -> [Console, Yield] Unit}
  echo st = print st; echo st

  sched : {<Yield> Unit -> <Yield> Unit -> Unit}
  sched unit unit = unit

  tree : {[Console] Unit}
  tree! = sched (echo "A ")
                (sched (echo "B ") (echo "C "))
\end{lstlisting}

We would like \code{tree!} to print out \code{"A B C A B C A B C ..."}. However, when
using the insertion and handling of \yield~commands as discussed, the result is
\code{"A B C B C B C ..."}. The \code{echo "A "} thread is \emph{starved} of
processor time. This happens because when \code{echo "B "} yields the command
is immediately handled by the lower \code{sched} handler and \code{echo "C "}
is ran (and vice versa). Ideally what we want is to break out of this cycle
and \yield~on top of the lower scheduler.

To do this we need to maintain a series of counters; one for each multihandler.
If we consider the \code{tree} as a tree where \code{echo} functions are at
the leaves and \code{sched} makes up the branches, we also can now yield at the
branches as well as the leaves.

We have to update the semantics with the following rules to make this possible.
Our transitions are now of the form $m, \bluetext{\many{\counter}} \redtou m',
\bluetext{\many{\counter}}$. This list of counters is the list of counters
\emph{above} the current term in this tree of multihandlers. For instance,
\code{echo "A "} will maintain the counter for \code{sched} directly above it;
but \code{echo "B "} maintains the counter for both multihandlers above. The
rules are shown in Figure~\ref{fig:tree-counting}. We label this system
\treefrank. As before, we adopt the syntactic sugar that if transitions are not
labelled with the counters then the counters remain unchanged.

\begin{figure}
%% \figrule
%% \flushleft
\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[Add-Counter]
          { \EC[n]; \bluetext{c_n, \ldots, c_1} \redtou \EC[n']; \bluetext{c_n,
              \ldots, c_1} \\
            \EF \textsf{ is handler }}
          { \EF[\EC[n]]; \bluetext{c_{n+1}, c_n, \ldots, c_1} \redtou
            \EF[\EC[n']]; \bluetext{c_{n+1}, c_n, \ldots, c_1}}
\\

\inferrule[R-Handle]
  { k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
    (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j} \\
    \forall~j\leq~n~.~\bluetext{c_j} \not = \yieldc
  }
  { \EC[\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A
          \to}~\effout{\sigs}B})~\many{t}]; \bluetext{c_n, \ldots, c_1}
    \redtou
    \EC[\cu ((\many{\venv}(n_k) : B))]; \bluetext{\succc{c_n}, \ldots, \succc{c_1}} }
\\

\inferrule[R-Yield-Can]
  { \EC~\allows~\Yield \\
    \forall~j\leq~(n-1)~.~\bluetext{c_j} \not = \yieldc
  }
  { \EC[m]; \bluetext{c_n, \ldots, c_2, \yield} \redtou \EC[\yield!; m];
    \bluetext{c_n, \ldots, c_2, \justc{0}}}
\\

\inferrule[R-Yield-Can't]
  { \neg (\EC~\allows~\Yield) \\
    \forall~j\leq~(n-1)~.~\bluetext{c_j} \not = \yieldc \\
    \EC[m]; \bluetext{c_n, \ldots, c_2, \justc{k}}~\redtou~\EC[m']; \bluetext{c_n,
      \ldots, c_2, c_1'}
  }
  { \EC[m]; \bluetext{c_n, \ldots, c_2, \yieldc} \redtou \EC[m'];
    \bluetext{c_n, \ldots, c_2, \yieldc} }
\\
\end{mathpar}
}
\caption{New counting, backwards ordered though}
\label{fig:tree-counting}
\end{figure}

\textsc{R-Yield-Can} and \textsc{R-Yield-Can't} are fairly similar to the rules
in Figure~\ref{fig:counting-rules}. The main difference is that we can only insert a
yield if every counter above ours is not also trying to \yieldc. This is
important as it gives priority to multihandlers higher up in our syntax tree.

\textsc{R-Handle} is also similar to previous versions of the rule. The
difference again is that we don't allow a transition if any of the earlier
counters are in the \yieldc~position; they must \yield~before we can progress.
Once we do handle the operation we increase all of the counters in the stack.

\todo{Check Add counter????}

Observe that this now means all threads scheduled in \code{tree} will get
processor time. As \code{echo ``B''} evaluates the counter at both schedulers is
incremented. They both pass over the threshold at the same time, and thus both
counters are in \yieldc. However, the lower scheduler is not allowed to insert a
\yield yet as the upper one blocks it. This is what the constraint
$\forall~j\leq~(n-1)~.~\bluetext{c_j} \not = \yieldc$ implements. Thus the
higher scheduler yields first, and \code{echo ``A''} gets processor time. With
this, we can express a liveness property of the new system.

\begin{theorem}[\treefrank~Liveness]
Given a multihandler $m$ with $n$ threads to be scheduled, any thread handled by
$m$ receives processor time in $n * \threshc$ \emph{local} reductions.
\end{theorem}

A local reduction is a reduction that happens underneath the multihandler in
question. In the function \code{tree} above, when \code{echo "A "} reduces it is
local to the top-level \code{sched} handler but not the lower one.

This directly implies that we do not have thread starvation in \treefrank~as we
do in \countingfrank.

\section{Soundness}

We now state the soundness property for our extended system, as well as the
subject reduction theorem needed for this proof. Our system is nothing more than
the system of~\citeauthor{convent2020doo} with extra rules; as such we omit most of
the details.

\begin{theorem}[Subject Reduction]\label{thm:sub-red}
\vskip
\begin{itemize}\\
\item If $\inferskgs{m}{A}$ and $m; \counter \redtou m'; \counter'$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n; \counter \redtoc n'; \counter'$ then $\checkskgs{A}{n'}$.
\end{itemize}
  \end{theorem}

\begin{proof}
The proof follows by induction on the transitions $\redtou, \redtoc$. We first
consider the two possible states for $\counter$. If it is in the form
$\justc{n}$, then the reduction rules are simply the same as
in~\cite{convent2020doo}, as we do not change the counter. The only exception to
this is the updated \textsc{R-Handle} rule, which is the same as before except
for modifications to the counter; regardless of the counter, the resulting term
$m'$ still remains the same type.

Thus the only new cases are \textsc{R-Yield-Can} and \textsc{R-Yield-Can't}.

\begin{itemize}
\item[\Cse] \textsc{R-Yield-Can}
  By the assumption we have that $\EC~\allows~\yield$. This only holds
  if the context is of the form
  \[\EC[~] = \cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},[~],\many{n'})\]

  Assume that
  \[\inferskgs{\cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},\EC'[n],\many{n'})}{B}\]

  From $\EC~\allows~\yield$ we know that $\yield \in \ext_{|\many{t}|}$ where
  $\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|}$.
  %
  Then by inversion on \textsc{T-App} we have
  $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{\EC'[n]}$ and
  $\adjact{\sigs}{\adj_{|\many{t}|}}{\sigs_{|\many{t}|}}$.
  %
  It follows than that
  $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{\EC'[\yield; n]}$, as
  we know that \yield~commands are permitted under ability $\sigs'_{|\many{t}|}$.
  %

  %% This follows from the assumption $\EC~\allows~\yield$, which
  %% entails that $\yield~\in~\sigs'_{|\many{t}|}$. Thus
  %% $\inferskgs{\EC[\yield; n]}{B}$.

\item[\Cse] \textsc{R-Yield-Can't}
  This case is more straightforward. By the assumption we have that the
  evaluation frame $\EF$ does not permit yielding, but the term inside the frame
  could otherwise reduce.

  Assume $\checkskgs{A}{\EF[n]}$, and therefore $\checkskgs{A'}{n}$. By the
  assumption and subject reduction, $\checkskgs{A'}{n'}$. Then clearly
  $\checkskgs{A}{\EF[n']}$.

\end{itemize}
\end{proof}




\begin{theorem}[Type Soundness]\label{thm:soundness}
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a unique
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a unique
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
%% In particular, if $\sigs = \nowt$ then either the term is a value $w$ or the
%% term can reduce by one step.
\end{theorem}

\begin{proof}
The proof proceeds by simultaneous induction on
$\infers{\cdot}{\cdot}{\sigs}{m}{A}$ and $\checks{\cdot}{\cdot}{\sigs}{A}{n}$.
\end{proof}

\todo{Talk about Soundness for \nondetfrank~as well as \countingfrank.}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{chap:implementation}

%% We now introduce the Frank library for programming with asynchronous effects.
%% %
%% Our design closely follows \aeff~(\cite{ahman2020asynchronous}), a language
%% designed around writing multithreaded programs using asycnhronous effects.

In this section we give a brief introduction to programming with asynchronous
effects, and introduce the Frank library for doing so.
%
Our design closely follwos \aeff~(\cite{ahman2020asynchronous}).

One can consider the traditional treatment of effect
handling~(\cite{kammar2013handlers}) as having three stages. First an operation
\textsf{op} is invoked. Then the handler for \textsf{op} --- being the
\emph{implementation} of \textsf{op} --- is evaluated until it returns some
value \textsf{V}. Finally, the continuation of the caller is resumed.

\todo{Check the maths here}

What makes effect handling \emph{synchronous} is that the three stages above
happen in order and straight away. As soon as \textsf{op} is invoked, the
handler is evaluated with the arguments to \textsf{op}. As soon as the handler
has reduced to a value, the continuation is resumed. \todo{Rewrite this bit.}
%
The \emph{asynchronous} treatment of effect handling decouples these three
stages; each of invoking an effect, evaluation of the handler, and resumption of
the caller are separate. This permits the non-blocking invocation of effects; we
invoke an operation and can continue the rest of the computation before the
operation has been handled.
%
The decoupling of operation invocation from handling has other benefits that we
discuss later in this section.
%
%% A secondary benefit of decoupling the components of effect handling is that
%% operations can be invoked

\todo{Talk about how these are all decoupled}

\section{Communication}

Consider a program \feed which lets the user scroll through an seemingly
infinite feed of information (example due to
\citeauthor{ahman2020asynchronous}). The program displays each item in the cache
of data as the user scrolls; the program simulates being infinite by
making a request for another cache of data whenever the user is nearly at the
end of the current cache. In this way, the user never notices the feed pausing
to download more data.

Asynchronous effects are particularly useful for writing \emph{multithreaded}
programs. We may have several other threads in addition to \feed, such as a
server and a user interface controller.

Using asynchronous effects, threads communicate with one another using
\emph{signals}, which are analogous to effect invocations. For instance, \feed
would use a \code{request} signal to ask for more data from the server. Signals
sent from other threads become \emph{interrupts} from the receiver's point of
view; for instance, \feed~would receive \code{response} interrupts from the server, containing the new cache of data.

Despite this example of fairly conventional, we remark that each signal need not
have a corresponding interrupt response and vice versa. For instance, in
Section~\ref{sec:pre-emptive-scheduling} we implement a pre-emptive scheduler,
which sends \code{stop} and \code{go} signals without expecting an interrupt as
a response.

\todo{Talk about potentially having the system intercept signals?}

% \todo{Write with a view to saying that this behaves asychronously; remember that
%   the user wants to imagine it's asynchronous and that the implementation is
%   just a kind of specialisation of this}

% How is this implemented with asynchronous effects? We have a number of operations
% here: \code{request} for when \feed~needs more information, \code{display d} to
% display data \code{d}, and then the \code{next} operation that \feed~responds
% to. Observe that from the point of view of \feed, \code{request} and
% \code{display} differ to \code{next}; the latter two are operations that
% \feed~performs, whilst \code{next} is an operation \feed~\emph{responds} to. We
% call the latter (outgoing) operations \emph{signals} and the former (incoming)
% opreations \emph{interrupts}.

\todo{Maybe highlight that there's not a material difference between sigs and
  interrupts and that it's just a naming thing}.

\todo{Maybe we don't need display?}


We define \emph{interrupt handlers} to dictate how to act when an interrupt is
received. An interrupt handler is a function of type \code{S -> Maybe \{R\}},
where \code{S} is a sum type made up of the possible interrupts that can be
received.
%
\todo{Fix the way we talk about S.}
%
The return type of the handler is \code{Maybe \{R\}} as we can choose \emph{not}
to handle the interrupt if we wish; this could be because it is the wrong type
of signal, or if some other condition regarding the interrupt is not
fulfilled\footnote{An interrupt handler which inspects the body of the interrupt
  before executing is called a \emph{guarded} interrupt handler. We see an
  example of guarded interrupt handling in
  Section~\ref{sec:pre-emptive-scheduling}.}.
%
An example of an interrupt handler is \code{boringFeed};

\begin{lstlisting}
data FeedSigs = nextItem | request | display String

boringFeed : {FeedSigs -> Maybe {[Console] Unit}}
boringFeed nextItem = just {print "10"}
boringFeed _ = nothing
\end{lstlisting}

\noindent Whenever we receive a \code{nextItem} interrupt we just print out
\code{10} and return unit. From henceforth we also refer to interrupt handlers
as \emph{promises}; an interrupt handler for \textsf{op} once installed is a
\emph{promise} to perform the given action once an \textsf{op} interrupt is
received.

\todo{Maybe get rid of this part.}

% Asynchrous effects are useful for writing \emph{multithreaded} programs. The
% program \feed~would be one thread of several; there might for instance be
% another thread which acts as a server and responds to \code{request} interrupts.
% We might then have another one which acts as the user interface and sends
% \code{nextItem} signals and responds to \code{display d} interrupts.

% The decoupling of invoking an operation and handling an operation means that an
% operation can be handled multiple --- or even 0 --- times, across different
% threads.



\todo{Talk about system?}

\todo{Talk about how one msg can start many handlers, etc}

\todo{Talk about signals converted to interrupts}

\section{An Interface for Asynchronous Effects}

To make our ideas more concrete, we introduce the Frank interface used for
programming with asynchronous effects. First of all we introduce the datatype
used to track the state of an installed promise, \code{Prom}.

\begin{lstlisting}
data Prom X = prom (Ref (PStatus X))
data PStatus X = waiting | done X | resume {X -> Unit}
\end{lstlisting}

A value of type \code{Prom X} is a reference to a value of type \code{PStatus
  X}. It is stored as a reference as we have to write to this cell from two
locations; the interrupt handler itself and the handler for \code{await}
commands (shown later in this section).
%
\todo{Justify reference better?}
%
\code{PStatus} has three constructors. The first, \code{waiting}, expresses that
the promise has not yet been fulfilled. The second, \code{done x}, expresses
that the promise has completed and resulted in a value, \code{x}. The third
option, \code{resume cont}, is used when a promise is awaited. The continuation
\code{cont} is the continuation offered by the calling code when the \code{await}
effect is performed. We see how this is handled later in this section.
\todo{Maybe go over this?}

\todo{Talk about caller not getting access to the Pid cell}

\begin{lstlisting}
interface Promise S =
    promise R : {S -> Maybe {<@\greytext{[Promise S, RefState, Yield]}@> R}}
             -> Prom R <@\greytext{[Promise S, RefState, Yield]}@>
  | signal : S -> Unit
  | await R : Prom R <@\greytext{[Promise S, RefState, Yield]}@> -> R
\end{lstlisting}

The entire \code{Promise} interface is polymorphic in the type of
\emph{signals} that threads can perform. However, the commands themselves are
polymorphic in the result types. \todo{Flesh this out / remove it.}

The \code{promise} command is used to install an interrupt handler; it
takes an interrupt handler and returns a \code{Prom R} value. The interrupt
handler can perform further \code{Promise S} effects, and must also have access
to the \code{RefState} interface; we show why later. The \code{Yield} interface
is also present so that interrupt handlers are themselves pre-emptible when
executed.

The \code{signal} command simply takes a value of the \code{S} type and returns
\code{unit}. When handling \code{signal sig}, all other threads are informed
that some thread has invoked the signal \code{sig}. At this point the other
threads are \emph{interrupted}, and all installed interrupt handlers are
evaluated against the signal. We revisit how interrupt handlers are executed
later.

\todo{Redo above}

Finally, the \code{await} command takes a \code{Prom R} cell and returns a value
of type \code{R}. Here we block and eventually return the value of the promise,
once it is available.

\section{In Action}

Let's revisit the infinitely scrolling feed example from earlier. When the user




%% \chapter{Implementation (Old)}

%% We now introduce the Frank library used for asynchronous effects.
%% %
%% Our design closely follows the design of \aeff~(\cite{ahman2020asynchronous}), a
%% language designed around writing multithreaded programs that communicate by
%% sending \emph{interrupts}. A thread dictates how it will respond to an interrupt
%% by installing an \emph{interrupt handler}, also known as a \emph{promise}.
%% %
%% %% These are analogous to traditional effects and handlers; an interrupt when
%% %% invoked is like the invocation of a command, and an interrupt handler is like an
%% %% effect handler.
%% Interrupts and interrupt handlers can be seen as a less expressive version of
%% effects and effect handlers; an interrupt handler describes how to behave on
%% receipt of an interrupt, but it does not get access to the continuation of the
%% caller.

%% Interrupts and interrupt handlers have one particularly compelling feature; when
%% we invoke an interrupt (in the case of synchronous effects, this is just
%% invoking a command), we can carry on computing the rest of the code whilst we
%% wait for a response. This is a stark difference to normal effects, where the
%% rest of the computation is blocked whilst we wait for an answer. The programmer
%% can then subsequently choose to await the response from interrupt, which blocks
%% computation until the interrupt handler has been fulfilled.

%% Unlike \aeff, our system does not track the use of asychronous effects in the
%% type system. It does, however, track the traditional effects that are permitted
%% in promises.


%% \paragraph*{}

%% \aeff's interrupt handlers are manifested in Frank through the \code{Promise}
%% interface. All of the keywords used in \aeff~are just operations of the
%% \code{Promise} interface, with the \code{promise} operation being a \emph{scoped}
%% operation (\cite{pirog2018syntax}).

%% %% \begin{lstlisting}
%% %% interface Promise <@\greytext{[E]}@> =
%% %%       promise R : Prom R <@\greytext{[E | Promise[E|], RefState, Yield]}@>
%% %%                -> Pid R  <@\greytext{[E | Promise[E|], RefState, Yield]}@>
%% %%     | signal : Sig -> Unit
%% %%     | await R : Pid R <@\greytext{[E | Promise[E|], RefState, Yield]}@> -> R

%% %% data Prom R <@\greytext{[E]}@> = prom {Sig -> Maybe {<@\greytext{[E|]}@>R}}

%% %% data Pid X = pid (Ref (PromiseStatus X))

%% %% data PromiseStatus X = empty | done X | resume {X -> Unit}
%% %% \end{lstlisting}

%% \begin{lstlisting}
%% interface Promise =
%%       promise R : Prom R <@\greytext{[Promise, RefState, Yield]}@>
%%                -> Pid R  <@\greytext{[Promise, RefState, Yield]}@>
%%     | signal : Sig -> Unit
%%     | await R : Pid R <@\greytext{[Promise, RefState, Yield]}@> -> R

%% data Prom R <@\greytext{[E]}@> = prom {Sig -> Maybe {<@\greytext{[E|]}@>R}}

%% data Pid X = pid (Ref (PromiseStatus X))

%% data PromiseStatus X = waiting | done X | resume {X -> Unit}
%% \end{lstlisting}

%% \noindent The \code{promise R} command is a polymorphic command which takes a
%% function of type \code{Sig -> Maybe \{[E|] R\}}. This function is an interrupt
%% handler; it dictates what to do on receipt of an interrupt, which is a thing of
%% type \code{Sig}. The return type of the interrupt handler is \code{Maybe \{[E|]
%%   R\}}; this is because the programmer has the chance to return \code{nothing},
%% which will mean the promise goes unfulfilled and waits for another message. The
%% programmer would want to do this on receipt of other types of message, or if a
%% certain condition regarding the interrupt is not fulfilled\footnote{Interrupt
%%   handlers which put conditions on the incoming interrupts are called
%%   \emph{guarded} interrupt handlers.}. An
%% interrupt handler corresponding to an asynchronous division could be;

%% \begin{lstlisting}
%%   div : {Sig -> Maybe {[Promise] Unit}}
%%   div (ask n d) = if (n > 0)
%%                      {just {signal (response (n / d))}}
%%                      {nohing}
%%   div _ = nothing
%% \end{lstlisting}

%% \noindent where we don't want to fire if the denominator is 0. We call the thunk
%% \code{signal (response (n / d))} the \emph{body} of the interrupt handler. We
%% say that an interrupt handler \emph{fires} if an interrupt is received that
%% results in a non-\code{nothing} value. Observe that whilst we can perform some
%% computation when deciding whether or not to fire based on an interrupt, the type
%% of \code{Prom R} restricts us so that we cannot perform any effects whilst
%% deciding; we may only perform effects in the body of the promise.

%% Once handled, \code{promise R} operation returns a \code{Pid R}. This contains
%% information about the status of the promise; it is either empty, to signify the
%% promise is unfulfilled, or it holds the result of the promise, or it holds a
%% resumption that is automatically invoked when the promise is finished.
%% Importantly, the caller should not look inside the \code{Pid} cell and inspect
%% the value; the caller should only be able to \code{await} it and no more.
%% Ideally \code{Pid} should be an abstract type.

%% \code{signal} is a more simple operation. The \code{Sig} data type is the type
%% of signals that the thread can invoke. These can hold extra data, also called a
%% \emph{payload}. For instance, if we had a program running remote function calls,
%% we might have \code{Sig = call ArgsType | result ResultType}; the payloads are
%% respectively of types \code{ArgsType} and \code{ResultType}. The handler for
%% \code{Promise} will then send the signals to each other thread, possibly
%% executing the interrupt handler if needs be.

%% \code{await} takes a \code{Pid R} and returns a value of type \code{R}. This
%% \code{R} is the returned value of the promise. \code{await} will block until the
%% promise it awaits has been fulfilled; we come on to how it does so later.

%% \paragraph*{Effect Typing}

%% %% We can track and control the effects that promises can perform using Frank's
%% %% effect type system.

%% %% For instance, a Frank program of type \code{[Promise
%% %%     [Console]] X} can install promises that print to the console, a program of
%% %% type \code{[Promise[Console, Web]] X} can install promises that perform web
%% %% requests and print to the console, etc.

%% %% Note however that the effect typing is slightly complicated in the definition of the
%% %% interface; a type of \code{Promise [Console]} means that the installed promise
%% %% can really perform the effects \code{[Promise[Console], Console, RefState,
%% %%     Yield]}. This is expressed by the \code{[E | Promise[E|], RefState, Yield]}
%% %% part of the \code{promise R} definition. A recursive type is needed as the
%% %% promises can themselves invoke other promises.

%% %% \todo{Flesh this out, rewrite it}

%% We can track and control the effects that promises can perform using Frank's
%% effect type system. Recall that Frank effect types implicitly add effect type
%% variables to effect type declarations (as discussed in
%% Section~\ref{sec:effects}); thus the type \code{[Promise, RefState, Yield]}
%% desugars to \code{[E | Promise [E|], RefState, Yield]}. Thus a Frank function
%% with ability \code{[Promise [Console]]} can install promises that use the
%% effects in the interface \code{[Promise [Console], Console, RefState, Yield]}.
%% We use a recursive type so that promises can themselves install other promises.
%% \code{RefState} and \code{Yield} are explicitly added to the ability as a
%% convenience, as every promise requires it in their ability for reasons that
%% become clear later.

%% \paragraph*{Threads}

%% %% To run several threads in parallel, we need to maintain a collection of thread
%% %% states. When we stop executing a thread we suspend it, storing the continuation,
%% %% and start executing a new one, in the same style as Section
%% %% \ref{sec:concurrency}. We also need to store the promises that each thread has
%% %% installed. These are stored as a stack to maintain the order of installation.
%% %% Installing a promise is as straightforward as pushing it onto the corresponding
%% %% thread's promise stack.

%% We maintain a collection of thread states, being the computation thus far and
%% the promises that each thread has installed.
%% %
%% This collection is realised in Frank as the \code{Threads} datatype. It is
%% essentially just a list of three-tuples\footnote{If Frank had support for type
%%   aliases, this is exactly what it would be.}, storing the integer ID, suspended
%% computation, and promise stack of each thread.

%% \begin{lstlisting}
%% data Threads =
%%       tentry Int <@\greytext{-- thread ID}@>
%%              {<@\greytext{[RefState, Yield]}@> Unit}
%%              (TStack {Sig -> {<@\greytext{[RefState, Yield]}@> Unit}
%%                           -> Maybe {<@\greytext{[RefState, Yield]}@> Unit}})
%%              Threads
%%     | tnil
%% \end{lstlisting}

%% When a thread \yield{}s, we take the continuation and store it in
%% \code{Threads}; we then take the next one (according to whatever our scheduling
%% strategy is) and resume the thunk.

%% Observe that installed promises take two arguments. The second
%% argument is the suspended computation thus far. This is because when handling
%% signals we take the promise's body, compose it with the suspended computation
%% and then rehandle it with the \code{Promise} handler. Again, promises can return
%% \code{nothing}; in this case the promise remains on the stack.

%% %% This is because we often have to
%% %% take the body of the promises, compose it with the rest of the interrupted
%% %% computation and then rehandle it with the \code{Promise} handler. If the promise
%% %% results in \code{Nothing}, we don't remove it from the stack and it remains
%% %% installed; recall that returning \code{Nothing} signifies the promise not
%% %% firing. If it returns \code{Just th}, we replace the currently stored suspended
%% %% computation with \code{th}. We go into further detail about this later.


%% \section{Handling Promises}
%% \label{sec:handling-promises}

%% We now introduce the handler for \code{Promise} effects.

%% \begin{lstlisting}
%% hdl : {Int -> Ref Threads
%%     -> <Promise> Unit
%%     -> <@\greytext{[RefState, Yield]}@> Unit}
%% \end{lstlisting}

%% The first argument is the id of the thread being handled. The second one is a
%% reference to the threads structure. These are parametrised by the effects
%% performed in the promises, just like the \code{Promise} interface. The third
%% argument is the thread itself, which performs \code{Promise} operations.
%% %
%% Finally, the ability expresses that this function can perform \code{RefState}
%% effects; the \code{Yield} interface states that \code{hdl} can be interrupted.
%% %% Finally, the return type expresses that this code can perform any of the effects
%% %% that the promises perform, plus \code{RefState} effects; the \code{Yield}
%% %% encodes that this can be interrupted (as in Chapter~\ref{chap:preemptive-concurrency}).

%% \paragraph*{Promises}~
%% \begin{lstlisting}[numbers=left]
%% hdl thId thrs <promise (prom cb) -> k> =
%%     let cell = pid (new waiting) in
%%     let cbMod = (toWrite cell cb) in
%%     let cbMaybe = {sig rest -> case (cbMod sig)
%%           { nothing -> nothing
%%           | (just susp) ->
%%                 just { hdl thId thrs (susp!; <@\greytext{<Promise>}@> rest!)} }} in
%%     let queued = (addCb thId cbMaybe (read thrs)) in
%%     write thrs queued;
%%     hdl thId thrs (k cell)
%% \end{lstlisting}

%% Above we see the handler for \code{promise}. Line 2 creates a new reference cell
%% for the promise id; this is initialised to \code{waiting}, as nothing has been
%% performed yet. Line 3 calls the utility function \code{toWrite}, shown below.

%% %% This takes a
%% %% promise of type \code{Sig -> \{R\}} and converts it to type \code{S ->
%% %%   \{[RefState]Unit\}}; it modifies it to write its value to the corresponding
%% %% \code{Pid} cell once finished.

%% \begin{lstlisting}
%% toWrite : Pid R <@\greytext{[RefState]}@>
%%           -> {S -> (Maybe {<@\greytext{[RefState]}@> R})}
%%           -> {S -> (Maybe {<@\greytext{[RefState]}@> Unit})}
%% toWrite (pid cell) cb =
%%     {x -> case (cb x)
%%          { nothing -> nothing
%%          | (just susp) ->
%%              just {case (read cell)
%%                       { empty -> write cell (done susp!)
%%                       | (resume resumption) -> resumption susp!}} }}
%% \end{lstlisting}

%% This takes a promise of type \code{Sig -> Maybe \{R\}} and converts it to type
%% \code{Sig -> Maybe \{Unit\}}. \code{toWrite} modifies the given callback so
%% once it has been executed it looks inside the given \code{Pid} cell. If the cell
%% is \code{empty}, we just write the return value of the promise body in
%% the cell. If there is a resumption, we resume it with the value of the promise
%% body.

%% %
%% %Having all promises as the same type makes storing them in
%% %% one data structure possible.
%% %
%% %% In lines 4-7 we convert our promise to one that
%% %% takes into account the computation after we've run the promise as well. This is
%% %% essential to get blocking via \code{await} to work properly when running a
%% %% promise, which is important for pre-emptive concurrency and other applications.
%% %% \todo{Go into more depth about this}.

%% In lines 4-7 we convert the promise to also take the computation it interrupts
%% as an argument. The body of the promise is composed with the interrupted
%% computation and the whole thing is rehandled by the promise handler. This is
%% essential to get blocking when installed from a promise working. For instance,
%% we might have a program like \code{thr};

%% \begin{lstlisting}
%% thr : {[Promise] Unit}
%% thr! = promise (prom {stop -> await (promise (prom {go -> unit}))});
%%        otherComputation!
%% \end{lstlisting}

%% The desired behaviour is to start blocking when a \code{stop} message comes in,
%% and then start running again once a \code{go} message is received. If we were
%% just to handle rehandle the promise body separate from the interrupted
%% computation, \code{otherComputation} would not get blocked.

%% Finally in lines 8-10 we add the new promise to the stack of promises installed
%% for this thread and resume the computation with the cell we created earlier.

%% \paragraph*{Signals} ~

%% \begin{lstlisting}
%% hdl thId thrs <signal sig -> thr> =
%%     let newThrs = runThreads sig (read thrs) in
%%     write thrs newThrs;
%%     hdl thId thrs (thr unit)
%% \end{lstlisting}

%% When a thread we're running invokes a signal, we inform the other threads of
%% this using \code{runThreads}. This function then calls the \code{runThread}
%% function on every thread;

%% %% When a signal comes in, we need to try and execute \emph{all} of the installed
%% %% promises, for every thread. To do this we use the \code{runThreads} function,
%% %% which calls the below function for all threads;

%% \begin{lstlisting}
%% runThread sig (trio susp cbs skipped) =
%%   case (dequeue cbs)
%%     { nothing -> trio susp cbs skipped
%%     | (just (pair cb cbs)) ->
%%       case (cb sig susp)
%%         { nothing -> runThread sig (trio susp cbs (enqueue cb skipped))
%%         | (just res) -> runThread sig (trio res cbs skipped)}}
%% \end{lstlisting}

%% \noindent We first check to see if there are any installed promises remaining.
%% If there is, we run the promise with the signal supplied. We supply the callback
%% with the incoming signal and the thunked computation thus far. If the callback
%% returns \code{nothing} we reinstall it. If the callback gives us an updated
%% thunk, we continue to run the rest of the promises, with this thunk the new
%% computation to be extended.

%% At no point in this process are these thunks ever actually invoked; we are
%% simply mutating suspended computations. When a signal triggers a promise, the
%% body of the promise does not get performed until the thread is run by the
%% scheduler. In \aeff, when a signal is received by an interrupt handler there is
%% some nondeterminism present; we can either trigger the interrupt handler or
%% continue computing underneath the handler. In our system this choice is not
%% available; the interrupt handler is always triggered first, and we process the
%% body of it immediately.


%% %% Recall that the type of the callbacks is \code{Sig -> \{Unit\} -> \{R\}}; we
%% %% have to also supply the callbacks with the thunked computation so far. Again,
%% %% this is important to correctly implement blocking. If the callback returns
%% %% \code{nothing} we do not evaluate it and we reinstall it afterwards, by putting
%% %% it onto the ``skipped'' stack.

%% Once promise execution is finished we update the state of \code{thrs} and resume
%% handling, restarting the continuation with \code{unit} immediately.
%% This is unlike traditional effect invocations, where we would block until a
%% result is produced.


%% \paragraph*{Await}~
%% \begin{lstlisting}
%% hdl thId thrs <await cell -> thr> =
%%     case (readPid cell)
%%         { (done x) ->
%%             hdl thId thrs (thr x)
%%         | waiting ->
%%             writePid cell (resume thr);
%%             hdl thId thrs unit }
%% \end{lstlisting}

%% Handling \code{await} is surprisingly the simplest of the lot. Recall that
%% \code{await} takes a promise id cell \code{Pid R} and returns a value of type
%% \code{R}. The handler looks inside this cell; if there is a finished value there
%% already (\code{done x}) it resumes the continuation with this value straight
%% away. If the promise has not yet completed, we then write the resumption (which
%% is of type \code{\{R -> Unit\}}) to the cell. The function \code{toWrite} used
%% when installing promises changes the original promise to resume the continuation
%% stored in \code{Pid}, if there is one present.

%% \section{Multithreading}

%% %% We now show how we can easily introduce multithreading to our system. Observe
%% %% that we are yet to have a handler for any \code{yield} commands. We can handle
%% %% them, yielding co-operative concurrency in the same style as
%% %% Section~\ref{sec:concurrency}, like so;

%% Multithreading then fits into our system in a natural way, via the
%% \code{schedule} handler.

%% \begin{lstlisting}[numbers=left]
%% schedule : {<Yield> Unit -> Int -> Ref Threads -> <@\greytext{[RefState]}@>Unit}
%% schedule <yield -> k> cur thrs =
%%     let next = nextId cur (keys (read thrs)) in
%%     let newThk = lookupThk next (read thrs) in
%%     let newThrs = writeThk cur {k unit} (read thrs) in
%%     write thrs newThrs;
%%     schedule newThk! next thrs

%% schedule unit cur thrs = scheduleT yield! cur thrs
%% \end{lstlisting}

%% \noindent Recall that the threads are stored with a thread id, an integer. We
%% use these in our simple scheduling strategy, where we just cycle through all ids
%% in ascending order. Line 3 finds the id of the next thread as per this strategy,
%% and line 4 looks up the thunk from \code{Threads}. Line 5 then writes the
%% current thread's thunk to \code{Threads}. Line 6 writes the updated version of
%% \code{Threads} and line 7 starts executing the next continuation. Line 9 states
%% that if a thread's value is unit we just force a yield. This is useful if a
%% thread is blocked as we will instantly stop processing it and start the next
%% one.

%% %% One disadvantage of our approach is that we are still tied into using
%% %% \code{Threads}, even though multithreading seems to be orthogonal to handling
%% %% promises; it would be nicer to use a generic queue data structure, or even just
%% %% a multihandler like in Section~\ref{sec:concurrency}. The problem
%% %% is that the stored thunks get modified whilst other threads work, so we need to
%% %% keep an up-to-date version of the latest ones.

%% %% \section{Running Processes}

\chapter{Examples}
\label{chap:examples}

%% The combination of our \code{Promise} interface with the pre-emptive concurrency
%% of Section~\ref{chap:preemptive-concurrency} lets us express complex concurrent
%% programs in a simple, direct manner. In this section we show some examples of
%% these.

%% The developed library gives us an expressive, malleable way to implement common
%% asynchronous programming features within our language.

Many languages which support async-await --- such as C# and Javascript --- have
the behaviour built-in. First the compiler is changed to add new syntax, then
the compiler is changed to add new type-checking, then we have to implement the
semantics; even worse, we have to do this when we want another asynchronous
primitive, such as futures (asynchronous post-processing of results).

We show that with our promise library we can implement all of these common
asynchronous primitives within the language itself.

\section{Pre-emptive Scheduling}
\label{sec:pre-emptive-scheduling}

%% An essential feature of our asynchronous effects system is that it supports
%% pre-emptive concurrency; that is, the suspension and resumption of threads
%% non-cooperatively. Naturally, this relies on the insertion of yields as
%% discussed in Chapter~\ref{chap:preemption}.

%% We supplement the signals supported in our program with two more;

Whilst we have already shown how to pre-emptively schedule several threads in
Section~\ref{sec:handling}, we might want to have a more robust way of doing
this; the multihandler strategy is fixed in a left-to-right evaluation order. In
this method, we can just have a single source sending out \code{stop} and
\code{go} messages, implementing a potentially more sophisticated scheduling
strategy than mere round-robin.

\begin{lstlisting}
data Sig = <@\ldots@> | stop Int | go Int
\end{lstlisting}

We add two more signals to the \code{Sig} datatype. The integer payload can act
as a counter, or as a way to tell specific threads to stop or go. The blocking
or non-blocking behaviour then depends on the promises for these signals.

\begin{lstlisting}
onStop : {Int -> <@\greytext{[Promise]}@> Unit}
onStop id = let gp = promise (prom {s -> goPromise id s}) in
            await gp;
            promise (prom {s -> stopPromise id s});
            unit

stopPromise : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
stopPromise id (stop n) = if (n == id)
                            { just { onStop id } }
                            { nothing }
stopPromise id _ = nothing
\end{lstlisting}

\code{stopPromise} is another guarded interrupt handler; it will only fire its
body if the payload to \code{stop} is the thread's ID. The body then installs a
promise waiting for \code{go} and immediately awaits it, starting to block. The
rest of the computation can not proceed until the corresponding go message is
received. Once the correct go promise is received the promise is fulfilled adn
the rest of the computation can start again, and the \code{stop} interrupt
handler is reinstalled.

\begin{lstlisting}
goPromise : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
goPromise id (go n) = if (n == id)
                         { just {unit} }
                         { nothing }
goPromise id _ = nothing
\end{lstlisting}

\code{goPromise} is simple in comparison; if it receives the correct \code{go} signal
it just returns \code{unit}.

%% We can then make a function  by just installing a stop-waiting promise
%% in front of the function code;

%% We can then install the stop interrupt handler before a computation to make it
%% schedulable. The computation being scheduled is then unaware it is being
%% scheduled, as desired.

To make a thread pre-emptible, we simply install the stop interrupt handler
before the main body of the computation. The computation being scheduled is then
entirely unaware it is being scheduled, as desired.

\begin{lstlisting}
counter : {Int -> <@\greytext{[Console]}@> Unit}
counter x = ouint x; print " "; sleep 200000; counter (x + 1)

thread : {<@\greytext{[Promise, Console, Yield]}@> Unit}
thread! = promise (prom {s -> stopPromise 0 s}); counter 0
\end{lstlisting}

Now all that remains is to have a source of \code{stop} and \code{go} signals.
This could just be a standard round-robin scheduler or some more sophisticated
strategy. One of the strengths of effect handlers for concurrency is the ability
to abstract over scheduling strategies, and this strength is still present here.

One disadvantage to our approach is that an adversarial thread could just send
\code{stop} and \code{go} signals of its own, overriding the scheduler. Using
session types (\cite{honda1998language}) to restrict inter-thread communication
would be able to solve this problem.

%% A
%% stronger type system to control communication would be able to fix this.

\section{Futures}
\label{sec:futures}

Our developed asynchronous effects system is expressive enough to implement the
asychronous post-processing of results, or \emph{futures}, on top of what we
already have. Previously these have had to be implemented as a separate language
feature (\cite{schwinghammer2002concurrent}).

Futures are useful if we want to asynchronously perform some action once another
promise has been completed. In the context of a web application, this might be
updating the application's display once some remote call for data has finished.
Observe that this differs from just awaiting the remote call and then updating
once we have this; we do not want to block everything else from running, but
want to perform this action asynchronously, when the promise is complete.

\begin{lstlisting}
futureList : {Pid R <@\greytext{[Promise]}@> -> {R -> <@\greytext{[Promise]}@> Z} -> Sig
    -> Maybe {<@\greytext{[Promise]}@> Z}}
futureList p comp (listSig _) =
    just { let res = await p in comp res}
futureList _ _ _ = nothing
\end{lstlisting}

\noindent When calling \code{futureList} we supply a promise of result type
\code{R} and a computation of type \code{R -> Z}. We then await the promise, and
once we have a value (of type \code{R}) run the computation with this. An
example computation using this system is;

\begin{lstlisting}
let recv = promise { (listSig xs) -> just {xs} | _ -> nothing} in
let prod = promise {s -> futureList filt product s} in
promise {s -> futureList prod {x -> signal (resultSig x)} s}
\end{lstlisting}

\noindent Where we, upon receipt of a list signal, take the product of the list
element-wise and send another signal with this result. All three of these
promises are triggered by the same signal; \code{recv} is executed first, which
then executes \code{prod}, which then lets the final one run. This behaviour
depends on signals being able to execute many promises at once (that is,
behaving like \emph{deep} rather than shallow handlers).

\section{Async-Await with Workers}

Our asynchronous effects system can express the familiar async-await
abstraction. This had previously been implemented in Frank by forking new
threads, then to be handled by a co-operative scheduler like in
Section~\ref{sec:concurrency}. We realise it by using a controller thread, which
will send tasks to one of a set of $n$ worker threads. When these worker threads
are not working, they are instantly skipped; hence there is not much
inefficiency associated with having extra idle workers.

We first show how the caller communicates with the controller.

\begin{lstlisting}
resultWaiter : {Int -> Sig -> Pid String <@\greytext{[Promise]}@>}
resultWaiter callNo (result res callNo') =
    if (callNo == callNo') { just {res} } { nothing }
resultWaiter _ _ = nothing

async : {[{String} -> Ref Int -> <@\greytext{[Promise]}@> Pid String <@\greytext{[Promise]}@>
async proc callCounter =
    let callNo = read callCounter in
    let waiter = {s -> resultWaiter callNo s} in
    signal (call proc callNo);
    write callCounter (callNo + 1);
    waiter
\end{lstlisting}

We use this function to issue a new asynchronous task. We keep a global counter
to give each call a unique identifier. We then install an interrupt handler that
waits for a result and simply returns it, if the call numbers match. Finally we
send a \code{call} signal with the process and return the result interrupt
handler. Observe that \code{async} returns the promise waiting for the correct
result. As such, the \code{await} operation is just the built-in \code{await}
operation; we don't need to define any extra functions.

\code{call} signals are handled by the controller thread. This thread keeps
track of which of the workers do not currently have a task running, and
also installs a promise to set its state to idle once the corresponding
\code{result} message is received.

\begin{lstlisting}
onResult : {Ref (List (Maybe Int)) -> Int -> Sig
    -> Maybe {<@\greytext{[Promise]}@> Unit}}
onResult active wid (result res cid) =
    just { write active (putIn nothing wid (read active)) }
onResult _ _ _ = nothing

onAsyncBody : {Ref (List (Maybe Int)) -> {String} -> Int
    -> <@\greytext{[Promise]}@> Unit}
onAsyncBody active p callId =
    case (nextFree (read active))
        { nothing -> print "All workers are busy."
        | (just wid) ->
            write active (putIn (just callId) wid (read active));
            promise (prom {s -> onResult active wid s});
            signal (workIn p wid callId)};
    promise (prom {s -> onAsync active s}); unit
\end{lstlisting}

Workers listen for a \code{workIn} message; when one comes in with their ID in
the payload, they simply perform the computation and send a signal with the
result.

\begin{lstlisting}
workProm : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
workProm wid (workIn p wid' callId) =
    if (wid == wid')
       { just {let res = p! in
               signal (result res callId);
               worker wid; unit}}
       { nothing }
workProm _ _ = nothing

worker : {Int -> <@\greytext{[Promise]}@> Pid Unit <@\greytext{[Promise]}@>}
worker wid = promise (prom {s -> workProm wid s})
\end{lstlisting}

This \code{result} signal triggers the interrupt handler installed by the
\code{async} caller, but also triggers the promise installed by the controller,
to inform it that the worker is now idle. This ability to trigger multiple
promises with one message is a subtle but useful feature of the system.

\section{Cancelling Tasks}

Because we are working in a language equipped with effect handlers, we can
easily write a handler for the \textsf{Cancel} effect, which just gets rid of
the continuation and replaces it with some default value (e.g. \code{unit}).

\begin{lstlisting}
  interface Cancel = cancel : Unit
 
  hdlCancel : {<Cancel> Unit -> Unit}
  hdlCancel <cancel -> _> = unit
  hdlCancel unit          = unit
\end{lstlisting}

%% We can use this to cancel a task issued with \code{async}. Recall that these
%% tasks run on their own thread. As such, we can just cancel the entire thread at
%% the top-level.

We can use this to cancel a task issued with \code{async}. Recall that tasks run
on their own worker thread. As such, all we need to do to cancel them is
reinstall the worker promise --- which waits for new tasks --- and then invoke
the cancel effect. As such, our worker code becomes

\begin{lstlisting}
canceller : {Int -> Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
canceller wid callId (cancelCall callId') =
    if (callId == callId')
        { just {worker wid; cancel!} }
        { nothing }
canceller _ _ _ = nothing

workProm : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
workProm wid (workIn p wid' callId) =
    if (wid == wid')
       { just {<@\texthighlight{promise (prom \{s -> canceller wid callId s\}}@>;
               let res = p! in
               signal (result res callId);
               worker wid; unit}}
       { nothing }
workProm _ _ = nothing
\end{lstlisting}

We have to modify the handler for the \textsf{Promise} effect for this. Recall
that when we install a promise, we convert it to a form that takes composes the
body of the promise with the interrupted computation and rehandles the
\code{Promise} effects that this might perform.
%
We need to then wrap this in a handler for \textsf{Cancel} effects again; this
is because user-level promises could perform \textsf{Cancel} effects, and we
want to cancel the \emph{whole} computation, not just the body of the promise.

\begin{lstlisting}
case (cbMod sig)
    { nothing -> nothing
    | (just susp) ->
      just { <@\texthighlight{stopCancel}@> (hdl thId thrs (susp!; <LCancel, Promise> rest!)) }}
\end{lstlisting}

The realisation of cancellable function calls in
\aeff(\cite{ahman2020asynchronous}) was to start awaiting a new promise that
will never be fulfilled. This leads to a space leak as unfulfilled promises
build up. Our approach improves on this as the cancelled calls do genuinely
disappear.

However, a weakness of our system is that we have to modify the handler code for
promises, even though cancellation of calls and promises should be orthogonal.

\section{Interleaving}

With the \textsf{Cancel} effect, we can also define the useful \code{interleave}
combinator, in the spirit of Koka's interleave
operator~\cite{leijen2017structured}.

%% \todo{Think of a better way to make reference to Daan's work}

\begin{lstlisting}
resultWaiter : {String -> Int -> Int -> Int
    -> Maybe {<@\greytext{[Promise]}@> String}}
resultWaiter res callNo callA callB =
    if (callNo == callA)
        { just { signal (cancelCall callB); res} }
        { if (callNo == callB)
            { just { signal (cancelCall callA); res} }
            { nothing }}

interleave : {{String} -> {String}
    -> Ref Int -> <@\greytext{[Promise]}@> Pid String <@\greytext{[Promise]}@>}
interleave procA procB callCounter =
    let callA = read callCounter in
    write callCounter (callA + 1);
    let callB = read callCounter in
    write callCounter (callB + 1);

    let ileaveWaiter =
        promise (prom {(result res callNo) ->
            resultWaiter res callNo callA callB
                      | _ -> nothing
        }) in

    signal (call procA callA);
    signal (call procB callB);

    ileaveWaiter
\end{lstlisting}

This will issue the two tasks on different threads. We then install an interrupt
handler for \code{result} signals; whichever result is received first we return
and cancel the other task.

This lets us write timeouts for functions, where we interleave a potentially
long-running request with a timer; we cancel the request if it takes too long.
We can also run two identical requests to different services and just take the
result of the one that returns first. The \code{interleave} operator can be
composed with itself to yield the $n$-ary operator \code{interleave} operator.

Observe the similarity of \code{interleave} and \code{async}. By taking
asynchronous programming structures out of library code and into the
programmer's hands, we hope that programmers will be able to more easily produce
their own, useful tools.


\chapter{Conclusion}
\label{chap:conclusion}

We conclude with a discussion of the achievements, some limitations, and
possible future work.

Combining the pre-emptive concurrency of
Section~\ref{sec:preemptive-concurrency} with the promise library of
Section~\ref{sec:implementation} yields a direct and comfortable way to write
asynchronous programs. It is our hope that these results will be reproducible in
other effect-handling languages.
%
Moreover, we have shown how effect handlers as a programming tool can be used to
easily express complicated control flow.

\todo{Add more to end of paragraph}

\paragraph*{Limitations and Future Work}

The implementation of asynchronous effects as discussed does not track
asynchronous effects, and is untyped. \citeauthor{ahman2020asynchronous} have
shown that this is possible; it remains as future work to add types to our
implementation.

Our system uses the fairly simple communication protocol where every message
gets sent to every thread. Naturally, two threads might want to communicate
secretly, without other threads eavesdropping. Finer control of this is
desirable for larger applications.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{plainnat}
\bibliography{bibliography}

%% You can include appendices like this:
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\appendix

\chapter{Remaining Formalisms}

\begin{figure} % \figrule
\flushleft
%% $\boxed{\kindchecksk{R}}$
%% \begin{mathpar}
%% \inferrule[K-Val]
%%   {\TyVar(A) \subseteq \kenv}
%%   {\kindchecksk{A}}

%% \inferrule[K-Eff]
%%   {\TyVar(\sigs) \subseteq \kenv}
%%   {\kindchecksk{[\sigs]}}
%% %
%% \end{mathpar}

$\boxed{\infersk{\Gamma}{\sigs}{m}{A}}$
\begin{mathpar}
\inferrule[T-Var]
  {
   x:A \in \Gamma}
  {\inferskgs{x}{A}}

\inferrule[T-PolyVar]
  {% \kindchecks{\kenv, \many{Z}}{A}\\
   \kindchecksk{\many{R}} \\
   f:\forall \many{Z}.A \in \Gamma}
  {\inferskgs{f~\many{R}}{A[\many{R}/\many{Z}]}}
\\
\inferrule[T-App]
  {\sigs' = \sigs \\
   (\adjact{\sigs}{\adj_i}{\sigs'_i})_i \\\\
   \inferskgs{m}{\thunk{\many{\effin{\adj}A \to}~ \effout{\sigs'}B}} \\
   (\checksk{\Gamma}{\sigs'_i}{A_i}{n_i})_i}
  {\infersk{\Gamma}{\sigs}{m~\many{n}}{B}}

\inferrule[T-Ascribe]
  {\checkskgs{A}{n}}
  {\inferskgs{\cu (n : A)}{A}}
%
\end{mathpar}

$\boxed{\checksk{\Gamma}{\sigs}{A}{n}}$
\begin{mathpar}
\inferrule[T-Switch]
  {\inferskgs{m}{A} \\ A = B}
  {\checkskgs{B}{\uc m}}

\inferrule[T-Data]
  {%(\kindchecksk{R_i})_i\\
   k~\many{A} \in D~\many{R} \\
   (\checkskgs{A_j}{n_j})_j}
  {\checkskgs{D~\many{R}}{k~\many{n}}}

\inferrule[T-Command]
  {\kindchecksk{\many{R}} \\
   c : \forall \many{Z}.\many{A \to}~ B \in \sigs \\
   (\checkskgs{A_j[\many{R}/\many{Z}]}{n_j})_j}
  {\checkskgs{B[\many{R}/\many{Z}]}{c~\many{R}~\many{n}}}

\inferrule[T-Thunk]
  {\checksdefkg{C}{e}}
  {\checkskgs{\thunk{C}}{\thunk{e}}}

\inferrule[T-Let]
  {P = \forall \many{Z}.A \\\\
   \checkbase{\kenv, \many{Z}}{\sigentails{\emptyset}}{\Gamma}{A}{n} \\
   \checksk{\Gamma, f : P}{\sigs}{B}{n'}}
  {\checkskgs{B}{\key{let}~f : P = n~\key{in}~n'}}

\inferrule[T-LetRec]
  {(P_i = \forall \many{Z}_i.\thunk{C_i})_i \\\\
   (\checkbase{\kenv, \many{Z}_i}{\vdash}{\Gamma, \many{f : P}}{C}{e_i})_i\\
   \checksk{\Gamma, \many{f : P}}{\sigs}{B}{n}}
  {\checkskgs{B}{\key{letrec}~\many{f : P = e}~\key{in}~n}}

\inferrule[T-Adapt]
  {\adjact{\sigs}{\adapt}{\sigs'} \\ \checksk{\Gamma}{\sigs'}{A}{n}}
  {\checkskgs{A}{\effin{\adapt}~n}}
\end{mathpar}

$\boxed{\checksdefkg{C}{e}}$
\begin{mathpar}
\inferrule[T-Comp]
  {(\matchesck{T_j}{r_{i,j}}{\sigs}{\exists \kenva_{i,j}.\Gamma'_{i,j}})_{i,j} \\
   (\checks{\kenv, (\kenva_{i,j})_j}{\Gamma, (\Gamma'_{i,j})_j}{\sigs}{B}{n_i})_i \\
   ((r_{i,j})_{i} \text{ covers } T_j)_j}
  {\checksdefkg{(T_j \to)_j~\effout{\sigs}B}{((r_{i,j})_j \mapsto n_i)_i}}
\end{mathpar}
\caption{Term Typing Rules}
\label{fig:term-typing}
% \figrule
\end{figure}

\begin{figure}%% \figrule
\flushleft
$\boxed{\adjact{\sigs}{\adj}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adj]{\adjact{\sigs}{\adapt}{\sigs'} \\
  \adjact{\sigs'}{\ext}{\sigs''}}
          {\adjact{\sigs}{\adapt\pipe\ext}{\sigs''}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\ext}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Ext-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Ext-Snoc]{\adjact{\sigs}{\ext}{\sigs'} }
          {\adjact{\sigs}{\ext, \sig~\many{R}}{\sigs', \sig~\many{R}}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\adapt}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Adapt-Snoc]{\adjact{\sigs}{\adapt}{\sigs'} \\
    \adpcom{\sigs'}{\sig}{S}{S'}{\sigs''}}
          {\adjact{\sigs}{\adapt, \sig(S \to S')}{\sigs''}}
\end{mathpar}
$\boxed{\adpcom{\sigs}{\sig}{S}{S'}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Com]
  {\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv} \\
   \itrinst{\ienv}{S'}{\sig}{\ext} \\
   \adjact{\sigs'}{\ext}{\sigs''}}
  {\adpcom{\sigs}{\sig}{S}{S'}{\sigs''}}
\end{mathpar}

$\boxed{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}$
\begin{mathpar}
\inferrule[I-Pat-Id]{ }
          {\itrbnd{\sigs}{\pid}{\sig}{\sigs}{s : \sigs}}

\inferrule[I-Pat-Bind]{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}
          {\itrbnd{\sigs,\sig~\many{R}}{S~a}{\sig}{\sigs'}
            {\ienv,a:\sig~\many{R}}}

\inferrule[I-Pat-Skip]{
  \itrbnd{\sigs}{S~a}{\sig}{\sigs'}{\ienv} \\
  \sig \neq \sig'}
  {\itrbnd{\sigs,\sig'~\many{R}}{S~a}{\sig}
          {\sigs',\sig'~\many{R}}{\ienv}}
\end{mathpar}


$\boxed{\itrinst{\ienv}{S}{\sig}{\ext}}$
\begin{mathpar}
\inferrule[I-Inst-Id]{s\in\meta{dom}(\ienv)}
          {\itrinst{\ienv}{\pid}{\sig}{\id}}

\inferrule[I-Inst-Lkp]{a\in\meta{dom}(\ienv) \\
  \itrinst{\ienv}{S}{\sig}{\ext} \\
  \ienv(a)=\sig~\many{R}}
          {\itrinst{\ienv}{S~a}{\sig}{\ext,\sig~\many{R}}}
\end{mathpar}
%% \caption{Action of an Adaptor's Interface Component on an Ability}
\label{fig:interface-components}

\begin{figure}[t]
%% \figrule
\flushleft
$\boxed{\inferskgs{m}{A}}$ \quad $\boxed{\checkskgs{A}{n}}$
\begin{mathpar}
\inferrule[T-Freeze-Use]
  {\neg(\EC \handles c) \\
   \inferskgs{\EC[c~\many{R}~\many{w}]}{A}}
  {\inferskgs{\freeze{\EC[c~\many{R}~\many{w}]}}{A}}

\inferrule[T-Freeze-Cons]
  {\neg(\EC \handles c) \\
   \checkskgs{A}{\EC[c~\many{R}~\many{w}]}}
  {\checkskgs{A}{\freeze{\EC[c~\many{R}~\many{w}]}}}
\end{mathpar}
\caption{Frozen Commands}
\label{fig:frozen-typing}
%% \figrule
\end{figure}

\caption{Action of an Adjustment on an Ability and Auxiliary Judgements}
\label{fig:act-adj}
%% \figrule
\end{figure}


\begin{figure} % \figrule
\flushleft

\[
\mathcal{X} ::= A \gor C \gor T \gor G \gor Z \gor R \gor P
                  \gor \seed \gor \sigs \gor \ext \gor \adapt \gor \adj
                  \gor \Gamma \gor \exists \kenva.\Gamma \gor \ienv
\]

$\boxed{\kindchecksk{\mathcal{X}}}$
%% \boxed{\kindchecksk{C}}\boxed{\kindchecksk{T}}
%% \boxed{\kindchecksk{G}}\boxed{\kindchecksk{Z}}\boxed{\kindchecksk{R}}\boxed{\kindchecksk{P}}
%% \boxed{\kindchecksk{\seed}}\boxed{\kindchecksk{\sigs}}
%% \boxed{\kindchecksk{\ext}}\boxed{\kindchecksk{\adapt}}\boxed{\kindchecksk{\adj}}
%% \boxed{\kindchecksk{S}}\boxed{\kindchecksk{\Gamma}}\boxed{\kindchecksk{\ienv}}
%% $
\begin{mathpar}
\inferrule[WF-Val]
  { }
  {\kindchecks{\kenv, X}{X}}

\inferrule[WF-Eff]
  { }
  {\kindchecks{\kenv, [E]}{E}}

\inferrule[WF-Poly]
  {\kindchecks{\kenv, \many{Z}}{A}}
  {\kindchecks{\kenv}{\forall \many{Z}.A}}
\\
\inferrule[WF-Data]
  {(\kindchecksk{R})_i}
  {\kindchecksk{D~\many{R}}}

\inferrule[WF-Thunk]
  {\kindchecksk{C}}
  {\kindchecksk{\thunk{C}}}

\inferrule[WF-Comp]
  {(\kindchecksk{T})_i \\ \kindchecksk{G}}
  {\kindchecksk{\many{T \to}~ G}}

\inferrule[WF-Arg]
  {\kindchecksk{\adj} \\ \kindchecksk{A}}
  {\kindchecksk{\effin{\adj}A}}

\inferrule[WF-Ret]
  {\kindchecksk{\sigs} \\ \kindchecksk{A}}
  {\kindchecksk{\effout{\sigs}A}}

\inferrule[WF-Ability]
  {\kindchecksk{\sigs}}
  {\kindchecksk{[\sigs]}}

\inferrule[WF-Pure]
  { }
  {\kindchecksk{\nowt}}

\inferrule[WF-Id]
  { }
  {\kindchecksk{\id}}

\inferrule[WF-Ext]
  {\kindchecksk{\ext} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ext, \sig~\many{R}}}

\inferrule[WF-Adapt]
  {\kindchecksk{\adapt}}
  {\kindchecksk{\adapt, \sig~(S \to S')}}
\\
\inferrule[WF-Empty]
  { }
  {\kindchecksk{\cdot}}

\inferrule[WF-Mono]
  {\kindchecksk{\Gamma} \\ \kindchecksk{A}}
  {\kindchecksk{\Gamma, x : A}}

\inferrule[WF-Poly]
  {\kindchecksk{\Gamma} \\ \kindchecksk{P}}
  {\kindchecksk{\Gamma, f : P}}
\\

\inferrule[WF-Existential]
  {\kindchecks{\kenv, \kenva}{\Gamma}}
  {\kindchecksk{\exists \kenva.\Gamma}}

\inferrule[WF-Interface]
  {\kindchecksk{\ienv} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ienv, x : \sig~\many{R}}}

\end{mathpar}


\caption{Well-Formedness Rules}
\label{fig:well-formedness}

% \figrule
\end{figure}

\begin{figure} % \figrule
\flushleft
$\boxed{\matchesvk{A}{p}{\Gamma}}$
\begin{mathpar}
\inferrule[P-Var]
  { }
  {\matchesvk{A}{x}{x:A}}

\inferrule[P-Data]
  {k~\many{A} \in D~\many{R} \\
   (\matchesvk{A_i}{p_i}{\Gamma})_i}
  {\matchesvk{D~\many{R}}{k~\many{p}}{\many{\Gamma}}}
\end{mathpar}
$\boxed{\matchesck{T}{r}{\sigs}{\exists \kenva.\Gamma}}$
\begin{mathpar}
\inferrule[P-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\ \matchesvk{A}{p}{\Gamma}}
  {\matchesck{\effin{\adj}A}{p}{\sigs}{\Gamma}}

\inferrule[P-CatchAll]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\matchesck{\effin{\adj}A}{\effin{x}}{\sigs}{x:{\thunk{\effout{\sigs'}A}}}}

\inferrule[P-Command]
  {
   \adjact{\sigs}{\adj}{\sigs'} \\
   \adj = \adapt\pipe\ext \\
   c:\forall \many{Z}.\many{A \to} B \in \ext \\
   (\matchesv{\kenv, \many{Z}}{A_i}{p_i}{\Gamma_i})_i}
  {\matchesc{\kenv}
            {\effin{\adj}B'}
            {\effin{\handle{c~\many{p}}{z}}}
            {\sigs}
            {\exists \many{Z}.\many{\Gamma}, z:\{\effin{\id\pipe\id}B \to \effout{\sigs'}B'\}}}
\end{mathpar}
\caption{Pattern Matching Typing Rules}
\label{fig:pattern-typing}
%% \figrule
\end{figure}

% \section{First section}
% 
% Markers do not have to consider appendices. Make sure that your contributions
% are made clear in the main body of the dissertation (within the page limit).

\end{document}
