\documentclass[msc,deptreport,cs]{infthesis} % Do not change except to add your degree (see above).

\usepackage[usenames,dvipsnames]{xcolor}
%% Imports poached from frankly
%% STILL can't find what makes \figrule work
\usepackage{natbib}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{thmtools,thm-restate}
\usepackage{comment}
\usepackage{flushend}
\usepackage{listings}
\usepackage{lstlinebgrd}

\usepackage[makeroom]{cancel}
%% \usepackage{beramono}

%% \lstdefinestyle{mystyle}{
%%     %% backgroundcolor=\color{backcolour},
%%     %% commentstyle=\color{codegreen},
%%     %% keywordstyle=\color{magenta},
%%     %% numberstyle=\tiny\color{codegray},
%%     %% stringstyle=\color{codepurple},
%%     breakatwhitespace=false,
%%     breaklines=true,
%%     captionpos=b,
%%     keepspaces=true,
%%     %% numbers=left,
%%     %% numbersep=5pt,
%%     showspaces=false,
%%     showstringspaces=false,
%%     showtabs=false,
%%     tabsize=2,
%%     %% basicstyle=\small\ttfamily
%%     basicstyle=\ttfamily\footnotesize,
%%     %% breaklines=true
%% }

%% \lstset{style=mystyle}

%% \lstset{escapeinside={<@}{@>}}

\lstset{
  %% basicstyle=\small\ttfamily\bfseries,
  basicstyle=\footnotesize\ttfamily\bfseries,
  %% basicstyle=\footnotesize\ttfamily,
  %% basicstyle=\small\ttfamily,
  breaklines=true,
  % For having lighter-coloured text inside listings
  % https://tex.stackexchange.com/questions/144448/color-a-text-line-in-a-code-lstlisting
  escapeinside={<@}{@>}
}


\usepackage{stmaryrd}
\usepackage{natbib}
\usepackage{xspace}
%% \usepackage[pdftex,
%%             pdfauthor={Sam Lindley, Conor McBride, and Craig McLauglin},
%%             pdftitle={Doo bee doo bee doo}]{hyperref}
%\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue}
%% \hypersetup{colorlinks=true,allcolors=black}
\usepackage{url}

% get rid of hypertext link on \citeauthor
\usepackage{etoolbox}

\usepackage{amssymb}

\usepackage{mathtools} % allows flush-left align environments and paired
                       % delimiters.
                       %
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}


%% abstract for inline code
\newcommand{\code}[1]{\lstinline{#1}}
\newcommand{\codem}[1]{\lstinline[mathescape]{#1}}


\newcommand{\highlight}[1]{%
  \colorbox{red!20}{$\displaystyle#1$}}

\newcommand{\texthighlight}[1]{%
  \colorbox{red!20}{#1}}

\newcommand{\highlightout}[1]{%
  \colorbox{black!20}{$\displaystyle#1$}}

\newcommand{\greytext}[1]{\textcolor{black!40}{#1}}

\newcommand\aeff{{\AE}ff\xspace}

% \newcommand\figscale{0.85}
\newcommand\figscale{0.9}
% \newcommand\figscale{1}

\newcommand\nondetfrank{$\mathbb{F}_{\cal{ND}}$}
\newcommand\countingfrank{$\mathbb{F}_{\cal{C}}$}
\newcommand\treefrank{$\mathbb{F}_{\cal{T}}$}
\newcommand\purefrank{$\mathbb{F}$}

\newcommand\feed{$\mathcal{F}$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\counter}{{\color{blue} \textsf{c}}}
\newcommand{\justc}[1]{{\color{blue} \textsf{count}({#1})}}
\newcommand{\yieldc}{{\color{blue}{\textsf{yield}}}}
\newcommand{\plusc}{{\color{blue} \oplus}}
\newcommand{\threshc}{{\color{blue} \textsf{t}}}
\newcommand{\succc}[1]{\bluetext{#1 \plusc 1}}

\newcommand{\bluetext}[1]{{\color{blue}#1}}

\newcommand\yield{\textsf{yield}\xspace}
\newcommand\Yield{\textsf{Yield}\xspace}
\newcommand\allows{\textsf{allows}\xspace}


\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newcommand{\todo}[1]
           {{\par\noindent\small\color{RoyalPurple}
  \framebox{\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
    {\textbf{TODO:} #1}}}}

\newcommand{\interrupt}[1]{!(#1)}

\newcommand{\fighead}{\textbf}

\newcommand{\lameff}{$\lambda_{\text{eff}}$\xspace}
\newcommand{\lameffrow}{$\lambda_{\text{eff}}^\rho$\xspace}
\newcommand{\feff}{$F_\textrm{eff}$\xspace}
\newcommand{\impeff}{Implicit \lameff}
\newcommand\Frank{\emph{Frank}\xspace}

\newcommand\Cse{\textbf{Case}}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\many}{\overline}
\newcommand{\opt}[1]{#1^?}
\newcommand{\medvert}{\mid}

\newcommand{\sem}[1]{\llbracket{#1}\rrbracket}
\newcommand{\seml}{\left\llbracket}
\newcommand{\semr}{\right\rrbracket}

\newcommand{\mdo}{~\textbf{do}~}
\newcommand{\seq}{~\textbf{;}~}
\newcommand{\assn}[2]{{#1}~\leftarrow~{#2}}
\newcommand{\func}[2]{\text{#1}~{#2}}

\newcommand{\deno}[1]{\sem{#1}\rho}
\newcommand{\denoex}[2]{\sem{#1}#2}
\newcommand{\pc}[1]{\llparenthesis{#1}\rrparenthesis}

\newcommand{\TyVar}{\mathit{Var}}
\newcommand{\dom}{\mathit{dom}}
%\newcommand{\sub}{\subseteq}
\newcommand{\Star}{{\Large$\star$}}

\newcommand{\reducesto}{\longrightarrow}

\newcommand\ba{\begin{array}}
\newcommand\ea{\end{array}}

\newcommand{\bl}{\ba[t]{@{}l@{}}}
\newcommand{\el}{\ea}

\newcommand{\bstack}{\begin{array}[t]{@{}l@{}}}
\newcommand{\estack}{\end{array}}

\newenvironment{equations}{\[\ba{@{}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}
\newenvironment{eqs}{\ba{@{}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{clauses}{\ba{@{}l@{~}c@{~}l@{}}}{\ea}

\newenvironment{syn}{\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea}

\newenvironment{syntax}{\[\ba{@{}l@{~}r@{~}c@{~}l@{}}}{\ea\]\ignorespacesafterend}

\newcommand{\judgeword}[1]{~\mathbf{#1}~}

%\renewcommand{\sig}{\Sigma}
%\renewcommand{\sigs}{\Sigma s}
\newcommand{\sigentails}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\hspace{-0.4ex}\text{-\!-}}\,}

%% \newcommand{\sigmodels}[1]{\mathbin{[{\text{\scriptsize ${#1}$}}]\!\mathord{=}}\,}
% \newcommand{\sigentails}[1]{\vdash_{#1}}

\newcommand{\val}[3]  {#1 \vdash {#2} : {#3}}

\newcommand{\rt}[1]{\langle{#1}\rangle}   % returner type

\newcommand{\valg}{\val{\Gamma}}

%% \newcommand{\is}[4]  {#1 \sigentails{#2} {#3} \judgeword{is} {#4}}
%% \newcommand{\isgs}{\is{\Gamma}{\sigs}}

%% \newcommand{\cdoes}[4]{#1 \sigentails{#2} {#3} \judgeword{has} {#4}
%% \newcommand{\cdoesgs}{\cdoes{\Gamma}{\sigs}}


%% some options for rendering bidirectional typing judgements

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \in {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \ni {#4}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

\newcommand{\kindcheckbase}[3]{#2 \mathbin{#1} #3} % For well-kindedness of types
\newcommand{\inferbase}[5]{#1; #3 \mathbin{#2} {#4} \Rightarrow {#5}}
\newcommand{\checkbase}[5]{#1; #3 \mathbin{#2} #5 \mathbin{:} #4}
\newcommand{\patbase}[5]{{#1} \vdash {#4} \mathbin{:} {#3} \mathbin{#2} {#5}}
\newcommand{\bindbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \Rightarrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \Leftarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \uparrow {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#4} \downarrow {#3}}
%% \newcommand{\patbase}[4]{{#3} \mathbin{:} {#2} \mathbin{#1} {#4}}

%% \newcommand{\inferbase}[4]{#2 \mathbin{#1} {#3} \judgeword{infers} {#4}}
%% \newcommand{\checkbase}[4]{#2 \mathbin{#1} {#3} \judgeword{checks} {#4}}
%% \newcommand{\patbase}[4]{{#2} \judgeword{matches} {#3} \mathbin{#1} #4}

\newcommand{\makes}[5]{\inferbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\has}[5]{\checkbase{#1}{\sigentails{#3}}{#2}{#4}{#5}}
\newcommand{\does}[4]{\checkbase{#1}{\vdash}{#2}{#3}{#4}}
\newcommand{\can}[4]{\makes{\kenv}{#1}{#2}{#3}{#4}}

\newcommand{\effs}[2]{{#1} \judgeword{does} {#2}}


% redefinitions for cbv type system
\newcommand{\kindchecks}[2]{\kindcheckbase{\vdash}{#1}{#2}} % Checks that a type is well-kinded
\newcommand{\infers}{\makes}
\newcommand{\checks}{\has}
\newcommand{\checksdef}{\does}
\newcommand{\matchesc}{\matches}
\newcommand{\matchesck}{\matchesc{\kenv}}

\newcommand{\infersk}{\makes{\kenv}}
\newcommand{\checksk}{\has{\kenv}}
\newcommand{\checksdefk}{\does{\kenv}}

\newcommand{\kindchecksk}{\kindchecks{\kenv}} % Checks that a type is well-kinded
\newcommand{\inferskgs}{\makes{\kenv}{\Gamma}{\sigs}}
\newcommand{\checkskgs}{\has{\kenv}{\Gamma}{\sigs}}
\newcommand{\checksdefkg}{\does{\kenv}{\Gamma}}


\newcommand{\adj}{\Delta}
\newcommand{\adapt}{\Theta}
\newcommand{\ext}{\Xi}
\newcommand{\sigs}{\Sigma}
\newcommand{\sig}{I}

\newcommand{\seed}{\sigma}

\newcommand{\effbox}[1]{[#1]}

\newcommand{\key}[1]{\mathbf{#1}} % keyword
\newcommand{\var}{\mathit}        % local variable or meta variable
\newcommand{\defaultvarname}[0]{x}

\newcommand{\op}{\mathsf}  % operator (command or computation)
\newcommand{\con}{\mathsf} % constructor (type or data)
\newcommand{\inter}{\mathsf} % interface
\newcommand{\str}[1]{\textrm{``#1''}} % string literal


\newcommand{\handleSymbol}{\rightarrow}
\newcommand{\handle}[2]{{#1} \handleSymbol {#2}}

\newcommand{\thunk}[1]{\{{#1}\}}

\newcommand{\force}[1]{{#1}!}

\newcommand{\emptylist}{[]}
\newcommand{\cons}{\mathbin{::}}
\newcommand{\concat}{\,\texttt{++}\,} %mathbin{+\!+}}
%\newcommand{\snoc}{\mathbin{:<}}
\newcommand{\snoc}{\ }


\newcommand{\NN}{\mathbb{N}}

\newcommand\slab[1]{(\textrm{#1})}

\newcommand{\ev}{E}
\newcommand{\evd}{\varepsilon}

\newcommand{\effin}[1]{\langle {#1} \rangle}
\newcommand{\effout}[1]{[{#1}]}

\newcommand{\nowt}{\emptyset}
\newcommand{\id}{\iota}
\newcommand{\pid}{\var{s}} % Pattern identity variable

\newcommand{\EC}{\mathcal{E}}
\newcommand{\EF}{\mathcal{F}}
\newcommand{\PC}{\mathcal{P}} % Syntactic phrase class for af operation
\newcommand{\venv}{\theta}

\newcommand{\freeze}{\ceil}

\newcommand{\uc}{\mathord{\downarrow}}
\newcommand{\cu}{\mathord{\uparrow}}

\newcommand{\redto}{\leadsto}
\newcommand{\redtou}{\leadsto_{\mathrm{u}}}
\newcommand{\redtoc}{\leadsto_{\mathrm{c}}}
\newcommand{\stepsto}{\longrightarrow}

\newcommand{\stepstou}{\longrightarrow_{\mathrm{u}}}
\newcommand{\stepstoc}{\longrightarrow_{\mathrm{c}}}

\newcommand{\sigat}{\mathbin{@}}

\newcommand{\meta}{\mathsf}
\newcommand{\level}{\meta{level}}
\newcommand{\af}{\meta{af}}
\newcommand{\handles}{~\meta{handles}~}

\newcommand{\poised}{~\meta{poisedfor}~}
\newcommand{\insts}{\meta{inst}}
\newcommand{\remap}{\meta{remap}}

\newcommand{\sigyields}[1]
           {\mathbin{\text{-\!-\!}[{\text{\scriptsize ${#1}$}}]\,}}

\newcommand{\matches}[5]{\patbase{#1}{\sigyields{#4}}{#2}{#3}{#5}}
\newcommand{\matchesv}[4]{\patbase{#1}{\dashv}{#2}{#3}{#4}}
\newcommand{\matchesvk}{\matchesv{\kenv}}

\newcommand{\bindsv}[4]{\bindbase{\dashv}{#2 \leftarrow #3}{#1}{#4}}
\newcommand{\bindsc}[5]{\bindbase{\sigyields{#4}}{#2 \leftarrow #3}{#1}{#5}}

\newcommand{\letin}[4][\defaultvarname]
           {\key{let}\;{#1}:{#2}={#3}\;\key{in}\;{#4}}
\newcommand{\letxin}[3][\defaultvarname]
           {\key{let}\;{#1}={#2}\;\key{in}\;{#3}}
\newcommand{\letrec}[4][f]{\key{letrec}~\many{{#1}:{#2} = {#3}}~\key{in}~{#4}}
\newcommand{\letrecU}[3][f]{\key{letrec}~\many{{#1} = {#2}}~\key{in}~{#3}}
\newcommand{\Gt}{\theta} % Substitution meta variable
\newcommand{\submap}[2]{{{#1}\vDash{#2}}}
\newcommand{\sub}[4]{#1 \vdash {{#2}:\submap{{#3}}{{#4}}}}
\newcommand{\subk}{\sub{\kenv}}
\newcommand{\subext}[2]{{{#1}{#2}}}
\newcommand{\subst}[3][\defaultvarname]{{#2}[{#3}/{#1}]}

% Frank letrec substitution
\newcommand{\recsub}[5][f]
      {[\many{\cu (\thunk{\many{\many{#2}\mapsto\letrec[{#1}]{#5}{#3}{#4}}}
            : {#5})/{#1}}]}


%%%% START inference rule system for action of adjustment on ability %%%%
\newcommand{\semi}{;}
\newcommand{\kenv}{\Phi}  % kind environment
\newcommand{\kenva}{\Psi} % another kind environment
%% \newcommand{\kenv}{\mathcal{T}} % kind environment
\newcommand{\ienv}{\Omega} % Instance environment
\newcommand{\adjact}[3]{{#1}\vdash{#2}\dashv{#3}}
\newcommand{\adpcom}[5]{{{#1}\vdash{#2}({#3} \to {#4})\dashv{#5}}}
\newcommand{\itrbnd}[5]{{{#1}\vdash{#2}:{#3}\dashv{#4}\semi{#5}}}
% \newcommand{\wf}[2]{{{#1}\vdash{#2}}}
\newcommand{\itrinst}[4]{{{#1}\vdash{#2}:{#3}\dashv{#4}}}

%%% END inference rule system for action of adjustment on ability %%%%%

% Untyped machine letrec substitution
\newcommand{\recsubst}[5]
 {{#1}[\many{(\thunk{\many{\many{#2} \mapsto \letrecU{#3}{#4}}}:{#5})/f}]}

%% Abstract machine commands
% Typing
\newcommand{\HAbs}[2]{{{#1}\to{#2}}}

\newcommand{\fail}{\textbf{fail}}

%% Translation function: Frank Terms to Untyped A-Normal Form
\newcommand{\UANF}[1]{{\llbracket{{#1}}\rrbracket}}

% Terms
\newcommand{\mtrns}[3][]{{#2} & \Rightarrow^{#1} & {#3}} % For array env
\newcommand{\mtrnsR}[3][]{{#2}\Rightarrow^{#1}{#3}}

\newcommand{\confg}[2]{{\langle{{#1}},{{#2}}\rangle}}
\newcommand{\term}[3]
           {{\langle{{#1}},{{#2}}\rangle\downarrow{#3}}}

\newcommand{\admin}[2]{{\langle{{#1}}\mid{{#2}}\rangle}}
\newcommand{\mat}[3]
           {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\rangle}}
\newcommand{\matc}[5]
        {{\langle{{#1}}\mid{{#2}}\mid{{#3}}\mid{{#4}}\mid{{#5}}\rangle}}

\newcommand{\msub}[3][\defaultvarname]{{#2}[{#1}\mapsto{#3}]}

\newcommand{\FHan}[4][\many{\effin{\adj}}]{{({#2}:{#1},{#3}\mid{#4})}}
\newcommand{\FSeq}[2][\defaultvarname]
           {{({#1}.{#2})}}
\newcommand{\SCons}[2]{{{#1}\circ{#2}}}


\newcommand{\HSHan}[5][C]{{{#2}\circ({#3},{#1},{#4}\mid{#5})}}
\newcommand{\HSSeq}[4][\defaultvarname]
           {{#2}\circ({#1}:{#3}.{#4})}
\newcommand{\HSCons}[2]{{{#1}\circ{#2}}}
\newcommand{\NF}[2]{{{#1}~\star~{#2}}}

\newcommand{\evalto}{\Longrightarrow}


\newcommand{\para}[1]{\paragraph{#1.}}

\newcommand{\gor}{\mid}
\newcommand{\pipe}{\texttt{|}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End of inference rules typesetting business
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start of main text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{preliminary}

\title{Asynchronous Effect Handling}

\author{Leo Poulson}

\abstract{

  % Asynchronous programming features are commonplace in modern programming
  % languages; one can request that a task is performed on another thread, perform
  % some other computation, and then collect the results of the remote task later.
  % Such features are often built into the language and are opaque black boxes
  % from the perspective of the user.

  We give an implementation of \citeauthor{ahman2020asynchronous}'s novel
  \emph{asynchronous effects} abstraction, based on effect handlers. The crux of
  this system is the decoupling of the invocation of an effect from the
  resumption of the caller with the handled value.

  We give an implementation in Frank, a language designed around effect
  handlers. We give a series of simple modifications to Frank to allow for
  pre-emptive concurrency, being the non-cooperative scheduling of several
  threads.

  Finally, we show how one can easily and elegantly implement many commonplace
  features of modern programming languages --- such as async-await and futures
  --- with asynchronous effects. Such structures are usually opaque black boxes
  to users; we move them into the hands of the programmer.

  % We show how the \emph{effect handlers} abstraction gives rise to . We describe an implementation of such a library and
 

  % allowing programmers to issue tasks to run on other
  % threads and wait for the results to come back later. These features are often
  % built into the language, and are opaque to the user.

  % In this thesis we show how a library for asynchronous programming can be very
  % easily implemented in a language with existing support for effect handlers. We
  % show how, with a small change to the language implementation, truly
  % asynchronous programming with pre-emptive concurrency is achieved.

  % Our system is expressive enough to define common asynchronous programming
  % constructs, such as async-await and futures, within the language itself.
}

\maketitle

\section*{Acknowledgements}
Thanks to Sam Lindley for giving me the opportunity to write this dissertation,
and for his feedback and support throughout, right up to the end.

Thanks to everyone who made the past year so much fun. Thanks to my parents and grandparents for all of the support throughout the whole process.



\tableofcontents

\end{preliminary}

\chapter{Introduction}

Effects, such as state and nondeterminism, are pervasive when programming; for a
program to do anything beyond compute a pure mathematical function, it must
interact with the outside world, be this to read from a file, make some random
choice, or run concurrently with another program. Algebraic effects and their
handlers (\cite{plotkin2003algebraic, plotkin2013handling}) are a novel way to
encapsulate, reason about and specify computational effects in programming
languages. For instance, a program that reads from and writes to some local
state can utilise the \textsf{State} effect, which supports two
\emph{operations}; \textsf{get} and \textsf{put}. A handler for the
\textsf{State} effect gives a meaning to these abstract operations. Programming
with algebraic effects and handlers is increasingly popular; they have seen
adoption in the form of libraries for existing languages
(\cite{kammar2013handlers, kiselyov2013extensible, brady2013programming}) as
well as in novel languages designed with effect handling at their core
(\cite{bauer2015programming, leijen2017type, convent2020doo}).

Traditional effect handling is \emph{synchronous}; when an operation is invoked,
the rest of the computation is blocked whilst the effect handler performs the
requisite computation and then resumes the original caller.
%
For many effects, this blocking behaviour is not a problem; the handler usually
returns quickly, and the user notices no delay. However, not every possible
computational effect behaves like this; consider an effect involving a query to
a remote database. We might not want to block the rest of the computation whilst
we perform this, as the query might take a long time; this case is even stronger
if we do not immediately want the data. To support this kind of behaviour, we
need to be able to invoke and handle effects in an asynchronous, non-blocking
manner; we characterise this as asynchronous effect handling.

In this project we investigate the implementation and applications of
asynchronous effect handling. Our lens for this is the language
Frank~(\cite{lindley2017do, convent2020doo}), a functional programming designed
with effect handling at its code. We follow the design
of~\aeff~(\cite{ahman2020asynchronous}), a small programming language designed
around asynchronous effects but supporting little else.
%
% We show how, with a small change to the semantics of Frank, we can recreate the
% asynchronous effect handling behaviour of~\aeff~whilst enjoying the benefits of
% traditional effect handlers.
We show how by making a simple change to the semantics of Frank, in order to
yield pre-emptible threads, we can recreate the asynchronous effect handling
behaviour of \aeff~whilst still enjoying the benefits of a language equipped
with traditional effect handlers.
%
Effect handlers have already shown to make complicated control flow easy to
implement (\textbf{refs}), and our work further cements this.

Our contributions are as follows;

\begin{itemize}
  %% \subparagraph*{Asynchronous Effects Library}
\item We present a library for programming with asynchronous effects, built in
  Frank. We show how a complex system can be expressed concisely and elegantly
  when programming in a language with effect handlers.
%% \todo{Rewrite the end of this; slightly
  %% messy}.

%% \subparagraph*{Pre-emptive Concurrency}
\item We show how, by making a small change to the operational semantics of
  Frank, we achieve \emph{pre-emptive concurrency}; that is, the suspension of
  running threads \emph{without} co-operation. It is our hope that this change
  is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples}
\item We also deliver a set of examples of the uses of asynchronous effects, and
  show how they have benefits to other models.
\end{itemize}

\section{Related Work}

Asynchronous programming with effect handlers is a fairly nascent field.
%
Koka (\cite{leijen2014koka}) is a programming language with built-in effect
handlers and a Javascript backend. \citeauthor{leijen2017structured} later shows
us how Koka can naturally support asynchronous programming
(\cite{leijen2017structured}). The asynchronous behaviour relies on offloading
asynchronous tasks with a \textsf{setTimeout} function supplied by the NodeJS
backend.

Multicore OCaml (\cite{dolan2014multicore}) also supports asynchronous
programming through effect handling (\cite{dolan2017concurrent}). The asynchronous behaviour of this approach relies on asynchronous signals performed by the operating system, such as a periodic \textsf{timer} message interrupting thread execution to yield pre-emptive concurrency.

% They handle
% effects and signals, which can be received asynchronously, and show how to
% efficiently and safely write concurrenct systems programs. However, in a similar
% way to Koka, the asynchrony relies on the operating system supplying operations,
% such as \textsf{setSignal} and \textsf{timer} signals.

A problem shared by both Koka and Multicore OCaml is they have no support for
\emph{user-defined} asychronous effects; the asynchronous signals that can be
received are predefined. This problem is solved by
\aeff~(\cite{ahman2020asynchronous}), a small language built around asynchronous
effect handling. \citeauthor{ahman2020asynchronous} approach the problem of
asynchrony from a different perspective, by decoupling the invocation of an
effect from its handling and resumption with the handled value. When an effect
is invoked the rest of the computation is not blocked whilst the handler is
performed. Programs then install interrupt handlers that dictate how to act on
receipt of a particular interrupt. To recover synchronous behaviour, these
interrupt handlers can be \textsf{await}ed; this will block the rest of the code
until the interrupt is received.

\citeauthor{ahman2020asynchronous} then show how the simple building blocks of
interrupt handlers can be used to build common constructs for asynchronous
programming, such as cancellable remote function calls and a pre-emptive
scheduler.

% We design our system based on \aeff, embedding its behaviour into Frank. We show
% that we can easily recover the behaviour of \aeff~when equipped with effect
% handlers, and show that asynchronous effects can still be used in conjunction
% with traditional, synchronous effects.

%
%The most prominent work is \aeff~(\cite{ahman2020asynchronous}),

%% \paragraph*{Contributions}

%% \subparagraph*{Asynchronous Effects Library} We present a library for programming
%% with asynchronous effects in the style of \aeff, built in Frank. We show how a
%% complex system can be expressed concisely and elegantly when programming in a
%% language with effect handlers, further cementing the case for effects as a
%% foundation for concurrent programming. \todo{Rewrite the end of this; slightly
%%   messy}.

%% \subparagraph*{Pre-emptive Concurrency} We show how, by making a small change to
%% the operational semantics of Frank, we achieve pre-emptive concurrency; that is,
%% the suspension of running threads \emph{without} co-operation. It is our hope
%% that this change is simple enough to be transferrable to other languages.

%% \subparagraph*{Examples} We also deliver a set of examples of the uses of
%% asynchronous effects, and show how they have benefits to other models.

\section{Structure}

In Chapter~\ref{chap:programming-in-frank} we give an introduction to
programming with effects in Frank. We skip over some unneeded (and previously
well-covered) parts of the language, such as adaptors, in the interests of time.

In Chapter~\ref{chap:formalisation} we give the formalisation of Frank. Again,
we skip over extraneous details which can be seen in past work
(\cite{convent2020doo}), opting to only describe the parts needed to understand
the changes to the semantics for the following chapter.

In Chapter~\ref{chap:preemptive-concurrency} we show how by making a small
change to the semantics of Frank we yield pre-emptible threads; that is, we can
interrupt a function in the same co-operative style but without co-operation.

In Chapter~\ref{chap:implementation} we introduce the asynchronous effects
abstraction and explain how it is implemented in Frank.
% In Chapter~\ref{chap:implementation} we describe the implementation of our
% asynchronous effect handling library in Frank.

In Chapter~\ref{chap:examples} we give examples of the new programs that become
easily expressible when combined with the changes made in
Chapter~\ref{chap:preemptive-concurrency}.

In Chapter~\ref{chap:conclusion} we conclude.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Programming in Frank}
\label{chap:programming-in-frank}

In this chapter we introduce Frank, and show why it is a well-suited language
for implementing an asynchronous effect handling library. We assume some
familiarity with typed functional programming, and skip over some common
features of Frank --- algebraic data types, pattern matching, etc --- so we can
spend more time with the novel, interesting parts; namely the definition,
control and handling of algebraic effects and the fine-grained control over
evaluation of computations.

% \todo{Talk about adaptors?}

% Frank is a typed functional programming language, designed around the
% definition, control and handling of algebraic effects. As such, Frank has an
% effect type system used to track which effects a computation may use.

% \todo{Extend this a bit - talk about ambient ability, computation vs. value, etc}

% % Frank offers very fine-grained control over computations. It clearly
% % distinguishes between computation and value, and offers \emph{multihandlers} to
% % carefully control when computations are evaluated. This combined with effect
% % handling provides a very rich foundation for expressing complex control
% % structures.

% In this chapter we introduce Frank, and show why it is so well-suited to our
% task. We assume some familiarity with typed functional programming, and skip
% over some common features of Frank --- algebraic data types, pattern matching,
% etc. --- so we can spend more time with the novel, interesting parts. We also
% skip some novel features of Frank, such as
% adaptors~(\cite{convent2017enhancing}), as they are not essential for
% understanding the work of this project.

% \section{Types, Values and Operators}
\paragraph*{Types, Values and Operators}

Frank types are distinguished between \emph{effect types} and \emph{value
  types}. Value types are the standard notion of type; effect types are
used to describe where certain effects can be performed and handled. Value types are further divided into traditional data types, such a \code{Bool},
\code{List X}, and \emph{computation types}.

A computation type
%
\lstinline[mathescape]!{X$_1$ -> $\ldots$ -> X$_m$ -> [I$_1$, $\ldots$, I$_n$] Y}!
%
%% This type expresses that the operator can handle some effect in the first
%% argument and then performs some other effects as a result, returning a value of
%% type \code{Y}.
describes an operator that takes $m$ arguments and returns a value of type
\code{Y}. The return type also expresses the \emph{ability} the computation
needs access to, being a list of $n$ \emph{interface} instances; we explain
abilities in more detail later in this chapter. An interface is a collection of
\emph{commands} which are offered to the computation.

% An ability is a

% \todo{Go more into depth about 'abilities'?}

%% Frank then specialises effect handling to traditional function application; a
%% function is the special case of an operator that handles no arguments. We see
%% that a function type \code{\{X -> Y -> Z\}} is just a special case of the
%% general operator type where no effects are handled or performed. Throughout this
%% thesis, we call

\paragraph*{Thunks}

\emph{Thunks} are the special case of an $n$-ary function that takes 0
arguments. We can evaluate them --- performing the suspended computation ---
with the 0-ary sequence of arguments, denoted \code{!}.
%
% Computations are suspended by wrapping them in braces.
The opposite action --- suspending a computation --- is done by surrounding the
computation in braces.
% , such that for a suspended computation \code{comp},
% \code{\{comp!\}} is the identity.
%
This gives us fine-grained control over when we want to evaluate computations.
For example, consider the operator \code{badIf} below:


\begin{lstlisting}
badIf : {Bool -> X -> X -> X}
badIf true  yes no = yes
badIf false yes no = no
\end{lstlisting}

\noindent Frank is a \emph{left-to-right}, \emph{call-by-value} language; all
arguments to operators are evaluated from left-to-right until they become a
value. As such, in the case of \code{badIf}, both of the branches will be
evaluated before the result of one of them is returned. We can recover the
correct semantics for \code{if} by giving the branches as thunks:

\begin{lstlisting}
if : {Bool -> {X} -> {X} -> X}
if true  yes no = yes!
if false yes no = no!
\end{lstlisting}

\noindent Here a single thunk is evaluated depending on the value of the
condition. Frank's distinction between computation and value make controlling
evaluation simple.

%% \todo{Example --- maybe fire missiles one?}

% \section{Effects and Effect Handling}
% \label{sec:effects}

\paragraph*{Interfaces and Operations}

Frank encapsulates effects through \emph{interfaces}, which offer
\emph{commands}. For instance, the \code{State} effect (interface) offers two
operations (commands), \code{get} and \code{put}. In Frank, this translates to

\begin{lstlisting}
  interface State X = get : X
                    | put : X -> Unit

  interface RandInt = random : Int
\end{lstlisting}

The interface declaration for \code{State X} expresses that \code{get} is a
0-ary operation which is \emph{resumed} with a value of type \code{X}, and
\code{put} takes a value of type \code{X} and is resumed with \code{unit}.
Computations get access to an interface's commands by including them in the
\emph{ability} of the program; the computation then needs to be executed in an
\emph{ambient ability} containing the corresponding interface. Commands are
invoked just as normal functions;

\begin{lstlisting}
  xplusplus : {[State Int] Unit}
  xplusplus! = put (get! + 1)
\end{lstlisting}

\noindent This familiar program increments the integer in the state by 1.
% The
% type of \code{xplusplus} expresses that it needs to be executed in an
% \emph{ability} containing the \code{State Int} interface.


\paragraph*{Handling Operations}

%% Traditional functions in Frank are a specialisation of Frank's handlers; that is
%% to say, functions are handlers that handle no effects. A handler for an
%% interface pattern matches \emph{on the operations} that are invoked, as well as
%% on the \emph{values} that the computation can return. Furthermore, the handler
%% gets access to the \emph{continuation} of the calling function as a first-class
%% value. Consider the handler for \code{State};

A handler for a specific interface can also pattern match on the
\code{operations} that are performed, and not just the values that can be
returned. As an example, consider the canonical handler for the \code{State S}
interface.

\begin{lstlisting}
  runState : {<State S> X -> S -> X}
  runState <get -> k>   s = runState (k s) s
  runState <put s -> k> _ = runState (k unit) s
  runState x            _ = x
\end{lstlisting}

%% \noindent The type of \code{runState} expresses that the first argument is a
%% computation that can perform \code{State S} effects and will eventually return a
%% value of type \code{X}, whilst the second argument is a value of type \code{S}.

\noindent Observe that the type of \code{runState} contains \code{<State S>},
called an \emph{adjustment}. This expresses that the first argument to
\code{runState} has the \code{State S} interface added to its \emph{ambient
  ability}. It also expresses that \code{runState} handles commands in the
\code{State S} interface, using \emph{computation pattern matching}.

\paragraph*{Computation Patterns} The second and third lines of \code{runState}
specify how we handle \code{get} and \code{put} commands. We use a new type of
pattern, called a \emph{computation pattern}; these are made up of a command and
some arguments (which are also values, and can be pattern matched on), plus the
continuation of the calling code. The types of arguments and the continuation
are determined by the interface declaration and the type of the handler; for
instance, in \code{<get -> k>} the type of \code{k} is \code{\{S -> [State S]
  X\}}. The continuation can then perform more \code{State S} effects; this is
characterised as \emph{shallow} effect handling.
%
This is in contrast to \emph{deep} handlers, where the continuation is
automatically re-handled by the same handler. These are defined by folds ---
specifically \emph{catamorphisms} (\cite{meijer1991functional}) --- over
computation trees; this is attractive as they allow for efficient optimisations
such as fusion of effect handlers (\cite{wu2015fusion}).
% This differs to some other implementations of effect handling languages
% (\cite{kammar2013handlers}) where the handlers can be \emph{deep}, meaning the
% continuation has been re-handled by the same handler automatically. Frank's
% \emph{shallow} handlers mean we have to explicitly re-handle the continuation,
% however this gives us the benefit of
Frank's \emph{shallow} handlers only handle the first instance of an operation;
we then have to explicitly re-handle the continuation. This lets us choose to
rehandle the computation in a non-standard way if we wish.

In short, effect handling in Frank is essentially just a generalisation of
traditional pattern matching to pattern matching on \emph{computations} as well.


%% What happens when we run \code{runState xplusplus! 0}? When a computation is
%% invoked, it is performed until it results in either a \emph{value} or a
%% \emph{command}. Thus, \code{runState} will be paused until \code{xplusplus!}
%% reduces; \code{runState} is resumed when \code{xplusplus} is in one of these two
%% forms.

%% \code{xplusplus} instantly invokes \code{get!}. At this point, control is given
%% to the handler \code{runState}; both in the sense that \code{runState} is now
%% being executed by the interpreter, and that \code{runState} has control over the
%% \emph{continuation} of \code{xplusplus}, which is a function of type \code{Int
%%   -> [State Int] Unit}. We see that \code{runState} chooses to resume this
%% continuation with the value of the state at that time.

\paragraph*{Effect Forwarding}

Effects that are not handled by a particular handler are left to be forwarded up
to the next one. For instance, we might want to write a random number to the
state;

\begin{lstlisting}
  xplusrand : {[State Int, RandomInt] Unit}
  xplusrand! = put (get! + random!)
\end{lstlisting}

\noindent We then have to handle both the \code{State Int} and \code{Random}
effect in this computation. Of course, we could just define one handler for both
effects; however in the interests of \emph{modularity} we want to define two
different handlers for each effect and \emph{compose} them. We can reuse the
same \code{runState} handler from before, and define a new handler for
\code{RandomInt} to generate pseudorandom numbers;

\begin{lstlisting}
  runRand : {Int -> <RandomInt> X -> X}
  runRand seed <random -> k> = runRand (mod (seed + 7) 10) (k seed)
  runRand _ x = x
\end{lstlisting}

\noindent From its type, we see that \code{xplusrand} requires the ambient
ability \code{[State Int, RandomInt]}. We can easily produce such an ability by
composing the two handlers we have, incrementally extending the ambient ability.
\cite{convent2017enhancing} gives a more detailed account of operator
composition in Frank and the different cases that can arise.


% Observe that the interaction between \code{xplusrand} and the handlers becomes
% like a conversation; the caller asks the handler for a result and waits,
% blocking, until the handler responds. We can characterise this as
% \emph{synchronous} effect handling. But what if we want to make a request for
% information --- such as the pseudorandom number --- and do something else, then
% pick it up later? We cannot just invoke \code{random} as this would block whilst
% the number is generated, which could possibly take a long time. This
% \emph{asynchronous} behaviour is exactly what we look for in this project.

% \todo{Maybe show example of how the order of composition can change the ending
%   semantics --- a la state + aborting}

\paragraph*{Top-Level Effects}
Some effects need to be handled by the Frank interpreter, as Frank is not
expressive or capable enough on its own. Examples are console I/O, web requests,
and ML-style state cells. These effects will pass through the whole stack of
handlers up to the top-level, at which point they are handled by the
interpreter.


\paragraph*{Implicit Effect Polymorphism}

Consider the type of the well-known function \code{map}, implemented in Frank;

\begin{lstlisting}
  map : {{X -> Y} -> List X -> List Y}
  map f [] = []
  map f (x :: xs) = (f x) :: (map f xs)
\end{lstlisting}

\noindent One might expect that the program \code{map \{_ -> random!\} [1, 2, 3]}
would give a type error; we are mapping a function of type \code{\{Int ->
  [RandomInt] Int\}}, which does not match the argument type \code{\{X -> Y\}}.
However, Frank uses a shorthand for \emph{implicit effect variables}. The
desugared type of \code{map} is actually:

\begin{lstlisting}[mathescape]
  map : {{X -> [$\epsilon$|] Y} -> List X -> [$\epsilon$|] List Y}
\end{lstlisting}

\noindent Effect variables mean that operators can become \emph{effect
  polymorphic}. This type expresses that whatever the ability is of \code{map f
  xs} will be offered to the element-wise operator \code{f}.

A similar thing happens in interface declarations; the interface \code{Co} below
desugars to \code{CoVerbose}:

\begin{lstlisting}[mathescape]
interface Co X            = fork : {[Co X] X} -> Unit
interface CoVerbose X [$\epsilon$] = fork : {[$\epsilon$ | Co X [$\epsilon$|]] X} -> Unit
\end{lstlisting}


\paragraph*{Polymorphic Commands}

As well as having polymorphic interfaces, such as \code{State X}, parametrised
by e.g.~the data stored in the state, Frank supports polymorphic
\emph{commands}. These are commands which can be instantiated for any type. An
example is ML-style references, realised through the \code{RefState} interface:

\begin{lstlisting}
interface RefState = new X   : X -> Ref X
                   | read X  : Ref X -> X
                   | write X : Ref X -> X -> Unit
\end{lstlisting}

\noindent where the type variables are determined based on the arguments supplied
the operations.

\section{Case Study: Cooperative Concurrency}
\label{sec:concurrency}

%% Frank is a single-threaded language. It is fortunate, then, that effect handlers
%% give us a malleable way to run multiple program-threads ``simultaneously'' \todo
%% {This is poorly written --- fix}.

Effect handlers have proved to be useful abstractions for concurrent programming
(\cite{dolan2015effective, dolan2017concurrent, hillerstrom2016compilation}).
This is partly because the invocation of an operation not only offers up the
operation's payload, but also the \emph{continuation} of the calling
computation. For many effects, such as \code{getState}, nothing interesting
happens to the continuation and it is just resumed immediately. But these
continuations are first-class; they can resumed, but also stored elsewhere or
even thrown away. We illustrate this with some examples of co-operative schedulers.


%
%As such, by handling
%% \code{Yield} operations, we easily pause and switch between several threads.

\subsection{Simple Scheduling}
\label{subsec:simple-scheduling}

We introduce some simple programs and some scheduling \emph{multihandlers}, to
demonstrate how subtly different handlers generate different scheduling
strategies. A multihandler is simply an operator that handles multiple effects from different sources simultaneously.

\begin{lstlisting}
interface Yield = yield : Unit

words : {[Console, Yield] Unit}
words! = print "one "; yield!;
         print "two "; yield!;
         print "three "; yield!

numbers : {[Console, Yield] Unit}
numbers! = print "1 "; yield!;
           print "2 "; yield!;
           print "3 "; yield!
\end{lstlisting}

First note the simplicity of the \code{Yield} interface; we have one operation
supported, which looks very boring; the operation \code{yield!} will just return
unit. It is the way we \emph{handle} yield that is more interesting. We can write a multihandler to schedule these two threads like so:

\begin{lstlisting}[numbers=left]
schedule : {<Yield> Unit -> <Yield> Unit -> Unit}
schedule <yield -> m> <yield -> n> = schedule (m unit) (n unit)
schedule <yield -> m> <n> = schedule (m unit) n!
schedule <m> <yield -> n> = schedule m! (n unit)
schedule _ _ = unit
\end{lstlisting}

When we run \code{schedule words! numbers!} we read \code{one 1 two 2 three 3
  unit} from the console. What happened? First \code{words} is evaluated until
it results in a \code{yield} command. Recall that Frank is a left-to-right
call-by-(command-or-)value language; at this point, we start evaluating the
second argument, \code{numbers}. This again runs until a \code{yield} is
performed, where we return control to the scheduler. Now that all arguments are
commands or values we can proceed with pattern matching; the first case matches
and we resume both threads, handling again. This process repeats until both
threads evaluate to \code{unit}. In this way, we can imagine multihandler
arguments as running in parallel and then \emph{synchronising} when all
arguments perform commands and control returns to the multihandler.

% If we omit line 2 we get quite a different result; the console output would be
% \code{one 1 two three 2 3}. This is because both threads are first evaluated
% until they are either a command or a value; this prints out \code{one 1}. Here
% we see the first use of the catch-all pattern \code{<n>}, which matches either a
% command or a value. At this point we resume the first thread, but the second
% thread remains blocked as the \code{yield} invocation has not been handled. We
% evaluate the first thread until it is \code{unit}, at which point we do the same
% to the second thread.

%% If we omit the first line of pattern matching (line 2) we get quite a different
%% result; the console output would be \code{one 1 two three 2 3}. This is because
%% both threads are evaluated until they are \code{yield} invocations, printing out
%% \code{one 1}; but then only the first thread is resumed. We then evaluate
%% \code{words} until it becomes a \code{unit} value. At this point the patterns on
%% line 4 match, as the catchall pattern \code{<m>} will match commands or values.
%% We then evaluate \code{numbers} until this is also \code{unit}.

%% \begin{lstlisting}
%% -- Runs all of the LHS first, then the RHS.
%% scheduleA : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleA <yield -> m> <n> = scheduleA (m unit) n!
%% scheduleA <m> <yield -> n> = scheduleA m! (n unit)
%% scheduleA _ _ = unit

%% -- Lets two yields synchronise, then handles both
%% scheduleB : {<Yield> Unit -> <Yield> Unit -> Unit}
%% scheduleB <yield -> m> <yield -> n> = scheduleB (m unit) (n unit)
%% scheduleB <yield -> m> <n> = scheduleB (m unit) n!
%% scheduleB <m> <yield -> n> = scheduleB m! (n unit)
%% scheduleB _ _ = unit
%% \end{lstlisting}

%% \todo{Can maybe delete the 2nd and 3rd matches of scheduleB to make the point
%%   more clear?}

%% We see two multihandlers above. Each take two \code{yield}ing threads and
%% schedule them, letting one run at a time. \code{scheduleA} runs the first thread
%% to completion, and only then runs the second one; the first time that the second
%% thread \code{yield}s it is \emph{blocked}, and can no longer execute. As such,
%% the output of \code{scheduleA words! numbers!} is \code{one 1 two three 2 3
%%   unit}.

%% \code{scheduleB} is fairer and more profound. We run \code{scheduleB words!
%%   number!} and receive \code{one 1 two 2 three 3 unit}; \code{scheduleB} is fair
%% and will ``match'' the yields together. We step through slowly. First
%% \code{words!} will print \code{one}, then it will \code{yield}. At this point
%% --- recalling that multihandlers pattern match left-to-right --- the second
%% thread, \code{numbers!}, is allowed to execute. In the meantime, \code{words!}
%% is stuck as \code{<yield -> m>}; it cannot evaluate any further, it is
%% \emph{blocked}. Whilst \code{words} is blocked \code{numbers!} prints \code{1}
%% and then \code{yield}s. Great; now the first case matches. Both threads are
%% resumed and the process repeats itself.

%% \todo{ The second paragraph here is a more compelling explanation; maybe we can
%%   just get rid of all of the scheduleA business and /just/ have the scheduleB
%%   stuff? scheduleA is quite obvious i think whilst B is more subtle and compelling. }

%% \todo{ It's not true that it matches L-R as much as runs all computations L - R
%%   until they are all a command / value - fix this }

\subsection{Forking New Processes}
\label{subsec:forking-new-processes}

We can make use of Frank's higher-order effects to dynamically create new
threads at runtime. We strengthen the \code{Yield} interface by adding a new
operation \code{fork}:

\begin{lstlisting}
interface Co = fork : {[Co] Unit} -> Unit
             | yield : Unit
\end{lstlisting}

The operation \code{fork} takes a suspended computation that can perform further
\code{Co} effects and returns unit once handled. An example program using this
interface is \code{forker}:

\begin{lstlisting}
forker : {[Console, Co [Console]] Unit}
forker! = print "Starting! ";
          fork {print "one "; yield!; print "two "};
          fork {print "1 "; yield!; print "2 "};
          exit!
\end{lstlisting}

We can now choose a strategy for handling \code{fork} operations; we can either
lazily run them, by continuing our current thread and then running the forked
thread later, or eagerly run them, suspending the currently executing thread and
running the forked process straight away. The handler for the former,
breadth-first style of scheduling, is:

\begin{lstlisting}
interface Queue = enqueue : {[Queue] Unit} -> Unit
                | runNext : {[Queue] Unit}

scheduleBF : {<Co> Unit -> [Queue] Unit}
scheduleBF <fork p -> k> = enqueue {scheduleBF (<Queue> p!)};
    scheduleBF (k unit)
scheduleBF <yield -> k> = enqueue {scheduleBF (k unit)};
    (dequeue!)!
scheduleBF unit =
    (dequeue!)!
\end{lstlisting}

We have to handle the computation \code{scheduleBF forker!} with a handler for
\code{Queue} effects afterwards. We can abstract over different queue handlers
for even more possible program combinations. Moreover, notice how concisely we
can express the scheduler; this is due to the handler having access to te
continuation of the caller, and treating it as a first-class object that can be
stored elsewhere.

\chapter{Formalisation of Frank}
\label{chap:formalisation}

The formalisation of the Frank language has been discussed at length in previous
work~(\cite{convent2020doo}). However, in order to illustrate changes made to
the language in this work, we explain some of the relevant parts of the
language. Later in this thesis we refer to the system presented in this chapter as \purefrank.

\begin{figure}[h]  %\figrule
\scalebox{\figscale}{%
\[
\ba{@{}c@{}}
\ba{@{}c@{\quad\quad}c@{}}
\begin{syn}
  \slab{data types}            & D \\
  \slab{value type variables}  & X \\
  \slab{effect type variables} & E \\
  \slab{value types}           & A, B   &::= & D~\overline{R} \\
                               &        &\gor& \thunk{C} \gor X \\
  \slab{computation types}     & C      &::= & \many{T \to}~G \\
  \slab{argument types}        & T      &::= & \effin{\adj}A \\
  \slab{return types}          & G      &::= & \effout{\sigs}A \\

  \slab{type binders}          & Z      &::= & X \gor [E]\\
  \slab{type arguments}        & R      &::= & A \gor [\Sigma]\\
  \slab{polytypes}             & P      &::= & \forall \overline{Z}.A \\
\end{syn}
&
\begin{syn}
  \slab{interfaces}           & I \\
  \slab{term variables}       & x, y, z, f \\
  \slab{instance variables}   & \pid, a, b, c \\
  \slab{seeds}                & \seed  &::= & \nowt \gor \ev \\
  \slab{abilities}            & \sigs  &::= & \seed\pipe\ext \\
  \slab{extensions}           & \ext   &::= & \id \gor \ext, \sig~\many{R} \\
  \slab{adaptors}             & \adapt &::= & \id \gor \adapt, \sig(S \to S') \\
  \slab{adjustments}          & \adj   &::= & \adapt\pipe\ext \\
  \slab{instance patterns}    & S      &::= & \pid \gor S \snoc a \\
  \slab{kind environments}    & \kenv,
                                \kenva &::= & \cdot \gor \kenv, Z \\
  \slab{type environments}    & \Gamma &::= & \cdot \gor \Gamma, x:A %\\
%                              &        &    & \hphantom{\cdot}
                                              \gor \Gamma, f:P\\
 \slab{instance environments} & \ienv  &::= & \pid:\sigs \gor \ienv, a:\sig~\many{R}\\
\end{syn} \\
\ea \\
\ea
\]}
%% \\[0.25cm]

\caption{Types}
\label{fig:types}
%\figrule
\end{figure}

\paragraph*{Types}
Value types are either datatypes instantiated with type arguments
$D~\overline{R}$, thunked computations $\thunk{C}$, or value type variables $X$.
%
Computation types are of the form
\[
  C = \effin{\adapt_1\pipe\ext_1}A_1 \to \dots \to \effin{\adapt_\pipe\ext_}A_ \to \effout{\sigs} B
\]

\noindent where a computation of type $C$ handles effects in $\ext_i$ or pattern
matches in $A_i$ on the $i$-th argument and returns a value of type $B$. $C$ may
perform effects in ability $\sigs$ along the way.
%
The $i$-th argument to $C$ can perform effects in $\sigs$ adapted by adaptor
$\adapt_i$ and augmented by extension $\ext_i$. We omit details on adaptors as
they are present in previous work (\cite{convent2020doo}). The same goes for the
typing rules, which do not change.

An ability $\sigs$ is an extension $\ext$ plus a seed, which can be closed
($\nowt$) or open $\ev$. This lets us explicitly choose whether a function can
be effect polymorphic, as discussed earlier. An extension $\ext$ is a finite
list of interfaces.

%% We deliberately leave out details on adaptors for the sake of brevity. We also
%% skip over the typing rules, as they are standard. These can be seen in the
%% appendix.


\begin{figure} %\figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
  %% \slab{monomorphic term variables} & x, y, z \\
  %% \slab{polymorphic term variables} & f \\
  \slab{constructors}               & k \\
  \slab{commands}                   & c \\
  \slab{uses}                 & m      &::= &
     x \gor f~\many{R} \gor m~\many{n} \gor \cu(n:A) \\
  \slab{constructions}        & n      &::= &
    \uc m \gor k~\many{n} \gor c~\many{R}~\many{n} \gor \thunk{e} \\
                              &        &\gor& \key{let}~f : P = n~\key{in}~n'
                                   \gor
                                   \key{letrec}~\many{f : P = e}~\key{in}~n \\
                              &        &\gor&  \effin{\adapt}~n \\
  \slab{computations}         & e      &::=& \many{\many{r} \mapsto n}
  \\
  \slab{computation patterns} & r      &::=& p
                                        \gor \effin{\handle{c~\many{p}\,}{z}}
                                        \gor \effin{x} \\
  \slab{value patterns}       & p      &::=& k~\many{p} \gor x        \\
\end{syntax}
}
%% \\[0.25cm]
%\textit{with} term variables $x$, $y$, $z$, polymorphic term variables $f$, constructors $k$, commands $c$\\[0.25cm]
\caption{Terms}
\label{fig:terms}
% \figrule
\end{figure}

\paragraph*{Terms} Frank uses bidirectional typing (\cite{pierce2000local}); as such, terms are
split into \emph{uses} whose types are inferred, and \emph{constructions}, which
are checked against a type. Uses are monomorphic variables $x$, polymorphic
variable instantiations $f~\many{R}$, applications $m~\many{n}$ and type
ascriptions $\cu(n:A)$. Constructions are made up of uses $\uc m$, data
constructor instances $k~\many{n}$, suspended computations $\thunk{e}$, let
bindings $\key{let}~f : P = n~\key{in}~n'$, recursive let $\key{letrec}~\many{f
  : P = e}~\key{in}~n$ and adaptors $\effin{\adapt}~n$. We can inject a use into
a construction and vice versa ($\uc$, $\cu$); in real Frank code these are not
present.

Computations are produced by a sequence of pattern matching clauses. Each
pattern matching clause takes a sequence $\many{r}$ of computation patterns.
These can either be a request pattern $\effin{\handle{c~\many{p}\,}{z}}$, a
catch-all pattern $\effin{x}$, or a standard value pattern $p$. Value patterns
are made up of data constructor patterns $k~\many{p}$ or variable patterns $x$.

\paragraph*{Runtime Syntax}

The operational semantics uses the runtime syntax of
Figure~\ref{fig:runtime-syntax}.
%
Uses and constructions are further divided into those which are values and those
which are not. Values are either variable or datatype instantiations, or
suspended computations.
%
We also declare a new class of \emph{normal forms}, to be used in pattern
binding. These are either construction values or \emph{frozen commands},
$\freeze{\EC[c~\many{R}~\many{w}]}$.
%
%% with a special term $\freeze{\EC[c~\many{R}~\many{w}]}$, of \emph{frozen
%%   commands}. We discuss these further later.
Frozen commands are used to capture a continuation's \emph{delimited
  continuation}, being the largest surrounding continuation up to where it is
handled. As soon as a command is invoked it becomes frozen; the entire rest of
the computation around the frozen command then also freezes (in the same way
that water behaves around ice), until we reach a handler for the frozen command.

Finally we have evaluation contexts, which are sequences of evaluation frames.
The interesting case is $u~(\many{t}, [~],\many{n})$; it is this that gives us
left-to-right call-by-value evaluation of multihandler arguments.

\begin{figure}[t]
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{constructions}           & n   &::= & \dots \mid \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}
\caption{Runtime Syntax}
\label{fig:runtime-syntax}
%% \figrule
\end{figure}

\paragraph*{Operational Semantics} Finally, the operational semantics are given
in Figure~\ref{fig:operational-semantics}.

The essential rule here is \textsc{R-Handle}. This relies on a new relations
regarding \emph{pattern binding} (Figure~\ref{fig:pattern-binding}).
$\bindsc{r}{T}{t}{\sigs}{\venv}$ states that the computation pattern $r$ of type
$T$ at ability $\sigs$ matches the normal form $t$ yielding substitution
$\venv$. The index $k$ is then the index of the earliest line of pattern matches
that all match. The conclusion of the rule states that we then perform the
substitutions $\many{\venv}$ that we get on the return value $n_k$ to get our
result. This is given type $B$.

\textsc{R-Ascribe-Use} and \textsc{R-Ascribe-Cons} remove unneeded conversions
from use to construction. \textsc{R-Let} and \textsc{R-LetRec} are standard.
\textsc{R-Adapt} shows that an adaptor applied to a value is the identity.

We have several rules regarding the freezing of commands. When handling a
command, we need to capture its delimited continuation; that is, the largest
enclosing evaluation context that does \emph{not} handle it.
\textsc{R-Freeze-Comm} expresses that invoked commands instantly become frozen;
\textsc{R-Freeze-Frame-Use} and \textsc{R-Freeze-Frame-Cons} show how the rest
of the context becomes frozen. These two rules rely on the predicate $\EC~
\textsf{handles}~c$. This is true if the context does indeed handle the
command $c$; i.e.\ it is a context of the form $u~(\many{t}, [~], \many{u'})$
where $u$ is a handler that handles $c$ at the index corresponding to the hole.
Thus, the whole term is frozen up to the first handler, at which point is it
handled with \textsc{R-Handle}.

The $\textsc{R-Lift}$ rules then express that we can perform any of these
reductions in any evaluation context.

\begin{figure}
%% \figrule
\flushleft
\scalebox{\figscale}{%
$\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
    \stepstou m'} \quad \boxed{n \stepstoc n'}$}

\centering
\scalebox{\figscale}{%
\\
\begin{mathpar}
\inferrule[R-Handle]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A \to}~\effout{\sigs}B})~\many{t} \redtou \cu ((\many{\venv}(n_k) : B)}

\inferrule[R-Ascribe-Use]
  { }
  {\cu(\uc u:A) \redtou u}

\inferrule[R-Ascribe-Cons]
  { }
  {\uc \cu (w : A) \redtoc w}

\inferrule[R-Let]
  { }
  {\key{let}~f:P = w~\key{in}~n \redtoc n[\cu (w : P)/f]}

\inferrule[R-LetRec]
  {\many{e = \many{\many{r} \to n}}}
  {%\vphantom{\many{\many{\many{\many{f}}}}}
   \key{letrec}~\many{f:P = e}~\key{in}~n' \redtoc
    n'[\many{\cu (\thunk{\many{\many{r} \to \key{letrec}~\many{f:P = e}~\key{in}~n}}: P)/f}]}

\inferrule[R-Adapt]
  { }
  {\effin{\adapt}~w \redtoc w}

\inferrule[R-Freeze-Comm]
  { }
  {c~\many{R}~\many{w} \redtoc \freeze{c~\many{R}~\many{w}}}\\

\inferrule[R-Freeze-Frame-Use]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtou \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\inferrule[R-Freeze-Frame-Cons]
  {\neg(\EF[\EC] \handles c)}
  {\EF[\freeze{\EC[c~\many{R}~\many{w}]}] \redtoc \freeze{\EF[\EC[c~\many{R}~\many{w}]]}}

\\
\inferrule[R-Lift-UU]
  {m \redtou m'}
  {\EC[m] \stepstou \EC[m']}

\inferrule[R-Lift-UC]
  {m \redtou m'}
  {\EC[m] \stepstoc \EC[m']}

\inferrule[R-Lift-CU]
  {n \redtoc n'}
  {\EC[n] \stepstou \EC[n']}

\inferrule[R-Lift-CC]
  {n \redtoc n'}
  {\EC[n] \stepstoc \EC[n']}
\end{mathpar}
}

\caption{Operational Semantics}
\label{fig:operational-semantics}
%% \figrule
\end{figure}

\paragraph*{Pattern Binding}

We now discuss the pattern binding rules of Figure~\ref{fig:pattern-binding}.
The relation $\bindsv{p}{A}{w}{\venv}$ states that a value pattern $p$ of type
$A$ matches normal form $w$ yielding substitution $\venv$. \textsc{B-Var} states
that any pattern $w$ matches a value $x$, whilst \textsc{B-Data} states that a
constructor pattern $k \many{w}$ matches a construction term $k \many{p}$ if
each subpattern $p_{i}$ matches an argument to the construction $w_{i}$.


The rules regarding $\bindsc{r}{T}{t}{\sigs}{\venv}$ are more interesting.
\textsc{B-Value} defers computation pattern matching onto value pattern
matching. \textsc{B-Request} expresses that a computation pattern
$\effin{c~\many{p} \to z}$ matches a frozen computation
$\freeze{\EC[c~\many{R}~\many{w}]}$ if command $c$ is handled by the evaluation
context $\EC$, and if the arguments to the command each match a subpattern in
the computation pattern.

The catchall pattern $\effin{x}$ matches any value and any command that is
handled by the current evaluation context; \textsc{B-CatchAll-Value} and
\textsc{B-CatchAll-Request} express this. Observe that
\textsc{B-CatchAll-Request} has the same constraints as \textsc{B-Request}; the
computation pattern only matches a command if it could otherwise be handled.

\begin{figure}
%% \figrule
\flushleft
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
$\boxed{\bindsc{r}{T}{t}{\sigs}{\venv}}$
}


\centering
\scalebox{\figscale}{%
\begin{mathpar}
\inferrule[B-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\\\ \bindsv{p}{A}{w}{\venv}}
  {\bindsc{p}{\effin{\adj}A}{w}{\sigs}{\venv}}

  \inferrule[B-Request]
    {%I~\many{R} \in \ext \\ %\capturesI{\Delta}{I}{\iota}\\
    \adjact{\sigs}{\adj}{\sigs'} \\
    \EC \poised c \\\\
    \adj = \adapt\pipe\ext \\
    c : \forall \many{Z}. \many{B \to}~B' \in \ext \\
    (\bindsv{p_i}{B_i}{w_i}{\venv_i})_i}
    {\bindsc{\effin{c~\many{p} \to z}}{\effin{\adj}A}
    {\freeze{\EC[c~\many{R}~\many{w}]}}{\sigs}{\many{\venv}[\cu (\thunk{x \mapsto \EC[x]} : \thunk{B' \to \effout{\sigs'}A})/z]}}
\\
\inferrule[B-CatchAll-Value]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{w}{\sigs}{[\cu (\thunk{w}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\\
\inferrule[B-CatchAll-Request]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  \EC \poised c \\\\
  \adj = \adapt\pipe\ext \\
  c : \forall \many{Z}. \many{B \to}~B' \in \ext
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}

\end{mathpar}

}

\flushleft
%~~ \textit{Value pattern $p$ for type $A$ matches $w$ and binds $\venv$.}
%
\scalebox{\figscale}{%
  $\boxed{\bindsv{p}{A}{w}{\venv}}$
  }

\centering
\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[B-Var]
  { }
  {\bindsv{x}{A}{w}{[\cu (w : A)/x]}}

\inferrule[B-Data]
  {k~\many{A} \in D~\many{R} \\
   (\bindsv{p_i}{A_i}{w_i}{\venv_i})_i}
  {\bindsv{k~\many{p}}{D~\many{R}}{k~\many{w}}{\many{\venv}}}
\end{mathpar}
  }

\caption{Pattern Binding}
\label{fig:pattern-binding}
%% \figrule
\end{figure}



\chapter{Pre-emptive Concurrency}
\label{chap:preemptive-concurrency}

\section{Motivation}
\label{sec:interrupt-motivation}

Our schedulers in Section~\ref{sec:concurrency} rely on threads manually
\yield{}ing. This co-operative concurrency can be problematic as it leaves the
responsibility of inserting \yield{} commands to the programmer, who may leave
them out or not disperse frequently enough. Even worse, the thread could get
into some inescapable state without every \yield{}ing, starving other threads of
processor time. It would be simpler, fairer and safer to just use some automatic
way of \yield{}ing, thus taking the responsibility away from the programmer. We express threads that automatically have \yield~commands inserted as \emph{pre-emptible} threads; we describe concurrency using pre-emptible threads as \emph{pre-emptive concurrency}.

% This is fine for simple examples, but when working with more
% complex programs this is inconvenient; the programmer must insert \yield{}s with
% a consistent frequency, so as to avoid process starvation. Furthermore, if we
% use external or library functions these will not hold yields, so will be
% uninterruptible. It would be simpler and fairer to just use some automatic way
% of \yield{}ing.

% \todo{Do we need to explicitly say THIS IS PRE EMPTIVE CONCURRENCY?}

%% One important part of our asynchronous effect handling system is the ability to
%% interrupt arbitrary computations. If two threads are running concurrently and
%% are communicating with one another, we have to stop running one to let messages
%% come in from the other. This is achievable with explicitly yielding, as in
%% Section~\ref{sec:concurrency}, however we would prefer for this behaviour to be
%% done automatically.

Consider the two programs below:

\begin{lstlisting}
interface Stop = stop : Unit
interface Go = go : Unit

controller : {[Stop, Go, Console] Unit}
controller! = stop!; print "stop!" ; sleep 200000; go!; controller!

runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)
\end{lstlisting}

%% \noindent We ideally want a multihandler that can run these two programs in
%% parallel, such that the console output will be \code{1 stop 2 stop 3 stop}; that
%% is to say, the \code{stop} and \code{go} operations from \code{controller} can
%% control the execution of \code{runner}.

\noindent We want a multihandler that uses the \code{stop} and \code{go}
commands from \code{controller} to control the execution of \code{runner}. The
desired console output is \code{1 2 3 ... n stop! (n + 1) ...}, running
infinitely. The problem as it stands is that there is no way for \code{runner}
to be suspended whilst it is running; it will just infinitely run, never
reducing to a value and thus never giving control to the handler or to
\code{controller}.

% There
% are several possible interleavings of

% The console output
% of this multihandler should be then \code{1 stop 2 stop 3 stop}.
%
%We need
%% pre-emptive interruptions for this, as otherwise there would be no way for the
%% \code{stop} and \code{go} messages to be registered.

%% \section{Interruption with Yields}
%% \label{sec:yield-interruption}

%% One way we can get this behaviour is using the \code{Yield} interface. This
%% offers a single operation, \code{yield : Unit}. With this, we can write a
%% multihandler \code{suspend};

% We can simulate this behaviour by using the familiar \code{Yield} interface from
% Section~\ref{subsec:simple-scheduling}.

As an example, we show how we can approximate the desired behaviour using the familiar \code{Yield} interface from Section~\ref{subsec:simple-scheduling}.

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; yield!: runner (x + 1)

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

% \noindent Running \code{suspend runner! controller! nothing} then prints out
% \code{1 stop 2 stop 3} as desired.
\noindent Running \code{suspend (runner 0) controller! nothing} then prints out
\code{1 stop 2 stop 3 stop ...}.
%
This is due to the same synchronisation behaviour that we saw in
Section~\ref{subsec:simple-scheduling}; \code{runner} is evaluated until it
becomes a command or a value, and then \code{controller} is given the same
treatment. Once both are a command or a value, pattern matching is done.

% In this way we use \yield~commands to split up our computations and let
% processing time be given to other computations. The closest handler for
% \yield~operations then gets access to the continuation of \code{runner} and can
% choose how to handle it.

We are, however, still operating co-operatively; the programmer has to manually
insert \yield~commands. Furthermore, in this case we \yield~far too often; it would be more efficient to have a consistent, yet longer, period in between each \yield~command.
%
As such, we continue searching for a better solution.

\section{Relaxing Catches}
\label{sec:relaxing-catches}

One approach is to relax the rules for pattern matching with the catchall
pattern $\effin{x}$. Currently the catchall pattern only matches commands that
the handler would otherwise handle; we propose relaxing the rules to match
\emph{any} command, that may not be handled by the current handler. The key to
implementing this lies in the pattern binding rules of
Figure~\ref{fig:pattern-binding}; specifically \textsc{B-CatchAll-Request}.

%% The key to this lies in the catchall pattern, $\effin{x}$, and the pattern
%% binding rules of Figure~\ref{fig:pattern-binding}; specifically
%% \textsc{B-CatchAll-Request}. %We quickly go into detail on this rule now.
%
%% $\effin{x} : {\effin{\adj}A}$ states that $\effin{x}$ is a term with value type
%% $A$ and \emph{adjustment} $\adj = \adapt\pipe\ext$, made up of an adaptor
%% $\adapt$ and an extension $\ext$. This extension is made up of a list of
%% interface instantiations $\sig~\many{R}$.

The crux is that the command $c$ that is invoked in the frozen term
$\freeze{\EC[c~\many{R}~\many{w}]}$ must be a command offered by the extension
$\ext$; that is, it must be handled by the current use of \textsc{R-Handle}.
Refer back to the example of Section~\ref{sec:interrupt-motivation}. This
rule means that the catch-all pattern \code{<_>} in the final pattern matching
case of \code{suspend} can match against \code{stop} or \code{go}, as they are
present in the extension of the second argument, but not \code{print} commands;
although the \code{Console} interface is present in the ability of
\code{controller}, it is not in the extension in \code{suspend}.



\begin{figure}[h]
%% \figrule
%% \flushleft
%% \centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\scalebox{\figscale}{%
\begin{mathpar}
%% \\

\inferrule[B-CatchAll-Request-Loose]
  {
  \adjact{\sigs}{\adj}{\sigs'} \\
  \xcancel{\EC \poised c} \\
  \xcancel{\adj = \adapt\pipe\ext} \\
  \xcancel{c : \forall \many{Z}. \many{B \to}~B' \in \ext}
  }
  {\bindsc{\effin{x}}{\effin{\adj}A}
  {\freeze{\EC[c~\many{R}~\many{w}]}}
  {\sigs}
  {[\cu (\thunk{\freeze{\EC[c~\many{R}~\many{w}]}}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}
\caption{Updated \textsc{B-CatchAll-Request}}
\label{fig:loose-catchall-request}
%% \figrule
\end{figure}

In the interests of pre-emption, we propose to remove this constraint from
\textsc{B-CatchAll-Request}, replacing the rule with
\textsc{B-CatchAll-Request-Loose} as seen in
Figure~\ref{fig:loose-catchall-request}. The key constraint that has been
removed is $c : \forall \many{Z}. \many{B \to}~B' \in \ext$, which requires that
the frozen command must be present in the argument extension $\ext$. The
constraint $\EC \poised c$ just states that the evaluation context containing
the frozen command will handle $c$; we also do away with this, as we do not
necessarily want to handle the command here. This lets us change \code{runner}
back to its original form, and update \code{suspend} like so:

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)

suspend : {Unit -> <Stop, Go> Unit
    -> Maybe {[Console] Unit} -> [Console] Unit}
suspend <r> <stop -> c> _ =
    suspend unit (c unit) (just r)
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend unit         <_>         _ = unit
\end{lstlisting}

\noindent Now when we run \code{suspend (runner 0) controller! nothing}, the
\code{suspend} handler can match the catchall pattern \code{<r>} against the
\code{print} commands in \code{runner}. This prints out \code{1 stop! 2 stop! 3
  stop! ...} as before.

% The no-snooping policy with respect to effect handlers (\cite{convent2020doo})
% states that a handler should not be able to intercept effects that it does not
% handle. This change breaks this policy, as we can now tell when an command is
% used. Whilst we can not handle it as per usual, we get the option to throw away
% the continuation. A system that does not allow for snooping is much preferred.

% \todo{Either flesh this out or remove it}

\section{Freezing Arbitrary Terms}
\label{sec:freezing-terms}

The approach of Section~\ref{sec:relaxing-catches} can only interrupt command
invocations. If \code{runner} were instead a sequence of pure computations ---
such as \code{1 + 1; 1 + 1; 1 + 1} --- we would be unable to interrupt it.

As such, we make a more significant change to the semantics of Frank. We adapt
the syntax so that \emph{any} term may become frozen, and not just commands;
this is reflected in Figure~\ref{fig:runtime-syntax-freeze}. In
Figure~\ref{fig:freezing} we see additional rules for freezing arbitrary
\emph{uses} and the surrounding computations. We can freeze arbitrary
\emph{constructions} in an identical fashion, substituting $m$ for $n$. These
rules rely on an extra predicate $\EF \textsf{ not handler }$, which is true
unless $\EF$ is of the form $u~(\many{t}, [~], \many{n})$. Frozen terms behave
very much like frozen commands, freezing the entire computation up to the
nearest handler. Finally, we supplement the pattern binding rules with the rule
in Figure~\ref{fig:catchall-freeze}, which shows how a computation becomes
unfrozen. A frozen computation $\freeze{m}$ can match against the catchall
pattern $\effin{x}$; the suspended, thawed computation $\thunk{m}$ is then bound
to $x$ in the continuation.


\begin{figure}[t]
%% \figrule
\centering
\scalebox{\figscale}{%
\begin{syntax}
\slab{uses}                    & m   &::= & {\dots} \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{constructions}           & n   &::= & \dots \gor
\freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}} \\
\slab{use values}              & u   &::= & x \gor f~\many{R} \gor \cu (v : A) \\
\slab{non-use values}          & v   &::= & k~\many{w} \gor \thunk{e} \\
\slab{construction values}     & w   &::= & \uc u \gor v \\
\slab{normal forms}            & t   &::= & w \gor \freeze{\EC[c~\many{R}~\many{w}]} \gor \highlight{\freeze{m}}\\
\slab{evaluation frames}       & \EF &::= & [~]~\many{n}
                                      \gor  u~(\many{t},[~],\many{n})
                                      \gor  \cu([~]:A) \\
                               &     &\gor& \uc [~]
                                      \gor  k~(\many{w},[~],\many{n})
                                      \gor  c~\many{R}~(\many{w},[~],\many{n}) \\
                               &     &\gor& \key{let}~f: P = [~]~\key{in}~n
                                      \gor \effin{\adapt}~[~] \\
\slab{evaluation contexts}     & \EC &::= & [~] \gor \EF[\EC] \\
\end{syntax}
}

\caption{Runtime Syntax, Updated with Freezing of Uses}
\label{fig:runtime-syntax-freeze}
%% \figrule
\end{figure}


\begin{figure}[t]
%% \figrule
% \scalebox{\figscale}{%
% \flushleft
% $\boxed{m \redtou m'} \quad \boxed{n \redtoc n'}$
% }

\scalebox{\figscale}{%
\centering
\begin{mathpar}

\inferrule[R-Freeze-Use]
  {  }
  { m \redtou \freeze{m} }

\inferrule[R-Freeze-Frame-Use]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtou \freeze{\EF[\EC[m]]} }

\inferrule[R-Freeze-Frame-Cons]
  { \EF \textsf{ not handler }}
  { \EF[\EC[\freeze{m}]] \redtoc \freeze{\EF[\EC[m]]} }

\end{mathpar}
}

\caption{Freezing Uses}
\label{fig:freezing}
%% \figrule
\end{figure}

\begin{figure}[t]
%% \figrule
\flushleft

\scalebox{\figscale}{%
\centering
%\textit{Comp. pattern $r$ for $\langle \Delta \rangle A$ matches $u$ under
%amb. $\venv$ and binds $\venv$.}
\begin{mathpar}

\inferrule[B-CatchAll-Freeze-Use]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\bindsc{\effin{x}}{\effin{\adj}A}{\freeze{m}}{\sigs}{[\cu (\thunk{m}\mathord{:}\thunk{\effout{\sigs'}A})/x]}}
\end{mathpar}
}

\caption{Thawing Computations.}
\label{fig:catchall-freeze}
%% \figrule
\end{figure}

% Note that frozen terms here behave in a similar way to frozen commands, by
% freezing the rest of the term around it as well. This continues up until a
% handler is reached, at which point the term is unfrozen and resumed. This
% process of freezing up to a handler is enforced by the predicate $\EF \textsf{
%   not handler }$, which is true only when $\EF$ is of the form $u~(\many{t},
% [~], \many{n})$.

% With this in mind, we now give the updated rule for the catchall pattern
% matching on frozen terms. This can be seen in Figure \ref{fig:catchall-freeze}.
% It expresses that an arbitrary frozen term can be matched against the
% computation pattern $\effin{x}$. The suspended, unfrozen computation $\thunk{m}$
% is then bound to $x$, in a similar way to other \textsc{B-CatchAll} rules.
% Observe that this maintains no-snooping; we don't know that the frozen
% computation performed an effect.



%% \begin{lstlisting}
%% suspend : {Unit -> <Stop, Go> Unit -> Maybe {[Console] Unit} -> [Console] Unit}
%% suspend <r> <stop -> c> _ =
%%     suspend unit (c unit) (just r)
%% suspend <_>          <go -> c>   (just res) =
%%     suspend res! (c unit) nothing
%% suspend unit         <_>         _ = unit
%% \end{lstlisting}

We can simply reuse the \code{suspend} handler from
Section~\ref{sec:relaxing-catches}. Everything works largely the same; we run
the leftmost argument until it freezes, invokes a command or is a value, at
which point we start evaluating the next argument. The frozen term can then be
bound to the catch-all pattern, if this is the pattern that matches.

However, observe that the frozen term is automatically rehandled at the closest
handler. This is problematic; we might have a handler for another effect, such
as \code{runState}, before the \code{suspend} handler. In this case,
\code{runState} would automatically resume \code{runner} when it freezes; we
would still have the same problem of starvation, as control would never rise to
\code{suspend}. This problem would be solved if we had finer-grained control
over when to resume a frozen computation, so we could choose to resume the
frozen computation at \code{suspend} and not at \code{runState}.

% \todo{Rewrite above paragraph}

\section{Yielding}
\label{sec:inserting-yields}

Observe that the freezing approach of Section~\ref{sec:freezing-terms} ends up
reimplementing a lot of the behaviour of the freezing of ordinary commands,
without adding much new behaviour. Furthermore, the term gets automatically
unfrozen at the closest handler, severely limiting control over computations. It
turns out that we can get the exact same behaviour by just inserting a command
invocation into the term instead, and handling this as normal.
%

Once again, the simple \Yield interface from Section~\ref{sec:concurrency} can
be used here. Whilst the interface itself sounds very boring, its use here comes
from the fact it freezes the rest of the computation around it up until the next
\Yield~handler. Our new system is simple; whenever a term reduces underneath a
handler for \Yield effects, we insert an invocation of the \yield command before
the reduct. This is expressed formally in Figure~\ref{fig:insert-yield}. We
refer to \purefrank~as described in Chapter~\ref{chap:formalisation}
supplemented with this rule as \nondetfrank.

% \todo{Add rules for eval ctxs converting use to const, use to use, etc}

\begin{figure}[h]
%% \figrule
% \scalebox{\figscale}{%
% \flushleft
% $\boxed{n \redtou n'} $
% }

\scalebox{\figscale}{%
\begin{mathpar}
%

\inferrule[R-Yield]
{ n \redtoc n' \\
  \EF~\textsf{allows}~\yield }
          { \EF[n] \redtou \EF[\textsf{yield}!; n] }
\end{mathpar}
}
%
%
\caption{Inserting Yields}
\label{fig:insert-yield}
%% \figrule
\end{figure}

Note that \textsc{R-Yield-EF} relies on the predicate $\EF~\allows~c$. For any
frame apart from argument frames (i.e. $u~(\many{t}, [~], \many{n})$),
$\EF~\allows~c = \textsf{false}$. In this case, it is defined as follows;

\begin{align*}
  \cu (v : \thunk{\many{\effin{\adj} A
      \to}~\effout{\sigs}B})~(\many{t},[~],\many{n})~\allows~c =
  &~\ext_{|\many{t}|}~\allows~c ~ \\
  & \text{where}~\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|} \\
  % \_\_\_~(\many{t}, [~], \many{n}) \allows c =& \textsf{false}
  \underline{\hspace{3cm}}~(\many{t}, [~], \many{n})~\allows~c =& \textsf{false}
  %\adjact{\sigs}{\adj_{|\many{t}|}}{\sigs'}
\end{align*}

%% \noindent For an ability $\sigs = \seed\pipe\ext$, the predicate $\sigs~ \allows~c$ is true if
%% $c \in I$ for some $I \in \ext$.

\noindent For an extension $\ext$, the predicate $\ext~\allows~c$ is true if $c
\in I$ for some $I \in \ext$.

Informally, $\EF~\allows~c$ is true when $\EF$ is a handler, and the extension at
the hole contains an interface which offers \yield~as a command. For instance,
if a handler had type \code{\{<Yield>X -> Y -> [Yield]X\}}, the first argument
would be allowed to yield but the second would not.

We also make use of an auxiliary combinator $\_ ; \_$. This is the traditional
sequential composition operator $\textsf{snd}~x~y~\mapsto~y$, where both
arguments are evaluated and the result of the second one is returned. In the
context of \textsc{R-Yield-EF} this means we will perform the \yield~operation
and then the use $m$, but discard the result from \yield.

Observe that this gives us fine-grained control over which parts of our program
are pre-emptible.
% One might want a short-running function to not be pre-emptible
% and just run without pause; conversely, one might want a long-running function
% to be interruptible.
The programmer can simply insert \Yield~into the adjustment of the multihandler
arguments which should be pre-emptible. This is one improvement over the system
of Section~\ref{sec:freezing-terms}; previously every thread was interruptible.
Another benefit is that we define fewer new rules and constructs. We also
benefit from the choice of when to resume a computation; in the previous system
computations were automatically unfrozen at the nearest handler, but this
problem is fixed in \nondetfrank. Finally, we can write custom handlers for
\yield~commands, whilst the unfreezing rules in Figure~\ref{fig:catchall-freeze}
was fixed at just restarting the continuation.

%% \todo{Talk about how this differs to the Freezing system}.

\paragraph*{Nondeterminism}

This system, and the system from Section~\ref{sec:freezing-terms}, are both
nondeterministic. This is because at any point we have the opportunity to either
invoke yield (respectively freeze the term), or continue as before.

Consider running \code{hdl (print "A") (print "B")}, for some binary
multihandler \code{hdl}. We could evaluate
\code{print "A"} first and then \code{print "B"}, or freeze \code{print "A"} and
evaluate \code{print "B"} first. Both of these would obviously result in
different things being printed to the console.

\section{Counting}
\label{sec:counting}


%% The semantics given by Section~\ref{sec:inserting-yields} is fine, but is
%% non-deterministic; at any point, we can choose to either insert a \yield
%% invocation or carry on as normal. Furthermore, we do not particularly need to
%% yield very frequently; we might rather yield every 1000 reduction steps or so.

The system described in Section~\ref{sec:inserting-yields} is slightly
problematic; we can insert a \yield whenever we want. If we spend too much time
inserting and handling \yield commands little other computation will be done.
Furthermore, it is non-deterministic; we often have the choice of either
\yield{}ing or reducing as normal. We need a way to decide whether or not to
\yield.

% \todo{It's not problematic; it's just not practical}

To combat this we supplement the operational semantics with a counter
$\counter$. This counter has two states; it could either be counting up, which
is the form $\justc{n}$ for some $n$, or a signal to yield as soon as possible,
which is the form $\yieldc$. To increment this counter, we use a slightly
modified version of addition, denoted $\plusc$. This is simply defined as:

\begin{equations}
  x \plusc y =
          \left\{ \ba{@{}l@{\quad}l@{}}
              \justc{x + y} & \text{if } x + y \leq \threshc \\
              \yieldc & \text{otherwise}
          \right.
        \end{equations}

\noindent where $\threshc$ is the threshold at which we force a yield.

The transitions in our operational semantics now are of the form
$m; \counter \redtou m'; \counter \bluetext{'}$. In
Figure~\ref{fig:counting-rules} we give an updated rule for \textsc{R-Handle}
--- overwriting the previous rule --- and two new rules for inserting yields. We
refer to \purefrank~extended with the rules in Figure~\ref{fig:counting-rules} as
\countingfrank.

\begin{figure}
%% \figrule
% \scalebox{\figscale}{%
% \flushleft
% $\boxed{m \redtou m'} \quad \boxed{n \redtoc n'} \quad \boxed{m
%     \stepstou m'} \quad \boxed{n \stepstoc n'}$
% }

\scalebox{\figscale}{%
\begin{mathpar}

\inferrule[R-Handle-Count]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~\many{t}; \justc{n}~
    \redtou~
    \cu ((\many{\venv}(n_k) : B)); \bluetext{n \plusc 1}}

\\
\inferrule[R-Yield-Can]
          { \EF~\textsf{allows}~\yield }
          { \EF[m]; \yieldc~\redtou~\EF[\textsf{yield!}; m]; \justc{0} }
\\
\inferrule[R-Yield-Can't]
          { \neg (\EF~\textsf{allows}~\yield) \\
            m; \justc{n} \redtou m'; \bluetext{c'} }
          { \EF[m]; \yieldc~\redtou~\EF[m']; \yieldc }
% \\
% \inferrule[R-Yield-Can't-UC]
%           { \neg (\EF~\textsf{allows}~\yield) \\
%             m; \justc{n} \redtou m'; \bluetext{c'} }
%           { \EF[m]; \yieldc~\redtoc~\EF[m']; \yieldc }
% \\
% \inferrule[R-Yield-Can't-CC]
%           { \neg (\EF~\textsf{allows}~\yield) \\
%             n; \justc{n} \redtoc n'; \bluetext{c'} }
%           { \EF[n]; \yieldc~\redtoc~\EF[n']; \yieldc }
% \\
% \inferrule[R-Yield-Can't-CU]
%           { \neg (\EF~\textsf{allows}~\yield) \\
%             n; \justc{n} \redtoc n'; \bluetext{c'} }
%           { \EF[n]; \yieldc~\redtou~\EF[n']; \yieldc }
\end{mathpar}
}

\caption{Yielding with Counting}
\label{fig:counting-rules}
%% \figrule
\end{figure}

\textsc{R-Handle-Count} replaces the previous rule \textsc{R-Handle}. If the
counter is in the state $\justc{n}$, we perform the handling as usual,
incrementing the counter by 1. Here we use $\plusc$, which will set the counter
to be $\yieldc$ if increasing the counter brings it over the threshold value.

\textsc{R-Yield-Can} and \textsc{R-Yield-Can't} dictate what to do if the
counter is in the \yieldc~state. If the evaluation context allows \yield{}
commands to be inserted we do so and reset the counter. If not, but the term
could otherwise reduce if the counter were of the form \justc{k}, then we make
that transition, still maintaining the $\yieldc$ signal.

Note that we have a family of 4 \textsc{R-Yield-Can't} rules, for each pair of
use or construction inside the evaluation context, which can be a use or a
construction, in a similar way to the \textsc{R-Lift} rules in
Chapter~\ref{chap:formalisation}. We omit these for brevity.

All of the other rules from Figure~\ref{fig:operational-semantics} are then
implicitly converted to $m; \counter \redtou m'; \counter$ or
$n; \counter \redtoc n'; \counter$; they may reduce at any point
regardless of the state of the counter, but they do \emph{not} change the value
of the counter.

\citeauthor{dolan2017concurrent} take a similar approach to this when
investigating asynchrony in Multicore OCaml (\cite{dolan2017concurrent}). They
rely on the operating system to provide a timer interrupt, which is handled as a
first-class effect. Our system is more self-contained; the timing is implemented
within the language itself and doesn't rely on the operating system providing
interrupts. Furthermore, we get control over when the timer can fire, as we can
choose to put \Yield~in the ability of interruptible terms.

\paragraph*{Determinism}
Observe that the semantics of Frank equipped with the rules in
Figure~\ref{fig:counting-rules} are now deterministic; for any term and counter
pair, there is only one possible reduction we can make. This is helpful for the
sake of implementation; it is always clear which reduction to make at any point.
We can characterise this by saying that \countingfrank~\emph{implements}~
\nondetfrank; the counting system gives a deterministic way to implement the
nondeterministic system. We have implemented the counting behaviour of
\countingfrank~into the Frank interpreter.

\begin{theorem}[\countingfrank~Implements \nondetfrank.]~
%% \begin{restatable}[Counting Implements Nondeterminsim]{theorem}{countimplynondet}\label{thm:count-impl-nondet}
\begin{itemize}
\item For any use $m$ and counter $\counter$, if $m, \counter~\redtou~
  m',\counter'$ in \countingfrank~ then $m~\redtou~m'$ in \nondetfrank.
\item For any construction $n$ and counter $\counter$, if $n, \counter~\redtou~
  n',\counter'$ in \countingfrank~ then $n~\redtou~n'$ in \nondetfrank.
\end{itemize}
%% \end{restatable}
\end{theorem}
\begin{proof}
  If we simply ignore the counters it's clear that any time we insert a \yield~command in \countingfrank, it is valid to also do so on \nondetfrank.
  \end{proof}

% One might consider a different approach, rather than a global counter, which
% would also implement the nondeterministic semantics.

In Section~\ref{sec:starvation} we see a different approach, rather than a
global counter, which also implements the nondeterministic semantics.

\section{Handling}
\label{sec:handling}

Observe that we can now use the same \code{suspend} handler from
Section~\ref{sec:interrupt-motivation}, without having to manually insert
\yield~commands in \code{runner}. The following code will then give the desired
output, of a series of numbers printing interspersed evenly with \code{stop!};

\begin{lstlisting}
runner : {Int -> [Console] Unit}
runner x = printInt x; runner (x + 1)

suspend : {<Yield> Unit -> <Stop, Go> Unit
  -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
suspend <yield -> r> <stop -> c> _ =
    suspend unit (c unit) (just {r unit})
suspend <_>          <go -> c>   (just res) =
    suspend res! (c unit) nothing
suspend <yield -> r> <c>           = suspend (r unit) c!
suspend unit         <_>         _ = unit
\end{lstlisting}

The first argument is evaluated until the counter is greater than the threshold,
at which point a yield command is performed; the rest of the computation is then
frozen and the second argument is evaluated. Observe that the \Yield~interface
is not present in the adjustment of the second argument, so it is left to run
as normal.

We might also want to make the controller --- being the second argument ---
preemptible; it might do some other computation in between performing
\code{stop} and \code{go} operations. We have to add \Yield~to the adjustment at
the second argument, but also add more pattern matching cases.

\begin{lstlisting}[]
suspend <yield -> r> <yield -> c> p = suspend (r unit) (c unit) p
suspend <yield -> r> <c>          p = suspend (r unit) c! p
suspend <r>          <yield -> c> p = suspend r! (c unit) p
suspend <r>          <c>          p = suspend r! c! p
\end{lstlisting}
%



% \begin{lstlisting}[]
% suspend : {<Yield> Unit -> <Stop, Go, <@\texthighlight{Yield}@>> Unit
%   -> Maybe {[Console, Yield] Unit} -> [Console] Unit}
% suspend <yield -> r> <stop -> c> _ =
%     suspend unit (c unit) (just {r unit})
% suspend <_>          <go -> c>   (just res) =
%     suspend res! (c unit) nothing
% suspend unit         <_>         _ = unit
% <@\texthighlight{
% suspend <yield -> r> <yield -> c> p = suspend (r unit) (c unit) p
% }@>
% <@\texthighlight{
% suspend <yield -> r> <c>          p = suspend (r unit) c! p
% }@>
% <@\texthighlight{
% suspend <r>          <yield -> c> p = suspend r! (c unit) p
% }@>
% \end{lstlisting}

These let \yield~commands synchronise with each other, achieving fair
scheduling, as discussed in Section~\ref{sec:concurrency}. It is annoying to
write these by hand, as they take up a lot of space and are orthogonal to the
rest of the logic of the handler.

Fortunately, this process of resuming as many yields as possible can be
automated completely. Given a multihandler with $m$ arguments, $n$ of which have
\Yield~in their adjustment, we first try to resume and rehandle all $n$
\yield~commands. After this we try to resume all of the different permutations
of $n-1$ \yield~commands, and so on until we are trying to resume 0
\yield~commands.
%
%The resuming clauses for the 3-ary case can be seen below.

%% \begin{lstlisting}
%% sch3 : {<Yield> Unit -> <Yield> Unit -> <Yield> Unit -> Unit}
%% sch3 <yield -> h> <yield -> j> <yield -> k> =
%%     sch3 (h unit) (j unit) (k unit)

%% sch3 <yield -> h> <yield -> j> <k> = sch3 (h unit) (j unit) k!
%% sch3 <yield -> h> <j> <yield -> k> = sch3 (h unit) j! (k unit)
%% sch3 <h> <yield -> j> <yield -> k> = sch3 h! (j unit) (k unit)

%% sch3 <yield -> h> <j> <k> = sch3 (h unit) j! k!
%% sch3 <h> <yield -> j> <k> = sch3 h! (j unit) k!
%% sch3 <h> <j> <yield -> k> = sch3 h! j! (k unit)
%% \end{lstlisting}

These commands can be inserted generically at runtime. If no other hand-written
patterns match, we insert these patterns and try all of them. It is important to
insert the automatically resuming patterns \emph{after} the rest of the
patterns, as the multihandler may want to handle \yield~commands some other way;
we do not want to interfere with this. This means we can program in a simpler,
direct manner, easily toggling which arguments should be interruptible by adding
\Yield~to the corresponding interface. Automatically inserting \yield-handling
clauses when combined with automatically \emph{inserting} \yield~commands then
gives us pre-emptive concurrency at very little overhead.

\section{Starvation}
\label{sec:starvation}

Consider the following program;

\begin{lstlisting}
  echo : {String -> [Console, Yield] Unit}
  echo st = print st; echo st

  sched : {<Yield> Unit -> <Yield> Unit -> Unit}
  sched unit unit = unit

  tree : {[Console] Unit}
  tree! = sched (echo "A ")
                (sched (echo "B ") (echo "C "))
\end{lstlisting}

We would like \code{tree!} to print out \code{"A B C A B C A B C ..."}. However,
when using \countingfrank~with automatic insertion of \yield~commands, the
result is \code{"A B C B C B C ..."}. The \code{echo "A "} thread is
\emph{starved} of processor time. This happens because when \code{echo "B "}
yields the command is immediately handled by the lower \code{sched} handler and
\code{echo "C "} is ran (and vice versa).

What we need is for each multihandler to have its own counter, which is
incremented every time an argument to the multihandler reduces. When an argument
to a multihandler reduces when the counter is over the threshold, we insert a
\yield command in front of the reduct.

% With respect to \code{tree}, in this system \code{echo "A "} will reduce,
% increasing the counter at the upper \code{sched}uler until the counter passes
% over the threshold, at which point a \yield is inserted in front of \code{echo
%   "A "}. We now switch to the other branch, \code{sched (echo "B ") (echo "C
%   ")}. When \code{echo "B "} reduces, we increment a counter at both
% \code{sched} handlers. Both counters then pass \threshc~at the same time, at
% which point we insert a \yield~in front of \code{echo "B "} to be handled by the
% lower scheduler. A similar thing happens to \code{echo "C "}.

% \todo{Finish this!}

\begin{figure}
\centering
\scalebox{\figscale}{%

\begin{mathpar}

\inferrule[R-Handle-GC]
  {% The type system should enforce this!
   %(\handles{\adj_j}{t_j})_j \\
   k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
   (\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}}
   %% \forall i < k.\exists j.r_{i, j} \# t_j}
   %% l \text{~is minimal}}
  {\cu (\thunk{((r_{i,j})_j \to n_i)_i} \bluetext{@ c} : \thunk{\many{\effin{\adj} A \to}~\effout{\sigs}B})~\many{t} \redtou \cu ((\many{\venv}(n_k) : B)}
 
\\
\inferrule[Arg-Increment]
  { %k = \min_i\,\{i \mid \exists \many{\venv}.(\bindsc{r_{i,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j}\} \\
    %(\bindsc{r_{k,j}}{\effin{\adj_j} A_j}{t_j}{\sigs}{\venv_j})_{j} \\
    % \exists i. \adj_i = \adapt_i\pipe\ext_i \
    %\highlight{\exists i. \Yield \in \ext_i \text{ for } \adj_i = \adapt_i\pipe\ext_i  }
    % \forall~j\leq~n~.~\bluetext{c_j} \not = \yieldc
    n \redtoc n'
  }
  { \cu (\thunk{((r_{i,j})_j \to n_i)_i}  {\bluetext{@ c}} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~(\many{t}, n, \many{n})
    \redtou \\
     \cu (\thunk{((r_{i,j})_j \to n_i)_i } {\bluetext{@} (\textsf{incOrReset}(\bluetext{c}, \adj_{|\many{t}|}))} : \thunk{\many{\effin{\adj} A
        \to}~\effout{\sigs}B})~(\many{t}, {\textsf{maybeYield}(n', \bluetext{c}, \adj_{|\many{t}|})}, \many{n})
       }
  \\
\end{mathpar}
}
\caption{Updated Counting Rules}
\label{fig:tree-counting}
\end{figure}

This system is expressed formally in Figure~\ref{fig:tree-counting}. Every
handler --- just being a collection of pattern matching rules
$\thunk{((r_{i,j})_j \to n_i)_i}$ --- is implicitly given a counter \counter~
initialised at $\justc{0}$. The first rule, \textsc{R-Handle-GC}\footnote{Where
  \textsc{GC} stands for Garbage Collector.}, expresses that counters are
removed when a handler is evaluated on fully-evaluated arguments. The second
rule, \textsc{Arg-Increment}, expresses that when an argument to a multihandler
evaluates, we increment the counter; if the counter is above the yielding
threshold we insert a yield command before the argument and reset the counter.
\textsc{Arg-Increment} relies on two auxilary functions, defined as;

% \[
%   \scalemath{\figscale}{%
\begin{equations}
  \textsf{incOrReset} (\counter, \adj = \adapt\pipe\ext) =
          \left\{ \ba{@{}l@{\quad}l@{}}
               \counter & \text{if } \Yield \not \in \ext \\
               \succc{\counter} & \text{if } \Yield \in \ext \text{ and } \counter \not = \yieldc \\
               \justc{0} & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc
              % \justc{x + y} & \text{if } x + y \leq \threshc \\
              % \yieldc & \text{otherwise}
             \right.
           \end{equations}
           % }
           % \]

\begin{equations}
  \textsf{maybeYield} (n, \counter, \adj = \adapt\pipe\ext) =
          \left\{ \ba{@{}l@{\quad}l@{}}
            \yield!; n & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc \\
            n & \text{otherwise}

               % \counter & \text{if } \Yield \not \in \ext \\
               % \succc{\counter} & \text{if } \Yield \in \ext \text{ and } \counter \not = \yieldc \\
               % \justc{0} & \text{if } \Yield \in \ext \text{ and } \counter = \yieldc
          \right.
\end{equations}

% We denote this system, being the basic system described in
% Chapter~\ref{chap:formalisation} equipped with the rules in
% Figure~\ref{fig:tree-counting}, as \treefrank.

We denote this system of \purefrank~equipped with the rules in
Figure~\ref{fig:tree-counting} as \treefrank.

\begin{theorem}[\treefrank~Implements \nondetfrank.]~
\begin{itemize}
\item For any use $m$ if $m~\redtou~m'$ in \treefrank~then $m~\redtou~m'$ in
  \nondetfrank.
\item For any construction $n$, if $n~\redtou~n'$ in \treefrank~then
  $n~\redtou~n'$ in \nondetfrank.
\end{itemize}
\end{theorem}
\begin{proof}
  We can see that this holds by just erasing the counters from the
  multihandlers; all transitions would be permitted in \nondetfrank.
\end{proof}

We walk through an example evaluation of \code{tree} in \treefrank. First,
\code{echo "A "} reduces, increasing the counter at the upper \code{sched}
handler. Once this counter passes the threshold, we insert a \yield~before
\code{echo "A "}; we now start evaluating the other branch, \code{sched (echo "B
  ") (echo "C ")}. While \code{echo "B "} reduces we increment the counter at
both \code{sched} handlers. Both counters then pass the threshold at the same
time. At this point the system can either choose to insert a \yield~at either of
the two \code{sched} handlers; let's consider it chooses to insert one at the
upper handler. Then \code{echo "A "} is evaluated again as before. Once we
resume computing \code{sched (echo "B ") (echo "C ")} the counter state is
\emph{maintained}, so we immediately \yield, give control to \code{echo "C "}
and continue.

In our implementation of \treefrank, we avoid the nondeterminism caused by
multiple multihandler trying to \yield~by always choosing the lowest multihandler.

This system does not let threads starve; eventually, any thread gets processor
time. However, if we have a lot of deeply-nested handlers, a thread might have
to wait a long time to get processor time. It would be good to have a system
where we can express a bound on the amount of time that will pass before a
thread gets processor time; this remains as future work.

\section{Soundness}

% We now state the soundness property for our extended system, as well as the
% subject reduction theorem needed for this proof. Our system is nothing more than
% the system of~\citeauthor{convent2020doo} with extra rules; as such we omit most of
% the details.

We now state the soundness properties for our systems, as well as the subject
reduction theorem needed for each soundness proof.

\begin{theorem}[Subject Reduction for \nondetfrank]~
  \label{thm:sub-red}
\begin{itemize}
\item If $\inferskgs{m}{A}$ and $m \redtou m'$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n \redtoc n'$ then $\checkskgs{A}{n'}$.
\end{itemize}
\end{theorem}

Identical theorems hold for each of \countingfrank~and \treefrank. Previous work
(\cite{convent2020doo}) has shown that subject reduction holds for \purefrank;
as such the proofs for each of our new systems amount to just showing the new
reduction rules preserve types. Indeed, even this just amounts to showing that
inserting a \yield~command before a term does not change the overall type of a
term. Proofs of subject reduction for \nondetfrank, \countingfrank~and
\treefrank~can be found in Section~\ref{sec:subject-reduction-proofs}.




\begin{theorem}[Type Soundness for \nondetfrank]\label{thm:soundness}~
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
%% In particular, if $\sigs = \nowt$ then either the term is a value $w$ or the
%% term can reduce by one step.
\end{theorem}

Again, we have identical theorems for \countingfrank~and \treefrank. The proof
of type soundness proceeds by induction on $\infers{\cdot}{\cdot}{\sigs}{m}{A}$
and $\checks{\cdot}{\cdot}{\sigs}{A}{n}$. None of our extensions involve new
typing judgements, so we do not add any new cases to the proof of type soundness
for \purefrank(\cite{convent2020doo}). Our main obligation is to show that
systems equipped with a counter never get stuck in a state where they cannot
reduce due to the counter blocking; this is shown in
Section~\ref{sec:type-soundness-proofs}.

% \begin{proof}
% The proof proceeds by simultaneous induction on
% $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ and $\checks{\cdot}{\cdot}{\sigs}{A}{n}$.
% \end{proof}

% \todo{Talk about Soundness for \nondetfrank~as well as \countingfrank.}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{chap:implementation}

%% We now introduce the Frank library for programming with asynchronous effects.
%% %
%% Our design closely follows \aeff~(\cite{ahman2020asynchronous}), a language
%% designed around writing multithreaded programs using asycnhronous effects.

% In this section we give a brief introduction to programming with asynchronous
% effects, and introduce the Frank library for doing so.
In this section we introduce the asynchronous effects abstraction, and introduce
the Frank library for programming with them.
%
Our design closely follows \aeff~(\cite{ahman2020asynchronous}), the only
existing implementation for programming with user-defined asynchronous effects.

One can consider the traditional treatment of shallow effect handling as having
three stages. First an operation \textsf{op} is invoked, with arguments $V$ and
continuation $\lambda x . M$. Then the handler for \textsf{op} --- being the
\emph{implementation} of \textsf{op} --- is evaluated with arguments $V$ until
it returns some value $W$. Finally, the continuation of the caller is resumed by
binding $W$ to $x$ in $M$, where this resumed continuation is possibly rehandled
or in some other context.

What makes effect handling \emph{synchronous} is that the operation call
\textsf{op} \emph{blocks} until the continuation $M$ is resumed. This means that
for \emph{every} algebraic effect, the rest of the calling code has to wait for
the handler to be performed, even when the results are not immediately needed.
The \emph{asynchronous} treatment of effect handling decouples these three
stages; each of invoking an effect, evaluation of the handler, and resumption of
the caller are separate.
%
% This permits the non-blocking invocation of effects; we invoke an operation and
% can continue the rest of the computation before the operation has been handled.
This permits the non-blocking invocation of effects; we can invoke an operation,
continue with other work, then if and when we need the result of the operation
we can choose to block.
%
% The decoupling of operation invocation from handling has other benefits that we
% discuss later in this section.

% Consider effect handling as a simple two threaded application; one thread is the
% caller, which invokes some operation \textsf{op}, and the other is the handler
% for \textsf{op}. In the synchronous treatment, once the caller invokes \code{op}
% the rest of the caller is blocked until the handler has finished handling
% \code{op}, at which point the caller restarts. In the asynchronous treatment,
% the caller can continue executing; once it needs the result of the operation it
% can then choose to block.

Asynchronous effects are used for writing multithreaded programs. A single
thread might handle some operations and also perform other ones, which
themselves are handled by other threads. Rather than the binary division of
caller and handler, a single thread can both invoke and handle asynchronous
operations. In the rest of this section we explain this behaviour by example,
and introduce our library for programming with asynchronous effects in Frank.

%
%% A secondary benefit of decoupling the components of effect handling is that
%% operations can be invoked

% \todo{Talk about how these are all decoupled}

\section{Communication}

Consider a program \feed which lets the user scroll through an seemingly
infinite feed of information (example due to \cite{ahman2020asynchronous}). The
program displays each item in its cache of data as the user scrolls; the program
simulates being infinite by making a request for another cache of data whenever
the user is nearly at the end of the current cache. In this way, the user never
notices the feed pausing to download more data; they happily scroll to their
heart's content.

The client thread \feed~would be run in parallel with a user interface
controller, to handle UI interaction, and a server, which supplies extra data
when needed. The client would then interact with these other threads by sending
\emph{signals} and receiving \emph{interrupts}. One can imagine these as a
further division of operation calls: a thread sends a signal to request another
thread to perform some operations, and the other threads receive a corresponding
interrupt. For instance, \feed~would send a \code{request} signal to ask the
server to send a new cache of data; \feed~would then receive a \code{response x}
interrupt, where \code{x} is the new data from the server.

Despite this example, we remark that signals do not require a corresponding
interrupt as response and vice versa.
%
For instance, \feed~would perform \code{display d} signals, as requests to the
UI controller to display data \code{d}; the client then doesn't need a response
from the UI controller. Similarly, \feed~receives \code{nextItem} interrupts
whenever the user requests to see a new item. The system could also receive
interrupts and send signals; for instance we could have a \textsf{timer}
interrupt, send by the operating system at a regular interval.


% This program has to interact with the outside world,

% We can implement this using asynchronous effects and several smaller program
% threads. We might have a user interface thread which deals with input and
% output, a client which  a server which

% Asynchronous effects are particularly useful for writing \emph{multithreaded}
% programs. We may have several other threads in addition to \feed, such as a
% server and a user interface controller.

% Using asynchronous effects, threads communicate with one another using
% \emph{signals}, which are analogous to effect invocations. For instance, \feed
% would use a \code{request} signal to ask for more data from the server. Signals
% sent from other threads become \emph{interrupts} from the receiver's point of
% view; for instance, \feed~would receive \code{response} interrupts from the
% server, containing the new cache of data.

% \todo{Maybe say ``operation calls are further split into signals & interrupts?''}


% For instance, in
% Section~\ref{sec:pre-emptive-scheduling} we implement a pre-emptive scheduler,
% which sends \code{stop} and \code{go} signals without expecting an interrupt as
% a response. Indeed,

% \todo{Write with a view to saying that this behaves asychronously; remember that
%   the user wants to imagine it's asynchronous and that the implementation is
%   just a kind of specialisation of this}

% How is this implemented with asynchronous effects? We have a number of operations
% here: \code{request} for when \feed~needs more information, \code{display d} to
% display data \code{d}, and then the \code{next} operation that \feed~responds
% to. Observe that from the point of view of \feed, \code{request} and
% \code{display} differ to \code{next}; the latter two are operations that
% \feed~performs, whilst \code{next} is an operation \feed~\emph{responds} to. We
% call the latter (outgoing) operations \emph{signals} and the former (incoming)
% opreations \emph{interrupts}.

We define \emph{interrupt handlers} to dictate how to act when an interrupt is
received. An interrupt handler is a function of type \code{S -> Maybe \{R\}},
where \code{S} is a sum type made up of the possible interrupts that can be
received; an example is the \code{Feed} type defined below.
%
% \todo{Fix the way we talk about S.}
%
The return type of the handler is \code{Maybe \{R\}} as we can choose \emph{not}
to handle the interrupt by returning \code{nothing}; this could be because it is
the wrong type of signal, or if some other condition regarding the interrupt is
not fulfilled\footnote{An interrupt handler which inspects the body of the
  interrupt and chooses whether or not to evaluate to \code{nothing} or
  \code{just thk} is called a \emph{guarded} interrupt handler. We see an
  example of guarded interrupt handling in
  Section~\ref{sec:pre-emptive-scheduling}.}.
%
An example of an interrupt handler is \code{boringFeed};

\begin{lstlisting}
data Feed = nextItem | request Int
          | response (List Int) | display Int

boringFeed : {Feed -> Maybe {[Console] Unit}}
boringFeed nextItem = just {print "10"}
boringFeed _ = nothing
\end{lstlisting}

\noindent The interrupt handler \code{boringFeed} prints out \code{10} on
receipt of a \code{nextItem} interrupt; if it receives any other interrupt it
does nothing. From now on we also call an interrupt handler a \emph{promise}. We say that a promise which reduces to \code{(just thk)} is \emph{fulfilled}.

For an interrupt handler to be used, a thread must \emph{install} it. Once
installed, the interrupt handler is evaluated against every interrupt that the
installing thread receives. We go into more depth on this process in the next
section.

% A thread will then \emph{install} an interrupt handler to use it. Once
% installed, an interrupt handler is then informed of every interrupt that the
% installing thread receives. We formalise what exactly happens in the next section.

% \todo{Fix this?}

% \noindent When a thread installs the interrupt handler \code{boringFeed}, it
% prints out \code{10} the first time it receives a \code{nextItem} interrupt.

% From henceforth we also refer to interrupt handlers
% as \emph{promises}; an interrupt handler for \textsf{op} once installed is a
% \emph{promise} to perform the given action once an \textsf{op} interrupt is
% received.

% \todo{Maybe get rid of this part.}


\section{An Interface for Asynchronous Effects}

To make our ideas more concrete, we introduce the Frank interface used for
programming with asynchronous effects. First of all we introduce the datatype
used to track the state of an installed promise, \code{Prom}.

\begin{lstlisting}
data Prom X = prom (Ref (PStatus X))
data PStatus X = waiting | done X | resume {X -> Unit}
\end{lstlisting}

A value of type \code{Prom X} is a reference to a value of type \code{PStatus
  X}. It is stored as a reference as we have to write to this cell from two
locations; the interrupt handler itself updates the cell once it has been
evaluated, and the handler for \code{await} commands also has to access the cell
when the promise is awaited.

A promise has three possible states, each a different constructor for
\code{PStatus}. The first, \code{waiting}, expresses that the promise has not
yet been fulfilled. The second, \code{done x}, expresses that the promise has
completed and resulted in a value \code{x}. The third option, \code{resume
  cont}, is used when a promise is awaited but has not yet completed; in this
case, the handler for \code{await} writes the continuation of the caller to
\code{resume}. The interrupt handler then automatically resumes this once it is
fulfilled. Ideally, \code{Pid} should be an abstract type; the programmer should
not be able to directly look inside an installed \code{Pid} from the point of
view of a thread. The only way the programmer should get the value out of a
\code{Pid} is by awaiting the promise.

% The
% continuation \code{cont} is the continuation offered by the calling code when
% the \code{await} effect is performed. We see how this is handled later in this
% section. \todo{Maybe go over this?}

% \todo{Talk about caller not getting access to the Pid cell}

\begin{lstlisting}
interface Promise S =
    promise R : {S -> Maybe {<@\greytext{[Promise S, RefState, Yield]}@> R}}
             -> Prom R <@\greytext{[Promise S, RefState, Yield]}@>
  | signal : S -> Unit
  | await R : Prom R <@\greytext{[Promise S, RefState, Yield]}@> -> R
\end{lstlisting}

The entire \code{Promise} interface is polymorphic in the type of \emph{signals}
that threads can perform. This will be a datatype such as \code{Feed}, as
discussed earlier. The commands themselves are polymorphic in the
result type \code{R} of the interrupt handlers being installed or awaited.

The \code{promise} command is used to install an interrupt handler; it takes an
interrupt handler and returns a \code{Prom R} value. The interrupt handler can
perform further \code{Promise S} effects, and must also have access to the
\code{RefState} interface. This is because when installing the promises we
modify them to automatically write to their \code{Prom} cell once they fire. The
\code{Yield} interface is also present so that interrupt handlers are themselves
pre-emptible when executed. We can also parametrise the \code{Promise} interface
by effects that the interrupt handlers can perform. For instance, if using the
\code{Promise S [Console]} interface interrupt handlers also perfom
\code{Console} effects and further \code{Promise S [Console]} effects. This is
due to implicit effect polymorphism as discussed in
Chapter~\ref{chap:programming-in-frank}. A stack of installed interrupt handlers
is kept for each thread.

The \code{signal} command takes a value of the \code{S} type and returns
\code{unit}. When handling \code{signal sig}, all other threads are interrupted;
they stop whatever they were doing, and all installed interrupt handlers now
have to handle this signal. We go through each interrupt handler \code{ih} in
the stack. Recall that an interrupt handler is just a function of type \code{S
  -> Maybe \{R\}}. Thus we simply apply \code{ih} to the interrupt \code{sig}.
If $\code{(ih sig)} \redto \code{nothing}$ we leave \code{ih} on the stack and
look at the next interrupt handler. If
$\code{(ih sig)} \redto \code{(just thk)}$, the interrupted thread immediately
performs the thunk \code{thk} before continuing with the interrupted
computation. In this case, \code{ih} is removed from the stack.

Finally, the \code{await} command takes a \code{Prom R} value and returns a
value of type \code{R}. At this point, we inspect the promise state as stored in
reference. If the promise is still \code{waiting}, we take the continuation
\code{cont} offered up by \code{await} and store it in the cell as \code{resume
  cont}. If the promise is \code{done} we immediately resume the continuation
with the stored value. At this point the cell should not have a continuation in
it, as it's not possible for multiple threads to await a single promise. As
such, we just safely exit.

When a promise is fulfilled, it automatically looks inside its associated
\code{Prom} cell. If the status is just \code{waiting}, the promise just writes
the returned value to the cell as \code{done x}. If there is a resumption in the
cell, the promise immediately resumes it. There should not already be a
\code{done x} value in the cell, as only the given promise and the handler for
the promise interface should have access to it.

\section{In Action}

Let's revisit the infinitely scrolling feed example from earlier, and consider
the client thread, \feed. The bulk of the client is an interrupt handler for
\code{nextItem} messages. The body of this handler will display the next datum
and reinstall the \code{nextItem} interrupt handler, as well as perform any
requests for extra data. The type signature of the body of our handler will be:

\begin{lstlisting}
onNext : {List Int -> Maybe (Prom (List Int) <@\greytext{[InThread]}@>)
          -> <@\greytext{[InThread]}@> Unit}
\end{lstlisting}

\noindent where \code{[InThread]} is an \emph{interface alias} for
\code{[Promise Feed [Console], Console, RefState, Yield]}. The first argument to
\code{onNext} is the currently stored cache of data. The second argument is a
\code{Prom} cell which may not be present; this stores the promise that waits
for a response from the server when a request for extra data is made.
%
We use a helper function, \code{displayRestart}, to display the next item from the cache and reinstall the \code{nextItem} promise:
% We use a
% helper function, \code{displayRestart}, to do some tasks that happen every time
% \code{onNext} is executed:

\begin{lstlisting}
displayRestart : {List Int -> Maybe (Prom (List Int) <@\greytext{[InThread]}@>)
              -> <@\greytext{[InThread]}@> Unit}
displayRestart cache p =
    signal (display (head cache));
    let cache = pop cache in
    promise { nextItem -> just { onNext cache p } | _ -> nothing };
    unit
\end{lstlisting}

% \noindent We simply \code{display} the first element of the cache, and then
% install an interrupt handler for \code{nextItem} interrupts that reinstalls
% \code{onNext}, with the top item removed from the cache.

For the sake of simplicity we assume that the cache size is fixed to 10 items.
Then whenever we have 3 or less items in the cache, and another request is not
already in progress, we want to issue a new request for data.

\begin{lstlisting}
onNext xs nothing =
  if (len xs == 3)
    { let r = promise {(response x) -> just {x} | _ -> nothing} in
      signal (newData (last xs));
      displayRestart xs (just r) }
    { displayRestart xs nothing }
\end{lstlisting}

\noindent Observe that if the length of the cache is 3 we first install an
interrupt handler for \code{response} interrupts, and then issue a
\code{newData} signal; we know that the server will respond to the
\code{newData} interrupt it receives with a \code{response} message. As
mentioned before, not every signal sent has a corresponding interrupt that will
later be received; for instance, the \code{display} signal is sent without
requiring an interrupt to respond, and the \code{nextItem} interrupt is received
without the client sending a signal to cause it to come in.

Once the request for new data has been issued, we reinvoke \code{onNext}, but
this time carrying the promise. This leads us to the other branch of
\code{onNext};

\begin{lstlisting}
onNextList cache (just p) =
    if (len cache == 0)
         { displayRestart (await p) nothing }
         { displayRestart cache (just p) }
\end{lstlisting}

\noindent Here we check if we are at the end of the current cache. If we are, we
await the promise, binding \code{newCache} to the result. Once the promise
\code{p} is fulfilled we proceed as normal with the cache returned from the
\code{resp} promise.

The client then installs the \code{nextItem} interrupt handler with
\code{(promise \{nextItem -> just \{onNext startCache nothing\} | _ -> nothing\})}.
%
% The client can then use this promise by installing it in the same way as in
% \code{displayRestart}; they may want to install another interrupt handler, to
% listen for other messages from the user interface.

\section{Modelling Asynchrony}

In this section we address how we model asynchrony in the single-threaded
setting of Frank. We use the system as described in
Chapter~\ref{chap:preemptive-concurrency} to automatically force threads to
\yield~after a certain amount of reductions. To handle these \yield~commands we
use a scheduler similar to the example in
Section~\ref{subsec:forking-new-processes}, where we have a collection of
threads, cycling through in order.
%
% As such, the system is not truly
% asynchronous; a thread does not receive interrupts whilst it is executing, only
% whilst other threads are executing.

Earlier we mentioned that when a thread sends a signal, all other threads
immediately perform the body of any fulfilled promises. This is not true in
practise; all other threads are notified that they should perform the bodies of
the fulfilled promises, but they only do so when the performing thread gets
processor time. Specifically, if an interrupt handler \code{ih} for a suspended
thread \code{thr} reduces to \code{(just thk)} on receipt of an interrupt, we
update the suspended thread's thunk in our collection to \code{\{thk!; thr!\}}.
As such, the body of the a fulfilled interrupt handler does not actually get
executed until the thread gets to run again.

This contrasts with \aeff, where any process may run at any point. However, with
the pre-emptive concurrency of our system we can easily recreate this. Another
way in which our system and \aeff~differ is that when a thread receives an
interrupt in our system \emph{all} interrupt handlers must immediately handle
it, and the rest of the computation may not reduce. In \aeff, this is not the
case; a computation may continue to otherwise evaluate before it handles an
interrupt.
% The model of \aeff~lets any process run at any point. This yields a greater
% degree of asynchrony, as interrupts can truly be received at any point. This is
% however a slightly
% This is a stricter approach than \aeff, where the system can
%
% This is a stricter approach than that taken by \aeff, where an interrupted
% computation may still reduce before the interrupt handlers process the
% interrupt. However, this is a testament to the true asynchronous behaviour of
% \aeff; this is only approximated in Frank. It remains as future work to mimic
% the full asynchronous behaviour of \aeff.

% \todo{Talk about non-confluence?}


\chapter{Examples}
\label{chap:examples}

Imagine you wanted to implement a structure for asynchronous programming, such
as async-await. We could add this as a new primitive to our language; we change
the compiler to add new syntax, then the new type-checking rules, then we have
to implement the semantics; then we have to do this all over again if we want a
new feature for asynchronous programming. This is cumbersome, boring, and worst
of all takes the implementations outside of the language; we cannot tweak them, they are opaque.

The alternative is to use asynchronous effects as the building block. In this
section, we show how several useful features for asynchronous programming can be implemented on top of the \code{Promise} library.

% Many languages which support async-await --- such as C# and Javascript --- have
% the behaviour built-in. First the compiler is changed to add new syntax, then
% the compiler is changed to add new type-checking, then we have to implement the
% semantics; even worse, we have to do this when we want another asynchronous
% primitive, such as futures (asynchronous post-processing of results).

% We show that with our promise library we can implement all of these common
% asynchronous primitives within the language itself.

\section{Pre-emptive Scheduling}
\label{sec:pre-emptive-scheduling}

Whilst we have already shown how to pre-emptively schedule several threads in
Section~\ref{sec:handling}, we might want to have a more robust way of doing
this; the multihandler strategy is fixed in a left-to-right evaluation order. In
this method, we can just have a single source sending out \code{stop} and
\code{go} messages, implementing a potentially more sophisticated scheduling
strategy than mere round-robin.

For simplicity's sake, we just display a version with only one thread, however
this approach can easily be generalised to pre-empt multiple threads by adding
ID fields to the \code{stop} and \code{go} signals and using guarded interrupt
handlers for \code{goPromise} and \code{stopPromise}.

\begin{lstlisting}
data Schedule = stop | go

goPromise : {Sig -> Maybe {<@\greytext{[Promise Schedule]}@> Unit}}
goPromise go = just {unit}
goPromise _ = nothing

stopPromise : {Sig -> Maybe {<@\greytext{[Promise Schedule]}@> Unit}}
stopPromise stop = just {await (promise goPromise);
                         promise stopPromise; unit}
stopPromise _ = nothing

preempt : {{X} -> <@\greytext{[Promise Schedule]}@> X}
preempt comp = promise stopPromise; comp!
\end{lstlisting}

\noindent We can easily make a computation pre-emptible by just installing
\code{stopPromise} before the main body, as in the function \code{preempt}.

Once a preemptible computation receives a \code{stop} interrupt, it installs
\code{goPromise} and immediately awaits it. This blocks the rest of the
computation from executing until a \code{go} interrupt is received. When such a
signal does come in, \code{goPromise} is fulfilled; the body of the interrupt
handler does nothing, but it unblocks the rest of the thread's computation. At
this point, the rest of the body of \code{stopPromise} is also unblocked, so
another \code{stopPromise} is installed.


% \noindent For simplicity's sake we just display a version with only one thread, however this approach can easily be generalised to multiple threads by adding ID fields to the signals in \code{schedule} and using guarded interrupt handlers.

% % \code{stopPromise} is another guarded interrupt handler; it will only fire its
% body if the payload to \code{stop} is the thread's ID. The body then installs a
% promise waiting for \code{go} and immediately awaits it, starting to block. The
% rest of the computation can not proceed until the corresponding go message is
% received. Once the correct go promise is received the promise is fulfilled adn
% the rest of the computation can start again, and the \code{stop} interrupt
% handler is reinstalled. \code{goPromise} is simple in comparison; if it receives
% the correct \code{go} signal it just returns \code{unit}.

%% We can then make a function  by just installing a stop-waiting promise
%% in front of the function code;

%% We can then install the stop interrupt handler before a computation to make it
%% schedulable. The computation being scheduled is then unaware it is being
%% scheduled, as desired.

Now all that remains is to have a source of \code{stop} and \code{go} signals.
This could just be a standard round-robin scheduler or some more sophisticated
strategy. One disadvantage to our approach is that an adversarial thread could
just send \code{stop} and \code{go} signals of its own, overriding the
scheduler. Using session types (\cite{honda1998language}) to restrict
communication protocols could be used to solve this problem; we leave this to future work.

\section{Futures}
\label{sec:futures}

We can implement the asynchronous post-processing of results, or \emph{futures}
(\cite{schwinghammer2002concurrent}), with asynchronous effects. Futures are
useful if we want to asynchronously perform some action once another promise (or
future) has been completed. In the context of a web application, this might be
updating the application's display once some remote call for data has finished.
Observe that this differs from just awaiting the remote call and then updating
once we have this; we do not want to block everything else from running, rather
perform this action asynchronously, when the promise is complete.

\begin{lstlisting}
data Fut = newData (List Int) | result Int

futureND : {Pid R <@\greytext{[Promise Fut]}@> -> {R -> <@\greytext{[Promise Fut]}@> Z} -> Sig
    -> Maybe {<@\greytext{[Promise Fut]}@> Z}}
futureND p comp (newData _) = just { let res = await p in comp res}
futureND _ _ _ = nothing
\end{lstlisting}

\noindent When calling \code{futureList} we supply a promise of result type
\code{R} and a computation of type \code{R -> Z}. We then await the promise, and
once we have a value (of type \code{R}) evaluate the supplied computation on
this value. An example using this system is:

\begin{lstlisting}
let recv = promise { (newData xs) -> just {xs} | _ -> nothing} in
let prod = promise {s -> futureND recv product s} in
promise {s -> futureND prod {x -> signal (result x)} s}
\end{lstlisting}

\noindent where we, upon receipt of a \code{newData} interrupt, take the product
of the list element-wise and send another signal with this result. All three of
these promises are triggered by the same signal; \code{recv} is executed first,
which is awaited by \code{prod}. When \code{prod} is fulfilled the final promise
is unblocked and the \code{result} signal is sent. This behaviour depends on a
single interrupt being able to trigger many interrupt handlers at once.

\section{Async-Await}
\label{sec:async-await}

Our asynchronous effects system can express the familiar async-await
abstraction. This had previously been implemented in Frank by \textsf{fork}ing
new threads, which were then handled with a scheduler like that in
Section~\ref{subsec:forking-new-processes}. We implement it with asynchronous
effects by using a controller thread, which will send tasks to one of a set of
worker threads. When these worker threads are idle, they are instantly skipped;
hence there is not much inefficiency associated with having extra idle workers.

We use three types of signal here. The calling thread sends \code{call}
messages, where the arguments are the computation to run and the call ID. The
controller handles \code{call} interrupts and sends \code{work} interrupts; the
arguments to this signal are the computation again, the call ID and the ID of
the worker who is designated to run this task. Finally, the worker sends
\code{result} signals when it has finished computing; arguments to this are the
result and the call ID.

\begin{lstlisting}
data Async R = result R Int | call {R} Int
             | work {R} Int Int

async : {[{String} -> Ref Int
    -> <@\greytext{[Promise (Async String)]}@> Pid String <@\greytext{[Promise (Async String)]}@>
async proc callCounter =
    let callNo = read callCounter in
    let waiter = {s -> resultWaiter callNo s} in
    signal (call proc callNo);
    write callCounter (callNo + 1);
    waiter
\end{lstlisting}

We use this function to issue a new asynchronous task. We keep a global counter
to give each call a unique identifier. We then install a promise
\code{resultWaiter} that waits for a result and simply returns it, if the call
numbers match. Finally we send a \code{call} signal with the process and return
the result interrupt handler. Observe that \code{async} just returns the
\code{result} promise; we just use the given \code{await} operation to await.


The controller installs an interrupt handler for \code{call} interrupts.
The thread tracks which threads have a task running; if there is a free worker
it then sends a \code{work} signal, containing the computation and the ID of the
worker who should perform it. The controller then installs a promise to update
the active status of the corresponding worker once a \code{result} interrupt is
received from the worker.

Workers listen for a \code{work} interrupt; when one comes in with their ID in
the payload, they simply perform the computation and send a \code{result} signal
with the result. This \code{result} signal triggers the interrupt handler
installed by the \code{async} caller, but also triggers the promise installed by
the controller, to inform it that the worker is now idle. This ability to
trigger multiple promises with one message is a subtle but useful feature of the
asynchronous effects system.

\section{Cancelling Tasks}

Because we are working in a language equipped with effect handlers, we can
easily write a handler for the $\textsf{Cancel} = \textsf{cancel : Unit}$
effect, which just gets rid of the continuation and replaces it with some
default value (e.g. \code{unit}). We can use this to cancel a task issued with
\code{async}. Recall that tasks issued with async-await run on their own thread;
we can use the \code{cancel} effect to throw away the continuation of the entire
thread and wipe the slate clean. To make our worker threads cancellable, we
change the interrupt handler for \code{work} interrupts to install the
\code{canceller} promise before the worker starts running the task:

% All we need to do to make our worker threads cancellable
% is install the \code{canceller} promise below;

\begin{lstlisting}
canceller : {Int -> Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
canceller wid callId (cancelCall callId') =
    if (callId == callId')
        { just {promise {s -> worker wid s}; cancel!} }
        { nothing }
canceller _ _ _ = nothing
\end{lstlisting}

% \noindent The \code{canceller} promise installs the \code{worker} promise before
% cancelling, so that the thread can one day run a task again. \todo{fix}

\noindent The \code{canceller} promise reinstalls the \code{worker} promise
before performing the \textsc{cancel}, so that the thread can eventually run
another task again after the current task is done. The controller also is
modified to install an interrupt handler for \code{cancelCall} interrupts; this
interrupt handler sets the corresponding worker's state to idle.

% workProm : {Int -> Sig -> Maybe {<@\greytext{[Promise]}@> Unit}}
% workProm wid (workIn p wid' callId) =
%     if (wid == wid')
%        { just {<@\texthighlight{promise \{s -> canceller wid callId s\}}@>;
%                let res = p! in
%                signal (result res callId);
%                worker wid; unit}}
%        { nothing }
% workProm _ _ = nothing
% \end{lstlisting}

The realisation of cancellable function calls in
\aeff(\cite{ahman2020asynchronous}) was to start awaiting a new promise that
will never be fulfilled. This leads to a space leak as unfulfilled promises
build up. Our approach improves on this as the cancelled calls do truly
disappear.

% However, a weakness of our system is that we have to modify the
% handler code for promises, even though cancellation of calls and promises should
% be orthogonal.

However, we have to modify the handler for the \textsf{Promise} effect to
correctly cancel threads. When we fulfill a promise, we take the result
computation and compose this with the interrupted computation and rehandle this
single computation with the promise handler. At this point, we also now handle
\code{Cancel} effects, so that we remove the whole thread. This is a point for
improvement; handling the \code{Cancel} effect and handling \code{Promise}
effects are orthogonal, and should be treated separately. We leave it as future
work to further investigate and refine interactions between traditional effects
when installed by promises.

% We have to modify the handler for the \textsf{Promise} effect for this. Recall
% that when we install a promise, we convert it to a form that takes composes the
% body of the promise with the interrupted computation and rehandles the
% \code{Promise} effects that this might perform.
% %
% We need to then wrap this in a handler for \textsf{Cancel} effects again; this
% is because user-level promises could perform \textsf{Cancel} effects, and we
% want to cancel the \emph{whole} computation, not just the body of the promise.

% \begin{lstlisting}
% case (cbMod sig)
%     { nothing -> nothing
%     | (just susp) ->
%       just { <@\texthighlight{stopCancel}@> (hdl thId thrs (susp!; <LCancel, Promise> rest!)) }}
% \end{lstlisting}


\subsection{Interleaving}

With the \textsf{Cancel} effect, we can also define the useful \code{interleave}
combinator (\cite{leijen2017structured}).
%
This lets us issue two tasks on two different threads, using the \code{call}
signal as defined in Section~\ref{sec:async-await}. We then install an interrupt
handler for \code{result} interrupts; if a \code{result} interrupt corresponds
to one of the installed threads we cancel the other thread using
\code{cancelCall} and return the received result. This lets us write timeouts
for functions, where we interleave a potentially long-running request with a
timer; we cancel the request if it takes too long. We can also run two identical
requests to different services and just take the result of the one that returns
first.

% Despite \code{interleave} being a more complex function than \code{async}, we
% can implement it with a small change to \code{async}.

Observe that \code{interleave} is just a slight modification of \code{async} as
defined earlier. By taking asynchronous programming structures outside of the
language implementation --- where they are opaque black boxes --- and
implementing them within the language itself, we hope that programmers will be able to easily craft their own tools specifically to what they need.


% By taking asychronous programming structures out of library
% code and into the programmer's hands, we hope that programmers will be able to
% shape the

% Observe the similarity of \code{interleave} and \code{async}. By taking
% asynchronous programming structures out of library code and into the
% programmer's hands, we hope that programmers will be able to more easily produce
% their own, useful tools.


\chapter{Conclusion}
\label{chap:conclusion}

We conclude with a discussion of the achievements, some limitations of our work, and
possible future work.

In Chapter~\ref{chap:preemptive-concurrency} we gave a simple, natural way to
accomodate pre-emptive concurrency into Frank. Our solution is particularly nice
as it doesn't rely on external signals, like in Multicore OCaml
(\cite{dolan2017concurrent}). Our system lets the programmer easily decide which threads to make pre-emptible, at virtually no overhead.

In Chapter~\ref{chap:implementation} we explained the abstraction of
asynchronous effects, and how they are implemented in Frank. In
Chapter~\ref{chap:examples} we showed how this system can be used to implement
common, useful structures for asynchronous programming. We can recreate the
behaviour of \aeff, the only other language with support for asynchronous
effects, and show how asynchronous effects in the prescence of synchronous
effects can be used to cancel calls.

We hope that one of the outcomes of this project and related work
(\cite{ahman2020asynchronous, leijen2017structured, dolan2017concurrent}) is
taking the definition of asynchronous programming features away from the realm
of low-level operating system schedulers and opaque web programming interfaces
and offering them up to the user. Synchronous effect handlers have shown to
achieve a similar goal with respect to exception handling and other control flow
operations; it is our hope that asynchronous effect handling could do the same.



% Moreover, we have shown how effect handlers as a programming tool can be used to
% easily express complicated control flow.

% \todo{Add more to end of paragraph}

\section{Limitations and Future Work}

\paragraph*{Type System}
The implementation of asynchronous effects as discussed does not track
asynchronous effects, and is untyped. \citeauthor{ahman2020asynchronous} have
shown that this is possible; it would be interesting to see a typed asynchronous effects system embedded into another language.

\paragraph*{Interactions between Synchronous and Asynchronous Effects}
Handling effects performed by interrupt handlers can be quite a challenge
sometimes. Effects like \code{Console} and random number generation are fairly
straightforward to handle, as we can let them pass up to the top-level and
handle with a single handler. However, handling something like the \code{State}
effect is trickier; we cannot use the same \code{State} handler to handle
everything as this would share the state between all threads. Threading the
\code{State} handler through the \code{Promise} handler is cumbersome; it would
be better to leave the \code{Promise} handler to be.

\paragraph*{Communication Protocols}
Our system uses the fairly simple communication protocol where every message
gets sent to every thread. Naturally, two threads might want to communicate
secretly, without other threads eavesdropping. A system of communication
protocols similar to session types (\cite{honda1998language}) could solve this.

\paragraph*{A Higher Degree of Asynchrony}
There are several degrees of asynchrony possible with a system like ours. We
restrict one thread to run at any given time, with fulfilled promises only
evaluating when the corresponding thread gets processor time. \aeff~take the
other approach; any thread can compute at any time. There is an in-between,
where the bodies of interrupts may be evaluated out-of-turn. It would be
interesting to further explore the differences between different models of
asynchrony and their benefits and limitations.

\paragraph*{Sophisticated Yielding Strategies}
Although our \yield{}ing strategy in Section~\ref{sec:starvation} does not allow
threads to starve due to lack of processing time, we do not have a bound on how
much time can pass before a thread gets processor time. It would be good to
either find a bound for \treefrank~or design a new system where a bound can be
easily expressed.

\paragraph*{Implementations in Other Languages}
We postulate that our \code{Promise} interface should be simple enough to
reimplement in other languages; it would be interesting to try to do so in
another language like Links or Koka and see whether our claim holds.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{plainnat}
\bibliography{bibliography}

%% You can include appendices like this:
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\appendix

\chapter{Remaining Formalisms}

\begin{figure} % \figrule
\flushleft
%% $\boxed{\kindchecksk{R}}$
%% \begin{mathpar}
%% \inferrule[K-Val]
%%   {\TyVar(A) \subseteq \kenv}
%%   {\kindchecksk{A}}

%% \inferrule[K-Eff]
%%   {\TyVar(\sigs) \subseteq \kenv}
%%   {\kindchecksk{[\sigs]}}
%% %
%% \end{mathpar}

$\boxed{\infersk{\Gamma}{\sigs}{m}{A}}$
\begin{mathpar}
\inferrule[T-Var]
  {
   x:A \in \Gamma}
  {\inferskgs{x}{A}}

\inferrule[T-PolyVar]
  {% \kindchecks{\kenv, \many{Z}}{A}\\
   \kindchecksk{\many{R}} \\
   f:\forall \many{Z}.A \in \Gamma}
  {\inferskgs{f~\many{R}}{A[\many{R}/\many{Z}]}}
\\
\inferrule[T-App]
  {\sigs' = \sigs \\
   (\adjact{\sigs}{\adj_i}{\sigs'_i})_i \\\\
   \inferskgs{m}{\thunk{\many{\effin{\adj}A \to}~ \effout{\sigs'}B}} \\
   (\checksk{\Gamma}{\sigs'_i}{A_i}{n_i})_i}
  {\infersk{\Gamma}{\sigs}{m~\many{n}}{B}}

\inferrule[T-Ascribe]
  {\checkskgs{A}{n}}
  {\inferskgs{\cu (n : A)}{A}}
%
\end{mathpar}

$\boxed{\checksk{\Gamma}{\sigs}{A}{n}}$
\begin{mathpar}
\inferrule[T-Switch]
  {\inferskgs{m}{A} \\ A = B}
  {\checkskgs{B}{\uc m}}

\inferrule[T-Data]
  {%(\kindchecksk{R_i})_i\\
   k~\many{A} \in D~\many{R} \\
   (\checkskgs{A_j}{n_j})_j}
  {\checkskgs{D~\many{R}}{k~\many{n}}}

\inferrule[T-Command]
  {\kindchecksk{\many{R}} \\
   c : \forall \many{Z}.\many{A \to}~ B \in \sigs \\
   (\checkskgs{A_j[\many{R}/\many{Z}]}{n_j})_j}
  {\checkskgs{B[\many{R}/\many{Z}]}{c~\many{R}~\many{n}}}

\inferrule[T-Thunk]
  {\checksdefkg{C}{e}}
  {\checkskgs{\thunk{C}}{\thunk{e}}}

\inferrule[T-Let]
  {P = \forall \many{Z}.A \\\\
   \checkbase{\kenv, \many{Z}}{\sigentails{\emptyset}}{\Gamma}{A}{n} \\
   \checksk{\Gamma, f : P}{\sigs}{B}{n'}}
  {\checkskgs{B}{\key{let}~f : P = n~\key{in}~n'}}

\inferrule[T-LetRec]
  {(P_i = \forall \many{Z}_i.\thunk{C_i})_i \\\\
   (\checkbase{\kenv, \many{Z}_i}{\vdash}{\Gamma, \many{f : P}}{C}{e_i})_i\\
   \checksk{\Gamma, \many{f : P}}{\sigs}{B}{n}}
  {\checkskgs{B}{\key{letrec}~\many{f : P = e}~\key{in}~n}}

\inferrule[T-Adapt]
  {\adjact{\sigs}{\adapt}{\sigs'} \\ \checksk{\Gamma}{\sigs'}{A}{n}}
  {\checkskgs{A}{\effin{\adapt}~n}}
\end{mathpar}

$\boxed{\checksdefkg{C}{e}}$
\begin{mathpar}
\inferrule[T-Comp]
  {(\matchesck{T_j}{r_{i,j}}{\sigs}{\exists \kenva_{i,j}.\Gamma'_{i,j}})_{i,j} \\
   (\checks{\kenv, (\kenva_{i,j})_j}{\Gamma, (\Gamma'_{i,j})_j}{\sigs}{B}{n_i})_i \\
   ((r_{i,j})_{i} \text{ covers } T_j)_j}
  {\checksdefkg{(T_j \to)_j~\effout{\sigs}B}{((r_{i,j})_j \mapsto n_i)_i}}
\end{mathpar}
\caption{Term Typing Rules}
\label{fig:term-typing}
% \figrule
\end{figure}

\begin{figure}%% \figrule
\flushleft
$\boxed{\adjact{\sigs}{\adj}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adj]{\adjact{\sigs}{\adapt}{\sigs'} \\
  \adjact{\sigs'}{\ext}{\sigs''}}
          {\adjact{\sigs}{\adapt\pipe\ext}{\sigs''}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\ext}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Ext-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Ext-Snoc]{\adjact{\sigs}{\ext}{\sigs'} }
          {\adjact{\sigs}{\ext, \sig~\many{R}}{\sigs', \sig~\many{R}}}
\end{mathpar}
$\boxed{\adjact{\sigs}{\adapt}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Id]{ }
          {\adjact{\sigs}{\id}{\sigs}}

\inferrule[A-Adapt-Snoc]{\adjact{\sigs}{\adapt}{\sigs'} \\
    \adpcom{\sigs'}{\sig}{S}{S'}{\sigs''}}
          {\adjact{\sigs}{\adapt, \sig(S \to S')}{\sigs''}}
\end{mathpar}
$\boxed{\adpcom{\sigs}{\sig}{S}{S'}{\sigs'}}$
\begin{mathpar}
\inferrule[A-Adapt-Com]
  {\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv} \\
   \itrinst{\ienv}{S'}{\sig}{\ext} \\
   \adjact{\sigs'}{\ext}{\sigs''}}
  {\adpcom{\sigs}{\sig}{S}{S'}{\sigs''}}
\end{mathpar}

$\boxed{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}$
\begin{mathpar}
\inferrule[I-Pat-Id]{ }
          {\itrbnd{\sigs}{\pid}{\sig}{\sigs}{s : \sigs}}

\inferrule[I-Pat-Bind]{\itrbnd{\sigs}{S}{\sig}{\sigs'}{\ienv}}
          {\itrbnd{\sigs,\sig~\many{R}}{S~a}{\sig}{\sigs'}
            {\ienv,a:\sig~\many{R}}}

\inferrule[I-Pat-Skip]{
  \itrbnd{\sigs}{S~a}{\sig}{\sigs'}{\ienv} \\
  \sig \neq \sig'}
  {\itrbnd{\sigs,\sig'~\many{R}}{S~a}{\sig}
          {\sigs',\sig'~\many{R}}{\ienv}}
\end{mathpar}


$\boxed{\itrinst{\ienv}{S}{\sig}{\ext}}$
\begin{mathpar}
\inferrule[I-Inst-Id]{s\in\meta{dom}(\ienv)}
          {\itrinst{\ienv}{\pid}{\sig}{\id}}

\inferrule[I-Inst-Lkp]{a\in\meta{dom}(\ienv) \\
  \itrinst{\ienv}{S}{\sig}{\ext} \\
  \ienv(a)=\sig~\many{R}}
          {\itrinst{\ienv}{S~a}{\sig}{\ext,\sig~\many{R}}}
\end{mathpar}
%% \caption{Action of an Adaptor's Interface Component on an Ability}
\label{fig:interface-components}

\begin{figure}[t]
%% \figrule
\flushleft
$\boxed{\inferskgs{m}{A}}$ \quad $\boxed{\checkskgs{A}{n}}$
\begin{mathpar}
\inferrule[T-Freeze-Use]
  {\neg(\EC \handles c) \\
   \inferskgs{\EC[c~\many{R}~\many{w}]}{A}}
  {\inferskgs{\freeze{\EC[c~\many{R}~\many{w}]}}{A}}

\inferrule[T-Freeze-Cons]
  {\neg(\EC \handles c) \\
   \checkskgs{A}{\EC[c~\many{R}~\many{w}]}}
  {\checkskgs{A}{\freeze{\EC[c~\many{R}~\many{w}]}}}
\end{mathpar}
\caption{Frozen Commands}
\label{fig:frozen-typing}
%% \figrule
\end{figure}

\caption{Action of an Adjustment on an Ability and Auxiliary Judgements}
\label{fig:act-adj}
%% \figrule
\end{figure}


\begin{figure} % \figrule
\flushleft

\[
\mathcal{X} ::= A \gor C \gor T \gor G \gor Z \gor R \gor P
                  \gor \seed \gor \sigs \gor \ext \gor \adapt \gor \adj
                  \gor \Gamma \gor \exists \kenva.\Gamma \gor \ienv
\]

$\boxed{\kindchecksk{\mathcal{X}}}$
%% \boxed{\kindchecksk{C}}\boxed{\kindchecksk{T}}
%% \boxed{\kindchecksk{G}}\boxed{\kindchecksk{Z}}\boxed{\kindchecksk{R}}\boxed{\kindchecksk{P}}
%% \boxed{\kindchecksk{\seed}}\boxed{\kindchecksk{\sigs}}
%% \boxed{\kindchecksk{\ext}}\boxed{\kindchecksk{\adapt}}\boxed{\kindchecksk{\adj}}
%% \boxed{\kindchecksk{S}}\boxed{\kindchecksk{\Gamma}}\boxed{\kindchecksk{\ienv}}
%% $
\begin{mathpar}
\inferrule[WF-Val]
  { }
  {\kindchecks{\kenv, X}{X}}

\inferrule[WF-Eff]
  { }
  {\kindchecks{\kenv, [E]}{E}}

\inferrule[WF-Poly]
  {\kindchecks{\kenv, \many{Z}}{A}}
  {\kindchecks{\kenv}{\forall \many{Z}.A}}
\\
\inferrule[WF-Data]
  {(\kindchecksk{R})_i}
  {\kindchecksk{D~\many{R}}}

\inferrule[WF-Thunk]
  {\kindchecksk{C}}
  {\kindchecksk{\thunk{C}}}

\inferrule[WF-Comp]
  {(\kindchecksk{T})_i \\ \kindchecksk{G}}
  {\kindchecksk{\many{T \to}~ G}}

\inferrule[WF-Arg]
  {\kindchecksk{\adj} \\ \kindchecksk{A}}
  {\kindchecksk{\effin{\adj}A}}

\inferrule[WF-Ret]
  {\kindchecksk{\sigs} \\ \kindchecksk{A}}
  {\kindchecksk{\effout{\sigs}A}}

\inferrule[WF-Ability]
  {\kindchecksk{\sigs}}
  {\kindchecksk{[\sigs]}}

\inferrule[WF-Pure]
  { }
  {\kindchecksk{\nowt}}

\inferrule[WF-Id]
  { }
  {\kindchecksk{\id}}

\inferrule[WF-Ext]
  {\kindchecksk{\ext} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ext, \sig~\many{R}}}

\inferrule[WF-Adapt]
  {\kindchecksk{\adapt}}
  {\kindchecksk{\adapt, \sig~(S \to S')}}
\\
\inferrule[WF-Empty]
  { }
  {\kindchecksk{\cdot}}

\inferrule[WF-Mono]
  {\kindchecksk{\Gamma} \\ \kindchecksk{A}}
  {\kindchecksk{\Gamma, x : A}}

\inferrule[WF-Poly]
  {\kindchecksk{\Gamma} \\ \kindchecksk{P}}
  {\kindchecksk{\Gamma, f : P}}
\\

\inferrule[WF-Existential]
  {\kindchecks{\kenv, \kenva}{\Gamma}}
  {\kindchecksk{\exists \kenva.\Gamma}}

\inferrule[WF-Interface]
  {\kindchecksk{\ienv} \\ (\kindchecksk{R})_i}
  {\kindchecksk{\ienv, x : \sig~\many{R}}}

\end{mathpar}


\caption{Well-Formedness Rules}
\label{fig:well-formedness}

% \figrule
\end{figure}

\begin{figure} % \figrule
\flushleft
$\boxed{\matchesvk{A}{p}{\Gamma}}$
\begin{mathpar}
\inferrule[P-Var]
  { }
  {\matchesvk{A}{x}{x:A}}

\inferrule[P-Data]
  {k~\many{A} \in D~\many{R} \\
   (\matchesvk{A_i}{p_i}{\Gamma})_i}
  {\matchesvk{D~\many{R}}{k~\many{p}}{\many{\Gamma}}}
\end{mathpar}
$\boxed{\matchesck{T}{r}{\sigs}{\exists \kenva.\Gamma}}$
\begin{mathpar}
\inferrule[P-Value]
  {\adjact{\sigs}{\adj}{\sigs'} \\ \matchesvk{A}{p}{\Gamma}}
  {\matchesck{\effin{\adj}A}{p}{\sigs}{\Gamma}}

\inferrule[P-CatchAll]
  {\adjact{\sigs}{\adj}{\sigs'}}
  {\matchesck{\effin{\adj}A}{\effin{x}}{\sigs}{x:{\thunk{\effout{\sigs'}A}}}}

\inferrule[P-Command]
  {
   \adjact{\sigs}{\adj}{\sigs'} \\
   \adj = \adapt\pipe\ext \\
   c:\forall \many{Z}.\many{A \to} B \in \ext \\
   (\matchesv{\kenv, \many{Z}}{A_i}{p_i}{\Gamma_i})_i}
  {\matchesc{\kenv}
            {\effin{\adj}B'}
            {\effin{\handle{c~\many{p}}{z}}}
            {\sigs}
            {\exists \many{Z}.\many{\Gamma}, z:\{\effin{\id\pipe\id}B \to \effout{\sigs'}B'\}}}
\end{mathpar}
\caption{Pattern Matching Typing Rules}
\label{fig:pattern-typing}
%% \figrule
\end{figure}

\chapter{Extended Proofs}

\section{Subject Reduction}
\label{sec:subject-reduction-proofs}

\begin{theorem*}[Subject Reduction for \nondetfrank{}~]~

\begin{itemize}
\item If $\inferskgs{m}{A}$ and $m \redtou m'$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n \redtoc n'$ then $\checkskgs{A}{n'}$.
\end{itemize}
\end{theorem*}
\begin{proof}
  The proof proceeds by induction on the transitions $\redtou, \redtoc$. We need
  only address the \textsc{R-Yield} rule, as all other rules have previously
  been shown to preserve types (\cite{convent2020doo}).

  \begin{itemize}
    \item[\Cse] \textsc{R-Yield}
    By the assumption we have that $\EF~\allows~\yield$. This only holds if the context is of the form
    \[\EF[~] = \cu (v : \thunk{\many{\effin{\adj} A
          \to}~\effout{\sigs}B})~(\many{t},[~],\many{n})
      \]

      \noindent where $\yield \in \ext_{|\many{t}|}$ and
      $\adj_{|\many{t}|} = \adapt_{|\many{t}|}\pipe\ext_{|\many{t}|}$.

      So assume that $\checkskgs{B}{\EF[n]}$. Then by inversion on
      \textsc{T-App} we have that
      $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{n}$ and
      $\adjact{\sigs}{\adj_{|\many{t}|}}{\sigs_{|\many{t}|}}$. It follows then
      that
      $\checksk{\Gamma}{\sigs'_{|\many{t}|}}{A_{|\many{t}|}}{(\yield{}!; n)}$,
      and accordingly that $\checkskgs{B}{\EF[\yield{}!; n]}$.
  \end{itemize}

\end{proof}

\begin{theorem*}[Subject Reduction for \countingfrank{}~]~

\begin{itemize}
\item If $\inferskgs{m}{A}$ and $m; \counter \redtou m'; \counter \bluetext{'}$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n; \counter \redtoc n'; \bluetext{\counter'}$ then $\checkskgs{A}{n'}$.
\end{itemize}
\end{theorem*}
\begin{proof}
  Again we look at each of the new rules added by \countingfrank.

  \begin{itemize}
    \item[\Cse] \textsc{R-Handle-Count} Follows from subject reduction for
      \textsc{R-Handle}, as the terms are unchanged between the two rules.

    \item[\Cse] \textsc{R-Yield-Can} Identical to \textsc{R-Yield} from above.

    \item[\Cse] \textsc{R-Yield-Can't} Assume that $\inferskgs{\EC[m]}{A}$, and
      let $\inferskg{m}{B}$. By the inversion we have that
      $m; \justc{k} \redtou m'; \justc{k'}$; by subject reduction we have that $\inferskg{m}{B}$. It follows that $\inferskgs{\EC[m']}{A}$.
  \end{itemize}

\end{proof}


\begin{theorem*}[Subject Reduction for \treefrank{}~]~

\begin{itemize}
\item If $\inferskgs{m}{A}$ and $m; \counter \redtou m'; \counter \bluetext{'}$ then $\inferskgs{m'}{A}$.
\item If $\checkskgs{A}{n}$ and $n; \counter \redtoc n'; \bluetext{\counter'}$ then $\checkskgs{A}{n'}$.
\end{itemize}
\end{theorem*}
\begin{proof}
  Essentially identical to the above two proofs. \textsc{R-Handle-GC} just
  removes the counter and otherwise acts identically to \textsc{R-Handle}.
  \textsc{Arg-Increment} might insert a \yield, but only if it's type-safe in
  the same way as before.
\end{proof}

We could also argue for subject reduction by using the fact that \treefrank~and
\countingfrank~both implement \nondetfrank, and \nondetfrank~ preserves types
when reducing.

\section{Type Soundness Proofs}
\label{sec:type-soundness-proofs}

\begin{theorem}[Type Soundness for \nondetfrank]~
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
\end{theorem}
\begin{proof}
% The proof proceeds by simultaneous induction on
The proof proceeds by simultaneous induction on
$\infers{\cdot}{\cdot}{\sigs}{m}{A}$ and $\checks{\cdot}{\cdot}{\sigs}{A}{n}$.

\nondetfrank~does not much complicate the proof. We can insert a \yield~command
at any point when evaluating an argument to a handler that handles
\yield~commands; this is then obviously a normal form that respects \sigs. If
the \yield~command is not inserted then soundness follows from previous proof
(\cite{convent2020doo}).
\end{proof}

\begin{theorem}[Type Soundness for \countingfrank]~
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
\end{theorem}
\begin{proof}
% The proof proceeds by simultaneous induction on

  Here the main obligation is to show that the use of \yieldc~does not
  potentially block a computation from reducing when it otherwise could, thus
  breaking type soundness. When the counter is in the \yieldc~state, the only
  type of term it effects is $\EC[m]$. If the evaluation context is a handler
  where the ability at the hole permits \yield~operations, we insert a yield;
  this freezes the rest of the term around it, becoming a normal form. If the
  evaluation context does not permit yields but the term could otherwise reduce
  then it does so.
\end{proof}


\begin{theorem}[Type Soundness for \treefrank]~
\begin{itemize}
\\
\item If $\infers{\cdot}{\cdot}{\sigs}{m}{A}$ then either $m$ is a normal form
  such that $m$ respects $\sigs$ or there exists a
  $\infers{\cdot}{\cdot}{\sigs}{m'}{A}$ such that $m \stepstou m'$.
\item If $\checks{\cdot}{\cdot}{\sigs}{A}{n}$ then either $n$ is a normal form
  such that $n$ respects $\sigs$ or there exists a
  $\checks{\cdot}{\cdot}{\sigs}{A}{n'}$ such that $n \stepstoc n'$.
\end{itemize}
\end{theorem}
\begin{proof}
  This proof is essentially the same as the above, showing that computation is
  never blocked by a counter.
\end{proof}


\end{document}
